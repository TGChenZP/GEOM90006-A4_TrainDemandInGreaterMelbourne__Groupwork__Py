{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = '../'\n",
    "home_directory = '../'\n",
    "\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "from model.model_class.environment import *\n",
    "\n",
    "from model.model_class import GNN\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_train_data = pd.read_parquet('../data/curated/ML_data/gnn_train_data.parquet')\n",
    "gnn_val_data = pd.read_parquet('../data/curated/ML_data/gnn_val_data.parquet')\n",
    "gnn_test_data = pd.read_parquet('../data/curated/ML_data/gnn_test_data.parquet')\n",
    "\n",
    "SA2_gnn_data = pd.read_parquet('../data/curated/ML_data/SA2_gnn_data.parquet')\n",
    "station_inference_gnn_data = pd.read_parquet('../data/curated/ML_data/station_inference_gnn_data.parquet')\n",
    "\n",
    "station_inference_gnn_data = station_inference_gnn_data.rename({'Station_Na': 'Station Name'}, axis=1)\n",
    "inference_data = pd.concat([SA2_gnn_data, station_inference_gnn_data], axis=0)\n",
    "inference_data = inference_data.rename({'Station Name': 'Station_Name'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations_list = [x for x in gnn_train_data['Station_Name'].unique()]\n",
    "# stations_index = {stations_list[i]:i for i in range(len(stations_list))}\n",
    "# reverse_stations_index = {v: k for (k, v) in stations_index.items()}\n",
    "\n",
    "# open npy\n",
    "station_weights_matrix = np.load('../data/curated/ML_data/station_weights_matrix.npy')\n",
    "SA2_weights_matrix = np.load('../data/curated/ML_data/station_weights_withSA2_matrix.npy')\n",
    "\n",
    "with open('../data/curated/ML_features/station_weights_withSA2.json', 'r') as f:\n",
    "    station_weights_withSA2 = json.load(f)\n",
    "\n",
    "with open('../data/curated/ML_features/station_weights.json', 'r') as f:\n",
    "    station_weights = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_features = ['log_Total_Demand']\n",
    "non_geospatial_features = ['Weekday', 'mean_rainfall_value', 'has_school',\n",
    "       'has_sport_facility', 'has_shopping_centre', 'has_hospital',\n",
    "       'total_population', ' med_rent_weekly_c2021',\n",
    "       ' med_mortg_rep_mon_c2021', ' med_person_inc_we_c2021',\n",
    "       ' med_famly_inc_we_c2021']\n",
    "label_columns = ['log_Total_Demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFactory(raw_dataset, geospatial_features, non_geospatial_features, label_columns, stations_index, inference = False):\n",
    "\n",
    "    \"\"\" Data Factory of GNN \"\"\"\n",
    "    \n",
    "    geospatial_x_batches = []\n",
    "    non_geospatial_x_batches = []\n",
    "    y_batches = []\n",
    "    masks = []\n",
    "\n",
    "    if inference:\n",
    "        groupby_column = 'Weekday'\n",
    "    else:\n",
    "        groupby_column = 'Business_Date'\n",
    "\n",
    "    for day, daily_df in tqdm(raw_dataset.groupby([groupby_column])):\n",
    "\n",
    "        geospatial_x = np.zeros([len(stations_index), len(geospatial_features)])\n",
    "        y = np.zeros([len(stations_index), len(label_columns)])\n",
    "        mask = np.zeros([len(stations_index), 1])\n",
    "        non_geospatial_x = np.zeros([len(stations_index), len(non_geospatial_features)])\n",
    "\n",
    "        daily_df.set_index('Station_Name', inplace=True)\n",
    "\n",
    "        for station in daily_df.index:\n",
    "\n",
    "            geospatial_x[stations_index[station]] = daily_df.loc[station][geospatial_features] # todo inference. \n",
    "            if not inference:\n",
    "                y[stations_index[station]] = daily_df.loc[station][label_columns]\n",
    "            mask[stations_index[station]] = 1\n",
    "            non_geospatial_x[stations_index[station]] = daily_df.loc[station][non_geospatial_features]\n",
    "                \n",
    "        geospatial_x_batches.append(geospatial_x)\n",
    "        y_batches.append(y)\n",
    "        masks.append(mask.flatten())\n",
    "\n",
    "        non_geospatial_x_batches.append(non_geospatial_x)\n",
    "\n",
    "        \n",
    "    return geospatial_x_batches, non_geospatial_x_batches, y_batches, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [01:11<00:00,  5.34it/s]\n",
      "100%|██████████| 82/82 [00:15<00:00,  5.42it/s]\n",
      "100%|██████████| 82/82 [00:14<00:00,  5.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_geospatial_X_batches, train_non_geospatial_X_batches, train_y_batches, train_masks = DataFactory(gnn_train_data, geospatial_features, non_geospatial_features, label_columns, station_weights)\n",
    "val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks = DataFactory(gnn_val_data, geospatial_features, non_geospatial_features, label_columns, station_weights)\n",
    "test_geospatial_X_batches, test_non_geospatial_X_batches, test_y_batches, test_masks = DataFactory(gnn_test_data, geospatial_features, non_geospatial_features, label_columns, station_weights)\n",
    "\n",
    "# inference_geospatial_X_batches, inference_non_geospatial_X_batches, inference_y_batches, inference_masks = DataFactory(inference_data, geospatial_features, non_geospatial_features, label_columns, station_weights_withSA2, inference = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:16<00:00, 22.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 Train | Loss:  0.0931 | R2:  0.8988| MSE:  0.0928 | RMSE:  0.3047 | MAE:  0.1941 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 83.27it/s]\n",
      "/Users/tg.chenny/Desktop/1. University/2. Masters/9. Geospatial Data Analysis/A4/GEOM90006-A4_TrainDemandInGreaterMelbourne__Groupwork__Py/model/model_class/__template__.py:193: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  val_y_tensor = torch.FloatTensor(val_y).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Val | Loss:  0.0182 | R2:  0.9818| MSE:  0.0182 | RMSE:  0.1348 | MAE:  0.1072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 27.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2 Train | Loss:  0.0246 | R2:  0.9729| MSE:  0.0247 | RMSE:  0.1570 | MAE:  0.1081 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 105.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Val | Loss:  0.0073 | R2:  0.9926| MSE:  0.0073 | RMSE:  0.0856 | MAE:  0.0701 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 28.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3 Train | Loss:  0.0165 | R2:  0.9818| MSE:  0.0166 | RMSE:  0.1289 | MAE:  0.0827 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 118.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Val | Loss:  0.0033 | R2:  0.9966| MSE:  0.0033 | RMSE:  0.0579 | MAE:  0.0462 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4 Train | Loss:  0.0141 | R2:  0.9844| MSE:  0.0142 | RMSE:  0.1192 | MAE:  0.0720 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 111.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Val | Loss:  0.0030 | R2:  0.9970| MSE:  0.0030 | RMSE:  0.0551 | MAE:  0.0471 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5 Train | Loss:  0.0131 | R2:  0.9855| MSE:  0.0132 | RMSE:  0.1148 | MAE:  0.0678 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 119.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Val | Loss:  0.0026 | R2:  0.9974| MSE:  0.0026 | RMSE:  0.0508 | MAE:  0.0396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:14<00:00, 26.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6 Train | Loss:  0.0127 | R2:  0.9860| MSE:  0.0127 | RMSE:  0.1128 | MAE:  0.0667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 104.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Val | Loss:  0.0049 | R2:  0.9951| MSE:  0.0049 | RMSE:  0.0702 | MAE:  0.0623 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 30.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7 Train | Loss:  0.0125 | R2:  0.9862| MSE:  0.0125 | RMSE:  0.1120 | MAE:  0.0655 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 101.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Val | Loss:  0.0035 | R2:  0.9965| MSE:  0.0035 | RMSE:  0.0590 | MAE:  0.0404 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 29.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 8 Train | Loss:  0.0125 | R2:  0.9863| MSE:  0.0125 | RMSE:  0.1120 | MAE:  0.0661 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 93.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0021 | R2:  0.9979| MSE:  0.0021 | RMSE:  0.0459 | MAE:  0.0332 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 9 Train | Loss:  0.0118 | R2:  0.9870| MSE:  0.0119 | RMSE:  0.1090 | MAE:  0.0641 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 104.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Val | Loss:  0.0050 | R2:  0.9949| MSE:  0.0050 | RMSE:  0.0710 | MAE:  0.0627 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 Train | Loss:  0.0116 | R2:  0.9872| MSE:  0.0116 | RMSE:  0.1079 | MAE:  0.0645 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 109.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Val | Loss:  0.0038 | R2:  0.9962| MSE:  0.0038 | RMSE:  0.0614 | MAE:  0.0449 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 29.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 Train | Loss:  0.0128 | R2:  0.9859| MSE:  0.0128 | RMSE:  0.1134 | MAE:  0.0676 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 86.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val | Loss:  0.0044 | R2:  0.9956| MSE:  0.0044 | RMSE:  0.0660 | MAE:  0.0501 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 115.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0021 | R2:  0.9979| MSE:  0.0021 | RMSE:  0.0459 | MAE:  0.0332 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 125.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0022 | R2:  0.9975| MSE:  0.0022 | RMSE:  0.0470 | MAE:  0.0343 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 1\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN'\n",
    "\n",
    "model = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# train the model (all cells except this one will print training log and evaluation at each batch)\n",
    "best_epoch = model.fit(train_geospatial_X_batches, train_non_geospatial_X_batches, train_y_batches, train_masks, val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix)\n",
    "print('\\n\\n')\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model.load()\n",
    "model.eval(val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix, best_epoch, evaluation_mode = True)\n",
    "model.eval(test_geospatial_X_batches, test_non_geospatial_X_batches, test_y_batches, test_masks, station_weights_matrix, best_epoch, evaluation_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:23<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 Train | Loss:  0.1195 | R2:  0.8701| MSE:  0.1191 | RMSE:  0.3452 | MAE:  0.2217 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 63.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Val | Loss:  0.0248 | R2:  0.9751| MSE:  0.0248 | RMSE:  0.1576 | MAE:  0.1200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2 Train | Loss:  0.0350 | R2:  0.9617| MSE:  0.0348 | RMSE:  0.1866 | MAE:  0.1311 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 52.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Val | Loss:  0.0204 | R2:  0.9796| MSE:  0.0204 | RMSE:  0.1428 | MAE:  0.0976 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3 Train | Loss:  0.0253 | R2:  0.9722| MSE:  0.0254 | RMSE:  0.1593 | MAE:  0.1069 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:02<00:00, 40.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Val | Loss:  0.0078 | R2:  0.9922| MSE:  0.0078 | RMSE:  0.0884 | MAE:  0.0666 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4 Train | Loss:  0.0211 | R2:  0.9768| MSE:  0.0211 | RMSE:  0.1453 | MAE:  0.0951 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Val | Loss:  0.0182 | R2:  0.9818| MSE:  0.0182 | RMSE:  0.1348 | MAE:  0.1128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5 Train | Loss:  0.0191 | R2:  0.9788| MSE:  0.0192 | RMSE:  0.1387 | MAE:  0.0897 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 55.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Val | Loss:  0.0077 | R2:  0.9923| MSE:  0.0077 | RMSE:  0.0875 | MAE:  0.0636 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 15.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6 Train | Loss:  0.0180 | R2:  0.9801| MSE:  0.0180 | RMSE:  0.1343 | MAE:  0.0859 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 49.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Val | Loss:  0.0072 | R2:  0.9928| MSE:  0.0072 | RMSE:  0.0848 | MAE:  0.0589 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7 Train | Loss:  0.0241 | R2:  0.9733| MSE:  0.0242 | RMSE:  0.1554 | MAE:  0.1012 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 55.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Val | Loss:  0.0091 | R2:  0.9909| MSE:  0.0091 | RMSE:  0.0954 | MAE:  0.0670 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 8 Train | Loss:  0.0181 | R2:  0.9801| MSE:  0.0182 | RMSE:  0.1348 | MAE:  0.0870 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0109 | R2:  0.9890| MSE:  0.0109 | RMSE:  0.1045 | MAE:  0.0707 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 9 Train | Loss:  0.0173 | R2:  0.9809| MSE:  0.0174 | RMSE:  0.1318 | MAE:  0.0841 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 52.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Val | Loss:  0.0094 | R2:  0.9906| MSE:  0.0094 | RMSE:  0.0967 | MAE:  0.0719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:24<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 Train | Loss:  0.0156 | R2:  0.9829| MSE:  0.0156 | RMSE:  0.1250 | MAE:  0.0767 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 57.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Val | Loss:  0.0071 | R2:  0.9929| MSE:  0.0071 | RMSE:  0.0841 | MAE:  0.0635 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:26<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 Train | Loss:  0.0142 | R2:  0.9843| MSE:  0.0143 | RMSE:  0.1194 | MAE:  0.0741 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 51.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val | Loss:  0.0051 | R2:  0.9948| MSE:  0.0051 | RMSE:  0.0717 | MAE:  0.0536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:24<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 Train | Loss:  0.0141 | R2:  0.9845| MSE:  0.0142 | RMSE:  0.1190 | MAE:  0.0726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 56.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Val | Loss:  0.0047 | R2:  0.9952| MSE:  0.0047 | RMSE:  0.0689 | MAE:  0.0515 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 Train | Loss:  0.0139 | R2:  0.9846| MSE:  0.0140 | RMSE:  0.1183 | MAE:  0.0716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 54.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val | Loss:  0.0044 | R2:  0.9956| MSE:  0.0044 | RMSE:  0.0663 | MAE:  0.0538 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:24<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 Train | Loss:  0.0144 | R2:  0.9842| MSE:  0.0145 | RMSE:  0.1202 | MAE:  0.0739 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Val | Loss:  0.0057 | R2:  0.9943| MSE:  0.0057 | RMSE:  0.0753 | MAE:  0.0541 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 53.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val | Loss:  0.0044 | R2:  0.9956| MSE:  0.0044 | RMSE:  0.0663 | MAE:  0.0538 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 56.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val | Loss:  0.0043 | R2:  0.9952| MSE:  0.0043 | RMSE:  0.0659 | MAE:  0.0533 \n"
     ]
    }
   ],
   "source": [
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 2\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN_2layer'\n",
    "\n",
    "model = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# train the model (all cells except this one will print training log and evaluation at each batch)\n",
    "best_epoch = model.fit(train_geospatial_X_batches, train_non_geospatial_X_batches, train_y_batches, train_masks, val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix)\n",
    "print('\\n\\n')\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model.load()\n",
    "model.eval(val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix, best_epoch, evaluation_mode = True)\n",
    "model.eval(test_geospatial_X_batches, test_non_geospatial_X_batches, test_y_batches, test_masks, station_weights_matrix, best_epoch, evaluation_mode = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 2 tuples correspond to weights for: 'Nearby Train Demand Aggregate', 'Weekday', 'PublicHoliday', 'mean_rainfall_value', 'has_school',\n",
    "       'has_sport_facility', 'has_shopping_centre', 'has_hospital',\n",
    "       'total_population', ' med_rent_weekly_c2021',\n",
    "       ' med_mortg_rep_mon_c2021', ' med_person_inc_we_c2021',\n",
    "       ' med_famly_inc_we_c2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.7362],\n",
      "        [ 0.8398],\n",
      "        [-0.3436],\n",
      "        [ 0.9492],\n",
      "        [-0.2153],\n",
      "        [ 0.1957],\n",
      "        [-0.5571],\n",
      "        [ 0.6811],\n",
      "        [ 0.9030],\n",
      "        [-0.7471],\n",
      "        [ 0.9454],\n",
      "        [ 0.0896],\n",
      "        [ 0.8059],\n",
      "        [ 0.1313],\n",
      "        [ 0.4793],\n",
      "        [-0.1369],\n",
      "        [ 0.7807],\n",
      "        [ 0.1755],\n",
      "        [-0.5059],\n",
      "        [ 0.2315],\n",
      "        [-0.4806],\n",
      "        [-0.0472],\n",
      "        [-0.4770],\n",
      "        [ 0.7152],\n",
      "        [-0.7993],\n",
      "        [-0.4881],\n",
      "        [-0.2937],\n",
      "        [-0.6137],\n",
      "        [ 0.0915],\n",
      "        [-0.9540],\n",
      "        [ 0.9292],\n",
      "        [-0.8240],\n",
      "        [ 0.7628],\n",
      "        [ 0.0945],\n",
      "        [-0.3497],\n",
      "        [ 0.6360],\n",
      "        [ 0.1512],\n",
      "        [ 0.8245],\n",
      "        [ 0.0918],\n",
      "        [-0.2330],\n",
      "        [ 0.3541],\n",
      "        [-0.0718],\n",
      "        [ 0.4646],\n",
      "        [ 0.9269],\n",
      "        [ 0.6514],\n",
      "        [-0.4592],\n",
      "        [ 0.6321],\n",
      "        [ 0.1548],\n",
      "        [ 0.5413],\n",
      "        [-0.6391],\n",
      "        [-0.9729],\n",
      "        [-0.4466],\n",
      "        [-0.7487],\n",
      "        [ 0.8921],\n",
      "        [ 0.2165],\n",
      "        [ 0.3975],\n",
      "        [ 0.2840],\n",
      "        [ 0.0121],\n",
      "        [ 0.7801],\n",
      "        [-0.7275],\n",
      "        [ 0.1201],\n",
      "        [-0.7331],\n",
      "        [ 0.3656],\n",
      "        [-0.3501],\n",
      "        [ 0.3280],\n",
      "        [-0.0932],\n",
      "        [ 0.8199],\n",
      "        [-0.5980],\n",
      "        [-0.6523],\n",
      "        [-0.6243],\n",
      "        [ 0.9374],\n",
      "        [ 0.3168],\n",
      "        [ 0.9937],\n",
      "        [-0.8243],\n",
      "        [-0.9218],\n",
      "        [-0.7923],\n",
      "        [-0.7059],\n",
      "        [ 0.4459],\n",
      "        [ 0.3385],\n",
      "        [ 0.8693],\n",
      "        [-0.5353],\n",
      "        [-0.7048],\n",
      "        [ 0.5395],\n",
      "        [-0.4327],\n",
      "        [ 0.6575],\n",
      "        [-0.1426],\n",
      "        [ 0.5427],\n",
      "        [-0.7589],\n",
      "        [-0.4979],\n",
      "        [ 0.3892],\n",
      "        [ 0.2305],\n",
      "        [-0.2722],\n",
      "        [ 0.6289],\n",
      "        [ 0.7537],\n",
      "        [-0.7505],\n",
      "        [-0.5812],\n",
      "        [ 0.8973],\n",
      "        [-0.3444],\n",
      "        [-0.4554],\n",
      "        [-0.9610],\n",
      "        [-0.6264],\n",
      "        [ 0.2505],\n",
      "        [-0.1280],\n",
      "        [-0.7265],\n",
      "        [ 0.0227],\n",
      "        [-0.6921],\n",
      "        [-0.8535],\n",
      "        [-0.5446],\n",
      "        [-0.8722],\n",
      "        [-0.6875],\n",
      "        [ 1.0332],\n",
      "        [ 0.1832],\n",
      "        [ 0.2839],\n",
      "        [-0.9181],\n",
      "        [-0.6608],\n",
      "        [-0.3691],\n",
      "        [ 0.1517],\n",
      "        [-0.8795],\n",
      "        [-0.4113],\n",
      "        [-0.6093],\n",
      "        [-0.0207],\n",
      "        [-0.4369],\n",
      "        [-0.0596],\n",
      "        [-0.6772],\n",
      "        [-0.6799],\n",
      "        [-0.6055],\n",
      "        [-0.3593],\n",
      "        [-0.7831],\n",
      "        [ 0.8913],\n",
      "        [-0.2619],\n",
      "        [ 0.9026],\n",
      "        [ 0.3253],\n",
      "        [-0.8462],\n",
      "        [ 0.7306],\n",
      "        [-0.2643],\n",
      "        [-0.3842],\n",
      "        [-0.8227],\n",
      "        [-0.9572],\n",
      "        [ 0.2916],\n",
      "        [-0.1508],\n",
      "        [ 0.3886],\n",
      "        [-0.8150],\n",
      "        [ 0.7973],\n",
      "        [-0.7614],\n",
      "        [-0.0845],\n",
      "        [ 0.1742],\n",
      "        [ 0.6334],\n",
      "        [ 0.8937],\n",
      "        [ 0.9714],\n",
      "        [-0.7804],\n",
      "        [ 0.2441],\n",
      "        [-0.4074],\n",
      "        [-0.1063],\n",
      "        [-0.7625],\n",
      "        [ 0.9729],\n",
      "        [-0.7313],\n",
      "        [ 0.5358],\n",
      "        [ 0.3176],\n",
      "        [ 0.2419],\n",
      "        [-0.5478],\n",
      "        [ 0.9675],\n",
      "        [ 0.0983],\n",
      "        [ 0.1248],\n",
      "        [-0.8620],\n",
      "        [ 0.4546],\n",
      "        [-0.0999],\n",
      "        [-0.4859],\n",
      "        [ 0.8736],\n",
      "        [ 0.1934],\n",
      "        [-0.5901],\n",
      "        [-0.5165],\n",
      "        [-0.0463],\n",
      "        [ 0.5984],\n",
      "        [-0.2440],\n",
      "        [-0.6216],\n",
      "        [-0.3743],\n",
      "        [-0.7072],\n",
      "        [ 0.3494],\n",
      "        [ 0.7931],\n",
      "        [-0.8879],\n",
      "        [ 0.2617],\n",
      "        [ 0.5334],\n",
      "        [ 0.1630],\n",
      "        [-0.3915],\n",
      "        [ 0.5972],\n",
      "        [ 0.5554],\n",
      "        [ 0.3152],\n",
      "        [-0.1241],\n",
      "        [-0.2930],\n",
      "        [ 0.1038],\n",
      "        [-0.1713],\n",
      "        [-0.3417],\n",
      "        [ 0.6556],\n",
      "        [ 0.8587],\n",
      "        [-0.0295],\n",
      "        [-0.2172],\n",
      "        [ 0.0142],\n",
      "        [-0.0438],\n",
      "        [ 0.1554],\n",
      "        [ 0.2966],\n",
      "        [-0.9043],\n",
      "        [-0.3584],\n",
      "        [ 0.9044],\n",
      "        [ 0.4284],\n",
      "        [-0.0183],\n",
      "        [-0.6431],\n",
      "        [-0.6719],\n",
      "        [-0.8842],\n",
      "        [-0.3795],\n",
      "        [ 0.3811],\n",
      "        [ 0.6388],\n",
      "        [ 0.4791],\n",
      "        [-0.8822],\n",
      "        [-0.6149],\n",
      "        [-0.1209],\n",
      "        [ 0.9674],\n",
      "        [ 0.1826],\n",
      "        [-0.1846],\n",
      "        [ 0.4683],\n",
      "        [-0.4722],\n",
      "        [-0.6441],\n",
      "        [ 0.7448],\n",
      "        [-0.5149],\n",
      "        [-0.0744],\n",
      "        [-0.9434],\n",
      "        [ 0.6842],\n",
      "        [ 0.8135],\n",
      "        [ 0.3256],\n",
      "        [-0.7044],\n",
      "        [-0.9629],\n",
      "        [-0.8198],\n",
      "        [ 0.7671],\n",
      "        [ 0.4682],\n",
      "        [ 0.8382],\n",
      "        [ 0.5539],\n",
      "        [ 0.2230],\n",
      "        [ 0.0260],\n",
      "        [-0.7687],\n",
      "        [-0.8513],\n",
      "        [-0.9152],\n",
      "        [ 0.4027],\n",
      "        [-0.5384],\n",
      "        [-0.1933],\n",
      "        [-0.5835],\n",
      "        [-0.1434],\n",
      "        [-0.6936],\n",
      "        [-0.6820],\n",
      "        [ 0.2187],\n",
      "        [-0.3323],\n",
      "        [ 0.6538],\n",
      "        [-0.3094],\n",
      "        [-0.7376],\n",
      "        [-0.1565],\n",
      "        [-0.5159],\n",
      "        [-0.3637],\n",
      "        [-0.9238]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 4.9027e-01, -6.4695e-01,  3.5758e-01,  3.9074e-01,  6.2010e-01,\n",
      "        -7.4394e-01,  6.0596e-01, -4.0781e-01,  3.3231e-01,  8.1070e-01,\n",
      "        -1.8773e-01, -3.5876e-02, -2.0417e-01, -8.0982e-01,  4.2828e-01,\n",
      "        -9.6280e-01,  5.5877e-01,  7.2252e-01,  8.1168e-01, -2.9183e-01,\n",
      "        -8.4573e-01,  1.9774e-01,  4.9087e-01, -9.6848e-01, -2.2935e-01,\n",
      "        -6.6979e-01, -1.9849e-01, -5.2868e-01, -3.9645e-01, -3.5522e-01,\n",
      "        -9.3694e-01,  6.8792e-01,  7.7213e-01, -2.2000e-01, -2.2982e-01,\n",
      "        -4.3000e-01, -8.7585e-01, -9.5237e-01,  3.6574e-01, -6.2433e-01,\n",
      "        -5.7549e-01, -2.2836e-01, -2.8687e-01, -3.2554e-01,  3.0226e-03,\n",
      "        -1.9330e-01, -3.1960e-01, -4.8315e-01, -8.3145e-01,  6.6171e-01,\n",
      "        -3.9729e-01,  1.6141e-01, -3.7693e-01,  7.2808e-02,  8.6064e-01,\n",
      "         4.1573e-01, -8.6290e-01,  3.6919e-01,  8.5634e-01,  2.6517e-01,\n",
      "         6.3718e-01,  8.7479e-01, -1.2297e-01,  1.6480e-01, -6.7050e-01,\n",
      "        -3.1471e-01,  6.5524e-01,  4.7923e-01, -6.0037e-01, -8.5574e-01,\n",
      "        -6.1609e-01, -9.6364e-01, -7.0663e-01, -2.3361e-01,  6.0715e-01,\n",
      "         1.1909e-01, -8.0126e-01, -7.8444e-01,  4.3556e-01, -6.8666e-01,\n",
      "        -1.4137e-01,  4.2765e-01, -4.7216e-01, -1.1697e-01, -1.0892e-01,\n",
      "        -3.7402e-01, -5.4700e-01, -9.4264e-01, -8.9565e-01, -4.7863e-01,\n",
      "         9.1875e-01, -5.2709e-01, -6.6067e-01,  2.2745e-01,  2.5038e-01,\n",
      "         4.8737e-01,  6.6101e-01,  4.9374e-01, -9.1925e-01,  7.3238e-02,\n",
      "         5.4101e-01, -1.2526e-01, -5.7152e-01,  8.0353e-01, -3.6276e-01,\n",
      "        -5.3543e-01, -9.2779e-01,  4.5270e-02,  4.0103e-01,  2.1229e-01,\n",
      "         1.5986e-01, -7.3553e-01, -9.2070e-01, -5.8024e-03,  7.7953e-01,\n",
      "         5.1592e-01, -5.6469e-01, -1.3401e-01, -8.1828e-01, -4.7553e-01,\n",
      "         9.2144e-02,  4.7596e-01,  7.8778e-01, -9.7718e-01,  5.9069e-01,\n",
      "        -7.3493e-01,  3.5499e-01,  7.4938e-01, -9.9019e-03,  7.4843e-01,\n",
      "        -8.1227e-01, -3.8794e-01,  5.1425e-01, -1.8499e-01, -3.0261e-01,\n",
      "        -5.0700e-01,  6.2637e-01,  4.2557e-01,  2.5852e-01, -6.0548e-01,\n",
      "        -7.8112e-01,  7.8727e-02,  2.5308e-01, -4.3969e-01, -3.4360e-01,\n",
      "         6.8887e-01,  5.3677e-02,  4.6957e-04, -2.4153e-01, -9.3545e-01,\n",
      "        -9.1192e-01, -5.7486e-01, -4.9301e-01,  2.7728e-01, -2.6281e-01,\n",
      "        -3.7325e-01,  8.3170e-01,  3.1050e-01,  6.2764e-01, -5.3113e-01,\n",
      "        -3.6922e-01,  3.2860e-01, -6.4619e-01, -7.1456e-01, -5.9732e-02,\n",
      "        -4.0017e-01, -8.0290e-01,  5.3833e-01,  7.6950e-01,  1.4736e-01,\n",
      "        -1.8380e-01, -8.9836e-01, -2.7478e-01,  2.4140e-01,  4.1875e-01,\n",
      "        -1.3082e-01, -4.2108e-01,  4.5247e-01, -7.9743e-01,  5.5886e-01,\n",
      "        -3.9643e-01, -4.7715e-02, -2.2583e-01,  7.4146e-02, -2.5305e-01,\n",
      "         6.3331e-01, -1.2488e-01,  7.3055e-01,  8.6485e-01, -4.7251e-01,\n",
      "        -7.0753e-01,  6.9128e-01,  7.1157e-01, -7.4935e-01, -1.2839e-01,\n",
      "        -9.5641e-01, -7.9393e-01,  1.7613e-01,  2.2484e-01,  1.4829e-01,\n",
      "        -2.9067e-01,  8.1959e-01,  9.4058e-02, -5.6908e-01, -7.5224e-02,\n",
      "         1.9434e-01,  3.0528e-01, -7.2977e-01,  3.2483e-01, -4.9041e-01,\n",
      "        -8.5291e-01, -5.7154e-01,  8.5358e-01,  7.4889e-01,  8.2367e-01,\n",
      "         5.3314e-01,  7.1914e-01, -2.3971e-01, -5.2511e-01,  4.3920e-01,\n",
      "        -5.4177e-01, -6.7384e-01, -2.9813e-01,  1.8789e-01,  3.9689e-01,\n",
      "        -3.5051e-01, -5.1088e-01,  1.1632e-01, -6.0038e-01, -6.6222e-01,\n",
      "         4.2926e-01, -1.7800e-01,  8.2841e-01,  8.1785e-01,  2.7875e-01,\n",
      "         3.0166e-01,  1.9658e-01, -4.6252e-03, -1.1385e-01,  5.2875e-04,\n",
      "         3.4403e-01,  7.9502e-01, -3.5766e-01, -4.4765e-01, -3.4323e-01,\n",
      "        -5.0128e-01,  1.4499e-01,  6.9082e-01,  7.0482e-01,  3.7955e-01,\n",
      "        -8.0005e-01, -5.5769e-01, -3.1075e-01, -2.1243e-01,  9.7848e-02,\n",
      "        -9.7209e-01], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0285,  0.0388, -0.0193,  ...,  0.0379,  0.0175,  0.0252],\n",
      "        [ 0.0517, -0.1001,  0.0792,  ..., -0.0112, -0.0044, -0.0856],\n",
      "        [-0.0332, -0.0008, -0.0884,  ...,  0.0529,  0.0115, -0.0232],\n",
      "        ...,\n",
      "        [-0.0206, -0.0688, -0.0575,  ...,  0.0020, -0.0346,  0.1002],\n",
      "        [ 0.0218,  0.0372,  0.0092,  ...,  0.0660,  0.0201,  0.0490],\n",
      "        [ 0.0275, -0.0352, -0.0464,  ..., -0.0215,  0.0236, -0.0383]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0217,  0.0570,  0.0575,  ...,  0.0803,  0.0669,  0.0179],\n",
      "        [ 0.0079, -0.0191,  0.0111,  ..., -0.1204, -0.0356, -0.0847],\n",
      "        [ 0.0117,  0.0686,  0.0418,  ...,  0.1331,  0.0490,  0.1846],\n",
      "        ...,\n",
      "        [ 0.0393,  0.0330, -0.0789,  ...,  0.1677,  0.0946,  0.0795],\n",
      "        [-0.0172,  0.0250, -0.0340,  ...,  0.0213, -0.0093,  0.0236],\n",
      "        [ 0.0303, -0.0270,  0.0153,  ..., -0.0466, -0.0353, -0.0368]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0191,  0.0455, -0.0332,  ...,  0.0119,  0.0499, -0.0251],\n",
      "        [ 0.0533, -0.0536,  0.0181,  ...,  0.0251, -0.0236, -0.0616],\n",
      "        [-0.0055,  0.0144,  0.0135,  ...,  0.0253,  0.0371, -0.0315],\n",
      "        ...,\n",
      "        [-0.0267, -0.0391,  0.0033,  ..., -0.0308,  0.0473, -0.0348],\n",
      "        [-0.0462, -0.0242, -0.0193,  ..., -0.0616,  0.0384, -0.0138],\n",
      "        [ 0.0390,  0.0036,  0.0412,  ...,  0.0171,  0.0258,  0.0048]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0341,  0.0422,  0.0267,  ..., -0.0230,  0.0585,  0.0232],\n",
      "        [-0.0221,  0.0051,  0.0490,  ..., -0.0537, -0.0403,  0.0006],\n",
      "        [-0.0397, -0.0030, -0.0412,  ..., -0.0079, -0.0266,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0239,  0.0228,  0.0398,  ..., -0.0134, -0.0295,  0.0514],\n",
      "        [ 0.0027, -0.0075, -0.0001,  ..., -0.0440, -0.0312, -0.0499],\n",
      "        [ 0.0170,  0.0137, -0.0499,  ..., -0.0537,  0.0233,  0.0395]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0008,  0.0132, -0.0257,  ..., -0.0383,  0.0609, -0.0341],\n",
      "        [-0.0586,  0.0565,  0.0176,  ..., -0.0140, -0.0198,  0.0709],\n",
      "        [-0.0154,  0.0291,  0.0032,  ..., -0.0428, -0.0201, -0.0356],\n",
      "        ...,\n",
      "        [ 0.0144, -0.0452,  0.0060,  ...,  0.0358,  0.0393, -0.0019],\n",
      "        [ 0.0140, -0.0682,  0.0234,  ..., -0.0070,  0.0169, -0.0437],\n",
      "        [ 0.0221, -0.0456,  0.0416,  ..., -0.0423, -0.0401, -0.0409]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0475,  0.0369,  0.0508,  ..., -0.0281, -0.0042, -0.0025],\n",
      "        [-0.0153,  0.0493,  0.0021,  ..., -0.0433,  0.0288, -0.0415],\n",
      "        [-0.0298,  0.0255, -0.0630,  ..., -0.0385,  0.0528,  0.0031],\n",
      "        ...,\n",
      "        [-0.0362, -0.0019, -0.0247,  ..., -0.0533,  0.0091, -0.0466],\n",
      "        [ 0.0022,  0.0274, -0.0640,  ...,  0.0037,  0.0403,  0.0330],\n",
      "        [-0.0469, -0.0139,  0.0381,  ..., -0.0248,  0.0151, -0.0283]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8921, 0.9769, 0.8936, 0.9450, 1.0289, 0.9423, 0.9263, 0.9537, 0.9529,\n",
      "        0.9143, 0.9600, 0.9303, 0.9482, 0.9197, 0.8990, 0.8832, 0.9200, 0.9800,\n",
      "        0.9487, 0.9376, 1.0941, 0.9796, 0.9270, 0.9380, 0.9242, 1.0617, 0.8796,\n",
      "        0.9495, 0.9349, 0.9477, 0.9632, 0.9274, 0.9219, 0.9805, 0.9164, 0.9619,\n",
      "        0.9967, 0.9691, 0.9504, 0.9604, 0.9516, 0.8940, 0.9583, 0.9724, 0.9337,\n",
      "        0.9370, 0.9337, 0.8895, 1.0730, 0.8881, 0.9263, 0.9399, 0.9537, 0.9234,\n",
      "        1.0875, 0.9560, 1.0366, 0.9508, 0.9343, 0.9397, 0.9507, 0.9229, 0.9660,\n",
      "        0.9188, 0.9610, 0.9347, 0.8878, 0.9291, 0.9621, 0.9283, 0.9335, 0.8966,\n",
      "        0.9629, 0.9161, 0.9232, 0.8555, 1.0404, 1.0241, 0.9546, 1.0060, 0.8908,\n",
      "        0.9411, 0.9408, 0.9406, 0.9323, 0.9525, 1.0136, 1.0326, 1.0308, 0.9371,\n",
      "        1.0792, 0.9694, 1.0011, 0.9430, 0.9242, 0.9485, 0.9105, 0.9617, 0.8870,\n",
      "        0.9105, 0.9151, 0.9019, 0.9197, 0.9300, 0.8256, 0.9355, 1.0093, 0.8554,\n",
      "        0.9188, 0.8923, 0.9321, 0.9228, 0.9797, 0.9303, 0.9201, 0.9502, 0.9215,\n",
      "        0.9313, 0.9886, 0.9674, 0.7872, 0.9488, 0.9425, 1.0407, 0.9125, 0.9736,\n",
      "        0.9592, 0.9383, 0.9382, 0.9740, 0.9258, 0.9569, 0.9391, 0.9440, 0.9728,\n",
      "        0.9487, 0.9253, 0.8467, 0.9157, 0.9812, 0.9754, 0.8848, 0.9491, 0.9524,\n",
      "        0.9490, 0.9772, 0.8978, 0.9134, 0.9387, 1.0141, 0.9941, 0.9321, 0.9003,\n",
      "        0.9021, 0.9757, 0.9333, 0.9137, 0.9751, 0.9785, 1.0134, 0.9281, 0.9637,\n",
      "        0.9731, 1.0038, 0.8995, 0.9391, 0.9462, 0.9230, 1.0392, 0.8276, 0.9348,\n",
      "        0.8661, 0.9486, 0.9574, 0.9031, 0.9062, 0.9472, 0.9139, 0.9807, 0.9229,\n",
      "        0.9499, 0.9382, 0.9586, 0.8828, 0.9169, 0.9148, 0.9349, 0.9305, 1.0359,\n",
      "        0.9205, 0.9870, 0.9576, 0.8671, 0.9623, 0.8810, 0.9261, 0.8210, 1.0552,\n",
      "        0.9624, 0.8942, 0.9460, 0.9467, 0.9158, 0.9539, 0.8759, 0.8630, 0.9263,\n",
      "        0.9680, 0.9299, 0.9401, 1.0167, 0.9914, 0.9184, 0.9329, 0.9608, 0.9178,\n",
      "        1.1769, 0.9113, 0.8236, 0.9521, 0.9484, 0.9517, 0.8416, 0.8951, 0.8873,\n",
      "        0.9673, 0.9326, 0.9850, 0.9700, 0.9629, 0.9115, 0.9413, 0.9362, 0.9095,\n",
      "        0.9427, 0.9345, 0.9263, 0.9438, 0.9413, 0.9305, 0.9452, 0.9568, 0.9300,\n",
      "        0.9912, 0.8682, 0.9690, 0.9122, 0.9808, 0.9848, 0.9361, 1.0109, 0.9511,\n",
      "        0.9484, 0.9246, 0.9365, 0.9952], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 8.6572e-03, -5.2376e-03,  5.9918e-02,  6.9400e-03, -2.9228e-02,\n",
      "        -5.4161e-02, -1.7423e-02,  3.2754e-02,  1.2311e-02, -1.2949e-02,\n",
      "         1.0909e-02, -8.0314e-02,  1.2029e-02,  6.3858e-02,  7.8630e-03,\n",
      "         9.1602e-02, -9.5282e-03, -5.0895e-02, -1.7731e-02,  4.2329e-02,\n",
      "         5.6381e-03, -5.5538e-02, -1.1812e-02,  5.3029e-02,  4.9675e-03,\n",
      "         4.4075e-02,  1.0074e-01,  2.8174e-02,  5.0584e-02,  4.8169e-03,\n",
      "         5.2830e-02, -1.1796e-02, -2.9193e-03,  6.5580e-04,  6.7025e-02,\n",
      "         5.0318e-02, -3.1649e-03,  4.1615e-02, -5.1711e-02, -1.0524e-02,\n",
      "         5.2656e-02, -1.6933e-02,  5.4383e-03,  1.2324e-02,  1.0729e-02,\n",
      "         1.2786e-02,  3.7131e-02, -7.0942e-02,  4.6988e-02, -1.8755e-02,\n",
      "         2.0628e-03,  3.5987e-03, -4.9379e-03,  1.1228e-02, -1.2895e-02,\n",
      "        -2.3387e-04, -1.6115e-02, -6.8274e-02, -1.2518e-03,  6.2800e-05,\n",
      "        -3.9980e-02, -1.5237e-02, -1.2486e-03, -2.2870e-02, -2.1694e-03,\n",
      "         8.9350e-03, -1.6057e-02, -1.1327e-02,  1.6782e-02,  4.9135e-02,\n",
      "         3.1746e-02,  4.7777e-02,  5.4186e-02,  9.7849e-04, -1.4320e-02,\n",
      "        -2.0744e-02,  3.1841e-02,  3.3830e-02, -7.8464e-03, -4.4976e-03,\n",
      "         2.1502e-02, -9.5095e-03,  4.0077e-02,  2.8999e-02,  3.7577e-02,\n",
      "        -2.9199e-03,  4.8879e-03,  5.5346e-03,  5.8227e-02,  6.9869e-02,\n",
      "        -3.1115e-02,  7.0636e-02,  2.5606e-02,  3.9204e-03, -7.0464e-03,\n",
      "        -1.1527e-02,  7.7117e-03, -2.1085e-02,  7.8952e-02,  3.2805e-03,\n",
      "        -1.2365e-02,  6.2050e-02, -5.7799e-03, -1.0641e-02, -6.8272e-02,\n",
      "         1.4374e-02,  2.8451e-02, -2.6001e-02,  1.3190e-03, -6.9287e-03,\n",
      "         1.1670e-02,  2.2790e-03, -5.9909e-03, -1.0221e-02, -1.7062e-02,\n",
      "        -1.3050e-02, -1.1030e-02,  1.4833e-02,  4.8891e-02,  1.2499e-02,\n",
      "         1.3172e-01, -1.2505e-02, -4.8808e-02,  2.9648e-02, -2.8147e-03,\n",
      "         2.4120e-02, -7.6324e-03, -1.6568e-02,  1.1518e-02, -4.5193e-02,\n",
      "         5.4685e-02,  4.4656e-02,  2.1215e-03,  1.6151e-02,  1.0377e-02,\n",
      "         6.3322e-02, -9.5393e-03, -2.8966e-02,  1.5224e-02, -3.8987e-02,\n",
      "        -1.0038e-02, -1.0039e-02,  1.0588e-02,  2.0598e-02, -1.8009e-02,\n",
      "        -4.2563e-02,  1.9721e-02,  9.5340e-03,  2.3719e-02,  1.8508e-02,\n",
      "        -2.7481e-02,  6.0701e-02, -7.7912e-02, -6.9217e-04,  9.3197e-03,\n",
      "         2.1561e-02, -6.8773e-03,  2.6743e-03, -3.0855e-02,  2.3260e-02,\n",
      "         3.4275e-02, -9.7102e-03, -6.6095e-03,  2.2851e-02,  3.1251e-02,\n",
      "        -4.3754e-02,  4.9881e-02,  1.2085e-02, -2.2326e-02, -1.5750e-02,\n",
      "         3.1866e-03, -7.7520e-02, -2.5366e-02, -1.2138e-02, -7.9511e-03,\n",
      "         2.5806e-03,  8.2554e-03,  6.5303e-03,  3.9175e-02, -1.0461e-02,\n",
      "         3.9170e-02, -7.3133e-03,  1.5297e-02, -3.2992e-02,  2.3213e-02,\n",
      "        -1.0271e-02,  2.9629e-02, -5.8977e-02, -2.1498e-02, -4.4721e-02,\n",
      "        -1.2206e-02, -2.8308e-02,  5.3507e-04,  4.3821e-02, -5.6567e-02,\n",
      "         1.3379e-02,  8.4781e-02, -4.0847e-02, -1.9093e-02,  1.8826e-02,\n",
      "        -4.0663e-03, -3.5505e-02, -3.4456e-04,  5.5384e-02, -8.8277e-02,\n",
      "         4.8759e-03, -4.5858e-03,  2.0913e-02, -1.6324e-02,  5.4334e-02,\n",
      "         8.7834e-03,  5.8854e-02, -7.3006e-03, -1.2727e-02, -7.1200e-02,\n",
      "        -4.6001e-04, -1.3859e-02,  1.0564e-02,  1.1501e-01, -8.1612e-03,\n",
      "         2.8109e-02,  4.1535e-02,  3.3339e-02, -7.0602e-02, -1.9087e-02,\n",
      "        -4.7890e-03,  5.0294e-02, -7.2940e-03,  2.8899e-02,  5.0624e-03,\n",
      "        -6.9571e-03,  7.1456e-03, -2.1312e-02, -8.1731e-03,  9.6690e-03,\n",
      "        -1.2151e-02, -7.0763e-02,  9.0647e-03, -9.6250e-03,  8.9095e-03,\n",
      "         3.4970e-03, -2.1884e-02,  6.3877e-02,  3.6383e-02,  1.1089e-01,\n",
      "         2.8342e-02, -1.0073e-02, -6.1106e-03, -1.6180e-02,  1.2626e-02,\n",
      "         4.4896e-02,  1.7569e-02,  4.7179e-02,  2.9442e-02, -9.2251e-03,\n",
      "         2.3942e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0346, 1.0092, 1.0101, 1.0288, 1.0304, 0.7712, 1.0520, 1.0364, 1.0338,\n",
      "        1.0320, 1.0954, 0.9191, 1.0551, 0.9755, 1.0230, 0.9549, 1.0423, 0.9240,\n",
      "        1.0428, 0.9387, 1.0208, 0.8823, 1.0443, 0.9353, 1.0689, 1.0325, 0.9792,\n",
      "        1.0417, 0.9620, 1.0526, 1.0326, 1.0358, 1.0070, 0.9934, 1.0349, 0.9573,\n",
      "        0.9823, 1.0149, 0.9027, 0.9598, 0.9372, 0.8341, 1.0087, 1.0288, 1.0390,\n",
      "        1.0384, 1.0019, 0.7539, 1.0096, 1.0329, 1.0645, 1.0446, 1.0373, 1.0670,\n",
      "        0.9876, 1.0154, 0.9747, 0.8294, 1.0003, 1.0456, 0.8815, 1.0244, 1.0075,\n",
      "        1.0396, 0.9822, 0.9285, 1.0144, 1.0479, 1.0646, 1.0391, 1.0331, 0.9219,\n",
      "        1.0334, 1.0462, 1.0141, 1.0556, 1.0499, 0.9882, 1.0123, 0.9950, 1.0502,\n",
      "        1.0585, 1.0140, 1.0483, 1.0174, 0.8101, 0.9821, 1.0173, 0.9445, 0.9147,\n",
      "        0.9485, 1.0004, 1.0169, 1.0606, 1.0552, 1.0450, 1.0006, 1.0578, 1.0494,\n",
      "        1.0347, 1.0227, 0.9777, 0.9552, 1.0143, 0.7482, 1.0387, 1.0324, 1.0268,\n",
      "        1.0451, 1.0646, 1.0609, 0.9827, 0.9836, 1.0429, 1.0188, 1.0433, 0.9655,\n",
      "        1.0522, 1.0147, 1.0205, 0.9814, 1.0323, 0.8731, 1.0106, 1.0422, 1.0419,\n",
      "        1.0343, 1.0142, 1.0646, 1.0356, 1.0377, 0.9968, 1.0379, 1.0092, 1.0301,\n",
      "        1.0075, 1.0322, 1.0431, 1.0141, 0.9442, 0.9923, 1.0529, 1.0574, 1.0540,\n",
      "        0.9649, 0.9427, 1.0446, 1.0644, 1.0686, 1.0315, 0.9412, 0.9929, 0.7982,\n",
      "        1.0555, 1.0559, 1.0453, 1.0082, 1.0096, 0.9793, 1.0383, 1.0680, 0.9828,\n",
      "        0.9631, 1.0410, 1.0156, 0.8619, 1.0558, 1.0331, 0.9670, 1.0636, 1.0413,\n",
      "        0.7734, 0.9988, 1.0365, 1.0879, 1.0718, 1.0231, 1.0011, 1.0157, 1.0200,\n",
      "        0.9610, 1.0036, 0.9637, 1.0527, 1.0256, 1.0289, 0.9448, 0.8351, 1.0031,\n",
      "        0.9150, 0.9433, 1.0365, 1.0136, 0.9846, 0.7663, 0.9635, 0.9587, 0.8944,\n",
      "        0.9887, 1.0088, 1.0559, 1.0215, 1.0475, 1.0097, 0.7370, 1.0477, 1.0526,\n",
      "        1.0536, 1.0291, 0.9694, 0.9902, 0.9925, 1.0094, 1.0184, 0.8318, 1.0153,\n",
      "        0.9610, 0.9332, 1.0637, 1.0483, 1.0430, 1.0066, 1.0563, 0.9080, 1.0274,\n",
      "        0.9890, 1.0172, 1.0011, 1.0482, 1.0418, 1.0549, 1.0065, 1.0031, 0.9965,\n",
      "        1.0153, 0.9979, 0.8991, 1.0609, 1.0683, 1.0570, 0.9986, 1.0295, 0.9457,\n",
      "        1.0349, 0.9313, 1.0425, 1.0622, 0.9929, 1.0451, 1.0412, 0.9698, 1.0432,\n",
      "        0.9375, 1.0580, 1.0624, 1.0722], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0136,  0.0152,  0.1424, -0.0157, -0.0412, -0.2227,  0.0084,  0.0807,\n",
      "        -0.0059, -0.0162,  0.0764, -0.0462,  0.0398, -0.0302,  0.0067,  0.0937,\n",
      "        -0.0202, -0.0496, -0.0061, -0.0729,  0.0558, -0.1326,  0.0405, -0.0339,\n",
      "         0.0899,  0.0666,  0.0472,  0.1194, -0.0317,  0.0817,  0.0554, -0.0108,\n",
      "        -0.0475, -0.0310,  0.1586,  0.0269, -0.0462,  0.0680, -0.0681, -0.1081,\n",
      "        -0.1083, -0.1805,  0.0120,  0.0351,  0.0526,  0.0773,  0.0455, -0.1535,\n",
      "         0.0032,  0.0044,  0.0758,  0.1294,  0.0795,  0.0167, -0.0725, -0.0190,\n",
      "        -0.0616, -0.1388, -0.0596,  0.0513, -0.0820, -0.0262,  0.0341,  0.0783,\n",
      "        -0.0676, -0.0791, -0.0326,  0.0283,  0.1157,  0.1700,  0.0416, -0.0228,\n",
      "         0.0352,  0.0687,  0.0028,  0.0548,  0.1248, -0.0269, -0.0011,  0.0202,\n",
      "         0.1206,  0.0397,  0.0173,  0.0733,  0.0317, -0.2091, -0.0365,  0.0862,\n",
      "        -0.1011,  0.0701, -0.1068,  0.0243,  0.0462,  0.0225,  0.0498,  0.0360,\n",
      "        -0.0356,  0.0300,  0.1028,  0.0483,  0.0188, -0.0188, -0.1170, -0.0136,\n",
      "        -0.1336,  0.0832,  0.0837,  0.0620,  0.0231,  0.0778, -0.0022, -0.0433,\n",
      "        -0.0389,  0.0751, -0.0153,  0.0417, -0.0973,  0.0892, -0.0168,  0.0630,\n",
      "         0.1087,  0.0348, -0.0796,  0.0667,  0.0392,  0.0971,  0.0363, -0.0143,\n",
      "         0.0156, -0.0273,  0.0541, -0.0188,  0.0050,  0.0323,  0.0353,  0.2163,\n",
      "        -0.0054,  0.0210,  0.0759, -0.1326, -0.0293,  0.0638,  0.0198,  0.0930,\n",
      "        -0.0756, -0.0294,  0.0557,  0.0200,  0.0274,  0.0985, -0.1171,  0.1718,\n",
      "        -0.1989,  0.0578,  0.0298,  0.0693, -0.0454,  0.0087, -0.0932,  0.0831,\n",
      "         0.0450, -0.0438, -0.0803,  0.0988,  0.0280, -0.1405,  0.1238, -0.0169,\n",
      "        -0.1035,  0.0879,  0.0806, -0.1788,  0.0080,  0.0327,  0.0570,  0.1140,\n",
      "         0.0923, -0.0215,  0.0381, -0.0019, -0.0587,  0.0272, -0.0511,  0.0786,\n",
      "         0.0607, -0.0131, -0.0509, -0.0697, -0.0609, -0.0606, -0.0984, -0.0027,\n",
      "        -0.0309,  0.0263, -0.1407, -0.0883,  0.2539, -0.1723, -0.0529,  0.0115,\n",
      "         0.0746, -0.0135,  0.0144,  0.0402, -0.1769,  0.0719,  0.0560,  0.0724,\n",
      "         0.0445,  0.0691,  0.0176, -0.0134, -0.0351,  0.0091, -0.0524, -0.0267,\n",
      "        -0.1249, -0.1194,  0.1805,  0.0568,  0.0956,  0.0282,  0.1197, -0.0873,\n",
      "         0.0230,  0.0200,  0.0731, -0.0205,  0.1135,  0.0638,  0.0316,  0.0339,\n",
      "        -0.0497, -0.0541, -0.0048, -0.0079, -0.0784,  0.0924,  0.0893,  0.0631,\n",
      "        -0.0026, -0.0101, -0.0553,  0.0904, -0.0355,  0.0733,  0.0937, -0.0608,\n",
      "         0.0051,  0.0018, -0.0759,  0.1116, -0.0778,  0.0919,  0.1075,  0.0777],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 9.7547e-02,  8.6742e-02, -7.1259e-02,  1.0482e-01, -6.7366e-02,\n",
      "          6.8550e-03, -9.6175e-02,  1.0661e-01,  1.1172e-01, -1.0008e-01,\n",
      "          1.6379e-01,  1.2816e-03,  1.1793e-01,  5.0342e-02,  7.5138e-02,\n",
      "          5.1969e-02,  1.0838e-01,  2.0896e-03, -8.9068e-02,  5.2158e-02,\n",
      "         -7.8590e-02, -3.5768e-03, -8.9208e-02, -2.2106e-02, -1.3409e-01,\n",
      "         -8.6796e-02, -8.0290e-02, -1.0174e-01,  4.5880e-02, -1.3220e-01,\n",
      "          1.1131e-01, -1.0882e-01,  8.1345e-02,  5.1001e-02, -9.5636e-02,\n",
      "          2.6349e-02,  4.0610e-02,  9.7433e-02,  2.1329e-03, -2.3407e-02,\n",
      "          3.0943e-02,  2.0351e-02,  6.7208e-02,  1.0515e-01,  9.9194e-02,\n",
      "         -9.0068e-02,  7.2914e-02,  2.0755e-03,  7.4100e-02, -8.8514e-02,\n",
      "         -1.4175e-01, -8.7120e-02, -1.0695e-01,  1.2607e-01,  4.4337e-02,\n",
      "          6.3435e-02,  3.2210e-02,  5.3613e-03,  7.7097e-02, -1.0705e-01,\n",
      "          1.8182e-03, -8.8719e-02,  6.0513e-02, -8.5036e-02,  3.7827e-02,\n",
      "          4.2430e-02,  9.5138e-02, -1.0033e-01, -1.1362e-01, -1.2931e-01,\n",
      "          1.1609e-01,  3.9460e-02,  1.1904e-01, -1.1435e-01, -9.9598e-02,\n",
      "         -1.2091e-01, -1.0993e-01,  4.6573e-02,  6.1809e-02,  7.5841e-02,\n",
      "         -1.0437e-01, -1.1672e-01,  7.4745e-02, -9.6559e-02,  8.4099e-02,\n",
      "          1.5095e-02,  4.8199e-02, -9.0357e-02, -4.5552e-02,  7.1394e-02,\n",
      "          1.2721e-02, -6.6103e-02,  8.3996e-02,  1.1889e-01, -1.1646e-01,\n",
      "         -9.5329e-02,  8.6401e-02, -8.6234e-02, -1.2725e-01, -1.1772e-01,\n",
      "         -8.1966e-02,  4.7474e-02, -2.6297e-02, -8.5021e-02,  2.1635e-03,\n",
      "         -1.0829e-01, -1.1023e-01, -8.7270e-02, -1.2010e-01, -1.1890e-01,\n",
      "          1.3530e-01,  4.0507e-02,  4.3192e-02, -1.2306e-01, -8.1823e-02,\n",
      "         -8.7514e-02,  3.3179e-02, -1.2685e-01, -6.2386e-02, -8.5365e-02,\n",
      "         -4.4448e-02, -8.0943e-02,  1.1783e-03, -7.8693e-02, -1.0537e-01,\n",
      "         -1.0533e-01, -8.0955e-02, -8.5917e-02,  1.3241e-01, -8.1180e-02,\n",
      "          1.1832e-01,  4.5206e-02, -1.1052e-01,  8.0178e-02, -6.4971e-02,\n",
      "         -1.0555e-01, -1.0477e-01, -1.2325e-01,  7.0984e-02, -2.0216e-02,\n",
      "          4.5675e-02, -1.2126e-01,  1.2166e-01, -1.1725e-01, -3.3031e-02,\n",
      "          1.7977e-03,  1.0198e-01,  1.2897e-01,  1.3740e-01, -1.0591e-01,\n",
      "          2.4202e-02, -8.2080e-02,  1.9124e-04, -1.1844e-01,  1.2404e-01,\n",
      "         -1.1110e-01,  6.6688e-02,  5.8624e-02,  3.5156e-02, -1.0025e-01,\n",
      "          1.4216e-01,  3.2943e-02,  3.3324e-02, -1.1746e-01,  7.0629e-02,\n",
      "         -3.0426e-03, -1.2690e-01,  1.0349e-01,  2.7684e-02, -1.1587e-01,\n",
      "         -9.4940e-02,  1.6995e-03,  6.1768e-02, -6.5912e-02, -1.3281e-01,\n",
      "         -1.0927e-01, -9.5286e-02,  5.0905e-02,  9.4892e-02, -1.0011e-01,\n",
      "         -3.9971e-02,  6.7772e-02,  3.8933e-02, -9.7010e-02,  9.3677e-02,\n",
      "          8.4813e-02, -4.3841e-02,  1.9075e-04, -4.9984e-02,  3.9986e-03,\n",
      "          4.7880e-02, -7.6384e-02,  7.9020e-02,  6.8458e-02,  4.2753e-04,\n",
      "         -3.3408e-02, -1.1023e-01, -1.8497e-02,  3.7827e-02,  5.6379e-02,\n",
      "         -1.3257e-01, -6.9316e-02,  1.1692e-01,  6.1276e-02,  3.5022e-04,\n",
      "         -1.0468e-01, -1.0836e-01, -1.2610e-01, -7.8102e-02,  5.7276e-02,\n",
      "          6.3599e-02,  5.6257e-02, -9.0700e-02, -8.1554e-02,  1.5704e-03,\n",
      "          1.0300e-01,  2.5406e-02, -1.9394e-02,  1.2796e-01, -9.5314e-02,\n",
      "         -1.0232e-01,  8.1303e-02, -1.1048e-01,  5.0669e-05, -1.1130e-01,\n",
      "          6.1301e-02,  9.7974e-02,  4.9210e-02, -1.0928e-01, -1.2257e-01,\n",
      "         -1.2295e-01,  8.0684e-02,  6.1980e-02,  7.8227e-02,  6.9552e-02,\n",
      "          4.7228e-02,  7.0205e-04, -1.2273e-01, -1.3674e-01, -1.3195e-01,\n",
      "          4.9873e-02, -8.0881e-02,  4.6449e-02, -9.1101e-02,  5.3613e-02,\n",
      "         -1.0866e-01, -1.1764e-01,  4.9613e-02, -8.3570e-02,  9.2566e-02,\n",
      "         -3.1063e-02, -1.1178e-01,  3.7094e-02, -1.0207e-01, -9.2335e-02,\n",
      "         -1.4481e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0087], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3057,  0.0125, -0.0236, -0.0005, -0.0012,  0.0008,  0.0097,  0.0050,\n",
      "          0.0163, -0.0042, -0.0031, -0.0062,  0.0096]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0044], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# A_GNN features\n",
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 1\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN'\n",
    "\n",
    "model1 = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model1.load()\n",
    "\n",
    "for parameters in model1.model.parameters():\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.7166],\n",
      "        [ 0.8427],\n",
      "        [-0.1441],\n",
      "        [ 1.0012],\n",
      "        [-0.1901],\n",
      "        [ 0.1942],\n",
      "        [-0.5508],\n",
      "        [ 0.6392],\n",
      "        [ 0.9027],\n",
      "        [-0.8150],\n",
      "        [ 0.9137],\n",
      "        [ 0.0327],\n",
      "        [ 0.7569],\n",
      "        [ 0.1303],\n",
      "        [ 0.3980],\n",
      "        [-0.1359],\n",
      "        [ 0.7395],\n",
      "        [ 0.1327],\n",
      "        [-0.4516],\n",
      "        [ 0.2119],\n",
      "        [-0.3637],\n",
      "        [-0.0616],\n",
      "        [-0.5009],\n",
      "        [ 0.6615],\n",
      "        [-0.7959],\n",
      "        [-0.3846],\n",
      "        [-0.1962],\n",
      "        [-0.6042],\n",
      "        [ 0.0908],\n",
      "        [-0.9626],\n",
      "        [ 0.9329],\n",
      "        [-0.8770],\n",
      "        [ 0.7723],\n",
      "        [ 0.0767],\n",
      "        [-0.3444],\n",
      "        [ 0.6519],\n",
      "        [ 0.1500],\n",
      "        [ 0.7907],\n",
      "        [ 0.0400],\n",
      "        [-0.1556],\n",
      "        [ 0.3401],\n",
      "        [-0.1957],\n",
      "        [ 0.4367],\n",
      "        [ 0.9276],\n",
      "        [ 0.6073],\n",
      "        [-0.4405],\n",
      "        [ 0.5767],\n",
      "        [ 0.1567],\n",
      "        [ 0.5497],\n",
      "        [-0.5952],\n",
      "        [-0.9792],\n",
      "        [-0.4103],\n",
      "        [-0.7662],\n",
      "        [ 0.8137],\n",
      "        [ 0.2294],\n",
      "        [ 0.3811],\n",
      "        [ 0.2821],\n",
      "        [ 0.0306],\n",
      "        [ 0.7685],\n",
      "        [-0.7341],\n",
      "        [ 0.0956],\n",
      "        [-0.7517],\n",
      "        [ 0.3605],\n",
      "        [-0.3705],\n",
      "        [ 0.3478],\n",
      "        [-0.1479],\n",
      "        [ 0.7802],\n",
      "        [-0.6526],\n",
      "        [-0.6102],\n",
      "        [-0.5660],\n",
      "        [ 0.9247],\n",
      "        [ 0.3106],\n",
      "        [ 0.9702],\n",
      "        [-0.8354],\n",
      "        [-0.9782],\n",
      "        [-0.7899],\n",
      "        [-0.6666],\n",
      "        [ 0.4454],\n",
      "        [ 0.3385],\n",
      "        [ 0.8818],\n",
      "        [-0.5506],\n",
      "        [-0.7041],\n",
      "        [ 0.5803],\n",
      "        [-0.4205],\n",
      "        [ 0.5584],\n",
      "        [-0.2196],\n",
      "        [ 0.5090],\n",
      "        [-0.7521],\n",
      "        [-0.5001],\n",
      "        [ 0.3205],\n",
      "        [ 0.2242],\n",
      "        [-0.2794],\n",
      "        [ 0.5874],\n",
      "        [ 0.7155],\n",
      "        [-0.7234],\n",
      "        [-0.4983],\n",
      "        [ 0.8813],\n",
      "        [-0.3246],\n",
      "        [-0.4441],\n",
      "        [-0.9190],\n",
      "        [-0.5792],\n",
      "        [ 0.2867],\n",
      "        [-0.1270],\n",
      "        [-0.7394],\n",
      "        [ 0.0226],\n",
      "        [-0.6674],\n",
      "        [-0.8279],\n",
      "        [-0.5972],\n",
      "        [-0.9029],\n",
      "        [-0.6622],\n",
      "        [ 1.0101],\n",
      "        [ 0.1818],\n",
      "        [ 0.2789],\n",
      "        [-0.9181],\n",
      "        [-0.6993],\n",
      "        [-0.3677],\n",
      "        [ 0.1505],\n",
      "        [-0.8657],\n",
      "        [-0.4312],\n",
      "        [-0.6426],\n",
      "        [-0.0301],\n",
      "        [-0.2989],\n",
      "        [-0.0978],\n",
      "        [-0.6929],\n",
      "        [-0.6929],\n",
      "        [-0.5630],\n",
      "        [-0.3335],\n",
      "        [-0.8858],\n",
      "        [ 0.8670],\n",
      "        [-0.1707],\n",
      "        [ 0.8546],\n",
      "        [ 0.3441],\n",
      "        [-0.8328],\n",
      "        [ 0.7272],\n",
      "        [-0.1695],\n",
      "        [-0.4229],\n",
      "        [-0.8588],\n",
      "        [-1.0369],\n",
      "        [ 0.2379],\n",
      "        [-0.1435],\n",
      "        [ 0.4556],\n",
      "        [-0.8484],\n",
      "        [ 0.8138],\n",
      "        [-0.7221],\n",
      "        [-0.1143],\n",
      "        [ 0.1352],\n",
      "        [ 0.5848],\n",
      "        [ 0.8357],\n",
      "        [ 0.9439],\n",
      "        [-0.7908],\n",
      "        [ 0.2422],\n",
      "        [-0.4633],\n",
      "        [-0.1055],\n",
      "        [-0.7697],\n",
      "        [ 0.9439],\n",
      "        [-0.7198],\n",
      "        [ 0.5407],\n",
      "        [ 0.2613],\n",
      "        [ 0.2095],\n",
      "        [-0.5338],\n",
      "        [ 0.9427],\n",
      "        [ 0.1396],\n",
      "        [ 0.1238],\n",
      "        [-0.8856],\n",
      "        [ 0.3965],\n",
      "        [-0.0941],\n",
      "        [-0.4685],\n",
      "        [ 0.8849],\n",
      "        [ 0.1783],\n",
      "        [-0.5943],\n",
      "        [-0.5093],\n",
      "        [-0.0460],\n",
      "        [ 0.6150],\n",
      "        [-0.1642],\n",
      "        [-0.6491],\n",
      "        [-0.3517],\n",
      "        [-0.7217],\n",
      "        [ 0.3063],\n",
      "        [ 0.7857],\n",
      "        [-0.9281],\n",
      "        [ 0.2672],\n",
      "        [ 0.4467],\n",
      "        [ 0.1933],\n",
      "        [-0.2714],\n",
      "        [ 0.5326],\n",
      "        [ 0.5142],\n",
      "        [ 0.3616],\n",
      "        [-0.1203],\n",
      "        [-0.2385],\n",
      "        [ 0.1030],\n",
      "        [-0.1700],\n",
      "        [-0.2348],\n",
      "        [ 0.6041],\n",
      "        [ 0.8913],\n",
      "        [-0.0089],\n",
      "        [-0.2155],\n",
      "        [ 0.0140],\n",
      "        [-0.0358],\n",
      "        [ 0.1454],\n",
      "        [ 0.1214],\n",
      "        [-0.8783],\n",
      "        [-0.2567],\n",
      "        [ 0.8905],\n",
      "        [ 0.4008],\n",
      "        [-0.0692],\n",
      "        [-0.6107],\n",
      "        [-0.6471],\n",
      "        [-0.8642],\n",
      "        [-0.2393],\n",
      "        [ 0.3865],\n",
      "        [ 0.6654],\n",
      "        [ 0.4937],\n",
      "        [-0.9573],\n",
      "        [-0.6250],\n",
      "        [-0.0823],\n",
      "        [ 1.0284],\n",
      "        [ 0.1712],\n",
      "        [-0.2616],\n",
      "        [ 0.4362],\n",
      "        [-0.4237],\n",
      "        [-0.6455],\n",
      "        [ 0.6838],\n",
      "        [-0.4863],\n",
      "        [-0.1137],\n",
      "        [-1.0267],\n",
      "        [ 0.7276],\n",
      "        [ 0.8106],\n",
      "        [ 0.3199],\n",
      "        [-0.6534],\n",
      "        [-0.9563],\n",
      "        [-0.8221],\n",
      "        [ 0.7948],\n",
      "        [ 0.4517],\n",
      "        [ 0.8326],\n",
      "        [ 0.5292],\n",
      "        [ 0.2587],\n",
      "        [-0.0464],\n",
      "        [-0.7912],\n",
      "        [-0.8415],\n",
      "        [-0.9216],\n",
      "        [ 0.1980],\n",
      "        [-0.5078],\n",
      "        [-0.1823],\n",
      "        [-0.5944],\n",
      "        [-0.0708],\n",
      "        [-0.6734],\n",
      "        [-0.6512],\n",
      "        [ 0.2533],\n",
      "        [-0.2436],\n",
      "        [ 0.6193],\n",
      "        [-0.3418],\n",
      "        [-0.7331],\n",
      "        [-0.2172],\n",
      "        [-0.4961],\n",
      "        [-0.1692],\n",
      "        [-0.9349]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 4.1491e-01, -6.9616e-01,  4.2204e-01,  4.0008e-01,  5.4766e-01,\n",
      "        -7.3827e-01,  5.7026e-01, -4.8627e-01,  3.0213e-01,  7.6065e-01,\n",
      "        -1.5232e-01, -9.9354e-02, -2.6326e-01, -8.0365e-01,  3.9603e-01,\n",
      "        -9.5546e-01,  5.6672e-01,  6.8361e-01,  7.9134e-01, -3.3122e-01,\n",
      "        -9.5568e-01,  1.8691e-01,  4.0913e-01, -1.0267e+00, -2.6913e-01,\n",
      "        -8.0871e-01, -1.5263e-01, -5.7319e-01, -3.9343e-01, -3.6678e-01,\n",
      "        -9.4302e-01,  6.2584e-01,  7.6657e-01, -2.6467e-01, -2.2112e-01,\n",
      "        -4.1321e-01, -8.6917e-01, -1.0107e+00,  2.5008e-01, -6.1918e-01,\n",
      "        -6.0763e-01, -4.9533e-02, -3.3630e-01, -3.4685e-01, -3.3271e-03,\n",
      "        -2.4263e-01, -3.4332e-01, -4.7626e-01, -8.1041e-01,  6.5921e-01,\n",
      "        -4.3597e-01,  7.4098e-02, -3.9352e-01,  8.5026e-03,  9.0313e-01,\n",
      "         3.7782e-01, -8.5561e-01,  3.4711e-01,  8.3791e-01,  1.7820e-01,\n",
      "         5.8601e-01,  8.1898e-01, -1.5570e-01,  8.7668e-02, -6.8100e-01,\n",
      "        -1.1465e-01,  6.4029e-01,  4.4578e-01, -7.0918e-01, -9.4477e-01,\n",
      "        -6.3302e-01, -9.5959e-01, -7.4119e-01, -2.4802e-01,  5.3354e-01,\n",
      "         9.2828e-02, -8.5420e-01, -7.8825e-01,  3.7786e-01, -6.9580e-01,\n",
      "        -1.1158e-01,  2.7220e-01, -4.2290e-01, -2.2189e-01, -1.5040e-01,\n",
      "        -3.2518e-01, -6.0819e-01, -9.9260e-01, -9.3830e-01, -5.8272e-01,\n",
      "         8.8491e-01, -5.6464e-01, -7.2523e-01,  1.4815e-01,  1.7697e-01,\n",
      "         4.1728e-01,  6.3150e-01,  4.5332e-01, -1.0072e+00,  1.0087e-02,\n",
      "         4.9322e-01, -1.1908e-01, -5.6716e-01,  7.4061e-01, -3.5999e-01,\n",
      "        -6.6700e-01, -9.8014e-01,  3.5651e-03,  3.2944e-01,  1.0214e-01,\n",
      "         1.1062e-01, -7.2993e-01, -9.1564e-01, -1.2105e-02,  6.8400e-01,\n",
      "         4.3899e-01, -5.6038e-01, -1.4260e-01, -8.5399e-01, -5.1600e-01,\n",
      "         1.1618e-01,  4.3103e-01,  7.1997e-01, -9.6795e-01,  5.0629e-01,\n",
      "        -8.3311e-01,  3.1245e-01,  6.5107e-01, -4.6599e-02,  7.8667e-01,\n",
      "        -8.8649e-01, -4.2095e-01,  4.4174e-01, -1.9821e-01, -2.2933e-01,\n",
      "        -5.0968e-01,  5.6897e-01,  4.3733e-01,  1.9868e-01, -6.0723e-01,\n",
      "        -7.8531e-01,  4.9287e-02,  2.0914e-01, -5.7243e-01, -2.9939e-01,\n",
      "         5.6170e-01, -1.3782e-02, -2.2400e-02, -2.9505e-01, -9.8089e-01,\n",
      "        -9.0497e-01, -5.5097e-01, -4.8925e-01,  2.1279e-01, -3.2307e-01,\n",
      "        -4.5737e-01,  7.9971e-01,  2.3931e-01,  5.5099e-01, -5.8729e-01,\n",
      "        -4.1226e-01,  2.5833e-01, -6.4127e-01, -6.9966e-01, -1.0435e-01,\n",
      "        -4.0071e-01, -8.3969e-01,  5.0387e-01,  7.1728e-01,  6.2666e-02,\n",
      "        -2.6405e-01, -8.9151e-01, -3.4632e-01,  1.9478e-01,  4.2812e-01,\n",
      "        -2.5235e-01, -4.9846e-01,  3.5289e-01, -8.2011e-01,  5.0320e-01,\n",
      "        -4.3512e-01, -1.1103e-01, -2.4090e-01,  4.4253e-02, -3.0852e-01,\n",
      "         6.0429e-01, -1.1667e-01,  7.0234e-01,  8.5843e-01, -4.6891e-01,\n",
      "        -7.0214e-01,  6.7189e-01,  6.8791e-01, -7.2718e-01, -4.7212e-02,\n",
      "        -9.4912e-01, -7.8788e-01,  1.2235e-01,  1.4794e-01,  9.2937e-02,\n",
      "        -3.3820e-01,  7.6627e-01,  6.1720e-02, -6.2494e-01, -1.6741e-01,\n",
      "         9.5608e-02,  2.4486e-01, -7.4865e-01,  2.5386e-01, -5.0368e-01,\n",
      "        -8.4495e-01, -5.8239e-01,  8.1741e-01,  7.6106e-01,  8.1293e-01,\n",
      "         5.2885e-01,  6.9420e-01, -2.1669e-01, -5.8216e-01,  3.8933e-01,\n",
      "        -5.7428e-01, -7.1892e-01, -3.7613e-01,  1.3605e-01,  3.9267e-01,\n",
      "        -3.7275e-01, -5.5108e-01,  3.6313e-02, -7.1417e-01, -7.3024e-01,\n",
      "         3.6441e-01, -1.9307e-01,  7.7523e-01,  8.1518e-01,  2.2727e-01,\n",
      "         2.1138e-01,  1.3623e-01,  1.3879e-02, -1.3803e-01,  9.2945e-04,\n",
      "         3.0895e-01,  7.6609e-01, -3.4749e-01, -4.8704e-01, -3.0231e-01,\n",
      "        -6.1248e-01,  3.3744e-02,  6.5236e-01,  7.0068e-01,  2.5847e-01,\n",
      "        -8.3284e-01, -5.9638e-01, -2.7752e-01, -2.6554e-01,  3.3721e-02,\n",
      "        -9.8990e-01], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1558e-05,  2.1396e-02,  1.3950e-03,  ...,  3.7396e-02,\n",
      "          1.9138e-02, -2.3719e-02],\n",
      "        [ 2.3921e-02, -1.0654e-01,  6.4155e-02,  ..., -1.0517e-02,\n",
      "         -1.4435e-02, -4.4907e-02],\n",
      "        [ 1.1494e-03, -1.0290e-01, -8.2292e-02,  ...,  3.4669e-02,\n",
      "          1.3300e-02, -1.7154e-02],\n",
      "        ...,\n",
      "        [-2.0199e-02,  2.4511e-02, -4.7787e-02,  ...,  1.9799e-02,\n",
      "          5.0733e-03,  4.0159e-02],\n",
      "        [ 1.9898e-02, -2.7370e-02,  2.2035e-02,  ...,  4.1907e-02,\n",
      "          4.5288e-02,  1.2011e-02],\n",
      "        [-2.7708e-03,  4.4342e-03, -5.5475e-02,  ...,  5.2543e-02,\n",
      "          5.5693e-02,  2.1346e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0007,  0.0568,  0.0372,  ...,  0.1055,  0.0847,  0.0209],\n",
      "        [-0.0150, -0.0444,  0.0213,  ..., -0.1530, -0.0050, -0.1064],\n",
      "        [-0.0103,  0.0968,  0.0130,  ...,  0.0695,  0.0543,  0.0900],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0024, -0.0379,  ..., -0.0019, -0.0467, -0.0828],\n",
      "        [-0.0190,  0.0226, -0.0463,  ...,  0.0715,  0.0135,  0.0629],\n",
      "        [ 0.0060, -0.0369,  0.0371,  ..., -0.1218, -0.0944, -0.0979]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0226,  0.0362, -0.0333,  ...,  0.0179,  0.0494, -0.0201],\n",
      "        [ 0.0505, -0.0437,  0.0048,  ...,  0.0222, -0.0309, -0.0676],\n",
      "        [ 0.0073,  0.0404,  0.0191,  ...,  0.0031,  0.0385, -0.0578],\n",
      "        ...,\n",
      "        [-0.0283, -0.0412, -0.0061,  ..., -0.0522,  0.0219, -0.0397],\n",
      "        [-0.0471, -0.0082, -0.0361,  ..., -0.0546,  0.0296, -0.0032],\n",
      "        [ 0.0288,  0.0085,  0.0391,  ...,  0.0290,  0.0211,  0.0438]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0341,  0.0422,  0.0267,  ..., -0.0230,  0.0585,  0.0232],\n",
      "        [-0.0221,  0.0051,  0.0490,  ..., -0.0537, -0.0403,  0.0006],\n",
      "        [-0.0397, -0.0030, -0.0412,  ..., -0.0079, -0.0266,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0239,  0.0228,  0.0398,  ..., -0.0134, -0.0295,  0.0514],\n",
      "        [ 0.0027, -0.0075, -0.0001,  ..., -0.0440, -0.0312, -0.0499],\n",
      "        [ 0.0170,  0.0137, -0.0499,  ..., -0.0537,  0.0233,  0.0395]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0231, -0.0083, -0.0397,  ..., -0.0024,  0.0244,  0.0164],\n",
      "        [-0.0389,  0.0232, -0.0437,  ..., -0.0453, -0.0043,  0.1141],\n",
      "        [ 0.0482, -0.0024, -0.0297,  ..., -0.0646, -0.0124, -0.0706],\n",
      "        ...,\n",
      "        [ 0.0078, -0.0456, -0.0034,  ...,  0.0406,  0.0303,  0.0085],\n",
      "        [ 0.0210,  0.0011, -0.1599,  ..., -0.0128,  0.0016, -0.0265],\n",
      "        [ 0.0042,  0.0199,  0.0286,  ..., -0.0432, -0.0107, -0.0446]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0357,  0.0204,  0.0388,  ..., -0.0250, -0.0578,  0.0046],\n",
      "        [-0.0168,  0.0652, -0.0084,  ..., -0.0459,  0.1302, -0.0484],\n",
      "        [-0.0606,  0.0010, -0.1068,  ..., -0.0088,  0.0213,  0.0211],\n",
      "        ...,\n",
      "        [-0.0428, -0.0508,  0.0298,  ..., -0.0542,  0.0063, -0.0456],\n",
      "        [ 0.0233, -0.0599, -0.1001,  ...,  0.0129,  0.2241,  0.0545],\n",
      "        [-0.0590, -0.0447,  0.0396,  ..., -0.0251,  0.0238, -0.0286]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9493, 0.9821, 0.9853, 0.9748, 0.9473, 0.9481, 0.9369, 0.9135, 0.9790,\n",
      "        0.8904, 0.9837, 0.9378, 0.9716, 0.9652, 0.9307, 0.8844, 0.9585, 1.0197,\n",
      "        0.9494, 0.8878, 1.0455, 0.9707, 0.9291, 0.9610, 0.9419, 1.0118, 0.8591,\n",
      "        0.9639, 0.8692, 0.9361, 0.9808, 0.8943, 0.9435, 1.0093, 0.9095, 0.9130,\n",
      "        0.9115, 0.9998, 0.9408, 0.9474, 0.9072, 0.9044, 0.9246, 0.9865, 0.9587,\n",
      "        0.8970, 0.9229, 0.9559, 0.9177, 0.8936, 0.9648, 0.8932, 0.9052, 0.9726,\n",
      "        1.0969, 0.9626, 1.0052, 1.0166, 0.9245, 0.9354, 0.9959, 0.8334, 0.8816,\n",
      "        0.8322, 0.8789, 0.9057, 0.9444, 0.9432, 0.9826, 1.0108, 1.0230, 0.9072,\n",
      "        1.0041, 0.9467, 0.8938, 0.9409, 1.0003, 0.9122, 0.9437, 0.9782, 0.8996,\n",
      "        0.9016, 0.9164, 0.9292, 0.9490, 0.8529, 0.9629, 0.9986, 1.0047, 0.9086,\n",
      "        1.0596, 0.9183, 0.9117, 0.9697, 0.9206, 0.9675, 0.9257, 0.9103, 0.9753,\n",
      "        0.9659, 0.9019, 0.8832, 0.9053, 0.9186, 0.9335, 0.9053, 0.9256, 0.8946,\n",
      "        0.9283, 0.9542, 0.9724, 0.9523, 0.9315, 0.9151, 0.8959, 0.9002, 0.8777,\n",
      "        0.9249, 0.9647, 0.9627, 0.9110, 0.9418, 0.9709, 1.0680, 0.8958, 0.9615,\n",
      "        0.9578, 0.8924, 0.9681, 0.9915, 1.0260, 0.9384, 0.9230, 0.9396, 0.9699,\n",
      "        0.9950, 0.8710, 0.8779, 0.8805, 0.9448, 0.9507, 0.9420, 0.9678, 0.9304,\n",
      "        0.8537, 0.9674, 0.9539, 0.9995, 0.9762, 1.0456, 0.9873, 0.9591, 0.8976,\n",
      "        0.9237, 1.0107, 0.9143, 0.8415, 0.9197, 0.9316, 0.9441, 0.9879, 0.9079,\n",
      "        0.9427, 0.9495, 0.8730, 0.9822, 0.9712, 0.9607, 1.0619, 0.9376, 0.9008,\n",
      "        0.8950, 0.9424, 0.9371, 0.9420, 0.8302, 0.9440, 0.8987, 1.0269, 0.8994,\n",
      "        0.8328, 0.9250, 0.8474, 0.8932, 0.9866, 0.9174, 0.8949, 0.9897, 1.0093,\n",
      "        0.9715, 0.9096, 0.9434, 0.9175, 0.9944, 0.8996, 0.8543, 0.8755, 0.9556,\n",
      "        0.8547, 0.8847, 0.9314, 0.8556, 0.9931, 0.8926, 0.8671, 0.9453, 0.9124,\n",
      "        0.9509, 0.9249, 0.9107, 0.9940, 0.9171, 0.8933, 0.9519, 0.9422, 0.9743,\n",
      "        1.0286, 0.9052, 0.8635, 0.9235, 1.0388, 0.9641, 0.9577, 0.9221, 0.8759,\n",
      "        1.0015, 0.9782, 0.9524, 1.0263, 0.9514, 0.8914, 0.9959, 0.8848, 0.9165,\n",
      "        0.9533, 0.9123, 0.9406, 0.9816, 0.9226, 0.9757, 0.9217, 0.9193, 0.9351,\n",
      "        0.9585, 0.9117, 0.9439, 0.8824, 0.9149, 1.0176, 0.9269, 0.9792, 0.9562,\n",
      "        0.9162, 0.9344, 0.9122, 1.0014], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0241,  0.0259, -0.0783,  0.0386, -0.0527, -0.0323, -0.0610,  0.0864,\n",
      "         0.0557, -0.0497,  0.0602, -0.0315,  0.0666, -0.0069, -0.0062,  0.0906,\n",
      "         0.0064, -0.0496, -0.0502,  0.0583, -0.0027, -0.0592, -0.0481,  0.0743,\n",
      "         0.0298,  0.0567, -0.0059,  0.0531,  0.0591,  0.0287,  0.0417, -0.0533,\n",
      "        -0.0048, -0.0467,  0.0678,  0.0926,  0.0174,  0.0578, -0.0509, -0.0422,\n",
      "         0.0695, -0.0477,  0.0272,  0.0597,  0.0505,  0.0171,  0.0291, -0.0479,\n",
      "         0.0800, -0.0586,  0.0224,  0.0465,  0.0285,  0.0551, -0.0164,  0.0041,\n",
      "        -0.0328, -0.0494, -0.0008, -0.0201, -0.0315, -0.0783,  0.0967, -0.0208,\n",
      "        -0.0470, -0.0251,  0.0039, -0.0267,  0.0331,  0.0355,  0.0378,  0.0057,\n",
      "         0.0932,  0.0297, -0.0390, -0.0148,  0.0553,  0.0778, -0.0102,  0.0724,\n",
      "         0.0313, -0.0285,  0.0735,  0.0601,  0.0224,  0.0042,  0.0044,  0.0347,\n",
      "         0.0699,  0.0231, -0.0269,  0.0529,  0.0939,  0.0408, -0.0180, -0.0417,\n",
      "         0.0215, -0.0698,  0.0758,  0.0123, -0.0569,  0.1067, -0.0064, -0.0552,\n",
      "         0.0231,  0.0628,  0.0680,  0.0079, -0.0218, -0.0085,  0.0664, -0.0227,\n",
      "        -0.0188,  0.0030, -0.0565, -0.0667,  0.0894,  0.0262,  0.0720,  0.0228,\n",
      "        -0.0168, -0.0621, -0.0657,  0.0168, -0.0300,  0.0475, -0.0455, -0.0452,\n",
      "         0.0617, -0.0853,  0.0129,  0.0804, -0.0266,  0.0631, -0.0313,  0.0590,\n",
      "        -0.0402, -0.0475,  0.0193, -0.0465,  0.0829, -0.0078,  0.0536,  0.0569,\n",
      "        -0.0127, -0.0335,  0.0559,  0.0492,  0.0690,  0.0431, -0.0368,  0.0480,\n",
      "         0.0455, -0.0129,  0.0535,  0.0562, -0.0138,  0.0018, -0.0322,  0.0571,\n",
      "         0.0705, -0.0074, -0.0593,  0.0596,  0.0431, -0.0380,  0.0618,  0.0479,\n",
      "        -0.0424, -0.0022,  0.0627, -0.0345,  0.0598, -0.0396, -0.0362,  0.0881,\n",
      "         0.0400, -0.0035,  0.0219, -0.0379,  0.1058, -0.0002,  0.0875, -0.0271,\n",
      "         0.0138, -0.0092,  0.0135, -0.0639, -0.0580, -0.0496, -0.0074, -0.0840,\n",
      "         0.0082,  0.0906, -0.0366,  0.0831,  0.0629, -0.0263,  0.0335, -0.0403,\n",
      "         0.0343, -0.0681,  0.0423,  0.1014,  0.0955,  0.0047, -0.0237,  0.0472,\n",
      "        -0.0540,  0.0814,  0.0433,  0.0925, -0.0453, -0.0612, -0.0731,  0.0191,\n",
      "        -0.0329,  0.0835,  0.0912, -0.0384,  0.0553, -0.0028, -0.0283, -0.0040,\n",
      "        -0.0274,  0.0368,  0.0650,  0.0168,  0.0326,  0.0441, -0.0338,  0.0565,\n",
      "        -0.0222, -0.0055,  0.0425,  0.0456, -0.0395, -0.0032,  0.0258,  0.0135,\n",
      "        -0.0302, -0.0782,  0.0117,  0.0448, -0.0319,  0.0720,  0.0289, -0.0294,\n",
      "        -0.0652,  0.0531,  0.0595,  0.0532,  0.0826,  0.0398,  0.0053,  0.0597],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9291, 0.9906, 0.9481, 0.9798, 0.8427, 0.8522, 0.9462, 0.9937, 0.9618,\n",
      "        0.9359, 0.9559, 0.9514, 0.9574, 0.8946, 0.8788, 0.9170, 0.9447, 0.9702,\n",
      "        0.9175, 0.8818, 0.9451, 0.9900, 0.9594, 0.9193, 1.0041, 1.0090, 0.8589,\n",
      "        0.9659, 0.9961, 0.9628, 1.0030, 0.9293, 0.9561, 0.9361, 0.8325, 0.9520,\n",
      "        0.9323, 0.9462, 0.8264, 0.9498, 0.8422, 0.9592, 0.9288, 0.9780, 0.9889,\n",
      "        0.9235, 0.9919, 0.9745, 0.9987, 0.9199, 0.9954, 0.9846, 0.9876, 0.9470,\n",
      "        0.9058, 0.9096, 0.8776, 0.9302, 0.9377, 0.9563, 0.9671, 0.9382, 0.9561,\n",
      "        0.9380, 0.9348, 0.9458, 0.9424, 0.9672, 1.0045, 0.9447, 0.9336, 0.8919,\n",
      "        0.9541, 0.9661, 0.9106, 0.9457, 1.0328, 0.9117, 0.8673, 0.9429, 0.9364,\n",
      "        0.9500, 0.9967, 0.9733, 0.9334, 0.9039, 0.8925, 1.0176, 0.8745, 0.8326,\n",
      "        0.8573, 0.8689, 1.0808, 0.9162, 0.9316, 0.9252, 0.9448, 0.9406, 0.9630,\n",
      "        0.9189, 0.9548, 0.8478, 0.9631, 0.8693, 0.8627, 1.0028, 1.0177, 0.9937,\n",
      "        0.9436, 0.9449, 0.9844, 1.0043, 0.9186, 0.9626, 0.8592, 0.9342, 0.8442,\n",
      "        0.9466, 0.8694, 1.0005, 0.9270, 0.9132, 0.9225, 0.9763, 0.9122, 0.8663,\n",
      "        0.9602, 0.9453, 0.9641, 0.9314, 0.9611, 0.9328, 0.9173, 0.9037, 0.9618,\n",
      "        0.8928, 0.9297, 0.9765, 0.8854, 0.9689, 0.9081, 0.9729, 0.9425, 1.0263,\n",
      "        0.7819, 0.9052, 0.8846, 0.9507, 0.9866, 0.9906, 0.8821, 0.8247, 0.7950,\n",
      "        0.9556, 0.9959, 1.0194, 0.9205, 0.8762, 0.8537, 0.9663, 0.9746, 0.9320,\n",
      "        0.8910, 0.9987, 0.9539, 0.8918, 0.9195, 0.9806, 0.8224, 0.9510, 0.9888,\n",
      "        0.6293, 0.9821, 0.9480, 0.9762, 0.9386, 0.9919, 0.9110, 0.9404, 0.9262,\n",
      "        0.8513, 0.9430, 0.6681, 0.9255, 0.8942, 0.9192, 0.9530, 0.9544, 0.9207,\n",
      "        0.9479, 0.8567, 0.8913, 0.9180, 0.9455, 0.9668, 0.8750, 0.7701, 0.8992,\n",
      "        0.8627, 0.9521, 0.9702, 0.9216, 0.9374, 0.7027, 0.8756, 0.9394, 0.9671,\n",
      "        0.9827, 0.8877, 0.9666, 0.9305, 1.0130, 0.9307, 0.9322, 0.9694, 0.9988,\n",
      "        0.9353, 0.7123, 0.9641, 0.9379, 0.9738, 0.8939, 0.9545, 0.8393, 0.9716,\n",
      "        0.9717, 0.9576, 0.9286, 0.9552, 1.0016, 0.9422, 0.9943, 0.9371, 0.9532,\n",
      "        0.9948, 0.9569, 0.8123, 0.9589, 1.0064, 0.9550, 0.9233, 0.9145, 0.9710,\n",
      "        0.9435, 0.9449, 0.9374, 0.9850, 0.9014, 0.9510, 0.8840, 0.8998, 1.0005,\n",
      "        0.9446, 0.9071, 1.0006, 1.0455], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0540, -0.0113, -0.0937,  0.0136, -0.1727, -0.0799, -0.0405,  0.0376,\n",
      "        -0.0451, -0.0698, -0.0265, -0.1154, -0.0118, -0.0945, -0.0459, -0.0497,\n",
      "        -0.0118, -0.0711, -0.0971, -0.1114, -0.0436, -0.0556, -0.0288, -0.1163,\n",
      "        -0.0218, -0.0585, -0.1256, -0.0064, -0.0747, -0.0336, -0.0195, -0.0776,\n",
      "        -0.0187, -0.1107, -0.1407, -0.0148, -0.0653, -0.0600, -0.1149, -0.0892,\n",
      "        -0.0196, -0.0315, -0.0772,  0.0024,  0.0039, -0.0105, -0.0145, -0.0942,\n",
      "        -0.0512, -0.0980, -0.0114, -0.0167, -0.0189, -0.0677, -0.0688, -0.0484,\n",
      "        -0.0718, -0.0759, -0.0243, -0.0344, -0.0855, -0.0638, -0.0354, -0.0005,\n",
      "        -0.0656, -0.0467, -0.0424, -0.0160,  0.0171, -0.0623, -0.0356, -0.0851,\n",
      "        -0.0347, -0.0083, -0.0681, -0.0294,  0.0032, -0.0788, -0.0805, -0.0079,\n",
      "        -0.0122, -0.0426, -0.0209, -0.0217, -0.0493, -0.0464, -0.0907, -0.0194,\n",
      "        -0.0864, -0.1440, -0.1071, -0.1461, -0.0186, -0.0240, -0.0455, -0.0223,\n",
      "        -0.0255, -0.0441,  0.0142, -0.0808, -0.0610, -0.1306, -0.0308, -0.1070,\n",
      "        -0.0964,  0.0073, -0.0159, -0.0038, -0.0536, -0.0324, -0.0454, -0.0799,\n",
      "        -0.0634, -0.0209, -0.1174, -0.0221, -0.0600, -0.0441, -0.0825,  0.0005,\n",
      "        -0.0679, -0.1142, -0.0956,  0.0060, -0.0692, -0.0814, -0.0252, -0.0779,\n",
      "        -0.0124, -0.1184, -0.0207, -0.0722, -0.0818, -0.0689, -0.0495,  0.0013,\n",
      "        -0.0607, -0.0021, -0.0907, -0.0518, -0.0662, -0.0155,  0.0037, -0.0225,\n",
      "        -0.1958, -0.1252, -0.0397, -0.0084,  0.0037, -0.0045, -0.0855, -0.0811,\n",
      "        -0.1273, -0.0234, -0.0251, -0.0296, -0.0205, -0.0602, -0.1308, -0.0166,\n",
      "        -0.0127, -0.0617, -0.0942,  0.0104, -0.0397, -0.1124, -0.0250,  0.0296,\n",
      "        -0.1758, -0.0023, -0.0058, -0.2756, -0.0132, -0.0482,  0.0169, -0.0635,\n",
      "        -0.0224, -0.0900, -0.0330, -0.0680, -0.1023, -0.0470, -0.2001, -0.0430,\n",
      "        -0.0569, -0.0203, -0.0292, -0.0806, -0.1224, -0.0942, -0.1106, -0.0905,\n",
      "        -0.0256, -0.0322, -0.0408, -0.1377, -0.1925, -0.0977, -0.0831, -0.0814,\n",
      "        -0.0353, -0.1370, -0.0269, -0.1997, -0.1184, -0.0685, -0.0065, -0.0163,\n",
      "        -0.1178, -0.0734, -0.0636, -0.0161, -0.0740, -0.0548, -0.0844,  0.0289,\n",
      "        -0.0977, -0.1524, -0.0210, -0.0367, -0.0047, -0.0516,  0.0056, -0.1249,\n",
      "        -0.0122, -0.0030, -0.0090, -0.0565, -0.0257, -0.0202, -0.0348, -0.0309,\n",
      "        -0.0973, -0.0166, -0.0217, -0.0219, -0.1152, -0.0233, -0.0352, -0.0315,\n",
      "        -0.0682, -0.0806, -0.0358,  0.0139, -0.0976, -0.0306,  0.0084, -0.0580,\n",
      "        -0.0968, -0.0316, -0.0817,  0.0292, -0.0159, -0.0203, -0.0584,  0.0065],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0478,  0.0843, -0.0045,  ..., -0.1126,  0.0100, -0.1312],\n",
      "        [ 0.0614, -0.0850,  0.0222,  ...,  0.0971, -0.0091, -0.0462],\n",
      "        [ 0.0094, -0.0800, -0.0263,  ...,  0.0733, -0.0021, -0.0805],\n",
      "        ...,\n",
      "        [ 0.0058, -0.0134, -0.0618,  ...,  0.0512, -0.0206,  0.0906],\n",
      "        [-0.0079, -0.0339,  0.0411,  ...,  0.0113,  0.0784, -0.0938],\n",
      "        [ 0.0122,  0.0070, -0.0295,  ..., -0.0315,  0.0162,  0.0491]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0541,  0.0465,  0.0656,  ...,  0.0069,  0.0439, -0.0325],\n",
      "        [-0.0122, -0.0113,  0.0166,  ...,  0.0099, -0.0400,  0.0104],\n",
      "        [ 0.0479,  0.0712,  0.0470,  ..., -0.0112,  0.0208,  0.0037],\n",
      "        ...,\n",
      "        [ 0.0556, -0.0118, -0.0491,  ...,  0.0662,  0.0117, -0.0296],\n",
      "        [-0.0412,  0.0500, -0.0623,  ...,  0.1249, -0.0208,  0.0054],\n",
      "        [ 0.0469,  0.0015, -0.0201,  ..., -0.0479, -0.0720, -0.0062]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0259,  0.0327, -0.0232,  ...,  0.0234,  0.0410, -0.0323],\n",
      "        [ 0.0520, -0.0692,  0.0170,  ...,  0.0531, -0.0347, -0.0891],\n",
      "        [-0.0231,  0.0287, -0.0231,  ...,  0.0696, -0.0046, -0.0536],\n",
      "        ...,\n",
      "        [-0.0259, -0.0505,  0.0204,  ..., -0.0908,  0.0497, -0.0445],\n",
      "        [-0.0357, -0.0456, -0.0479,  ..., -0.0521, -0.0133, -0.0392],\n",
      "        [ 0.0355, -0.0168,  0.0525,  ...,  0.0228,  0.0195, -0.0008]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0341,  0.0422,  0.0267,  ..., -0.0230,  0.0585,  0.0232],\n",
      "        [-0.0221,  0.0051,  0.0490,  ..., -0.0537, -0.0403,  0.0006],\n",
      "        [-0.0397, -0.0030, -0.0412,  ..., -0.0079, -0.0266,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0239,  0.0228,  0.0398,  ..., -0.0134, -0.0295,  0.0514],\n",
      "        [ 0.0027, -0.0075, -0.0001,  ..., -0.0440, -0.0312, -0.0499],\n",
      "        [ 0.0170,  0.0137, -0.0499,  ..., -0.0537,  0.0233,  0.0395]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0201, -0.0783, -0.0158,  ..., -0.0316, -0.0104,  0.0049],\n",
      "        [-0.0453,  0.0072, -0.0187,  ...,  0.0152, -0.0857,  0.1844],\n",
      "        [ 0.0143,  0.0378, -0.0037,  ..., -0.0913, -0.0944, -0.0396],\n",
      "        ...,\n",
      "        [-0.0142, -0.0385,  0.0268,  ...,  0.0182,  0.0429, -0.0504],\n",
      "        [ 0.0750,  0.0237,  0.0099,  ..., -0.0460, -0.0181, -0.0359],\n",
      "        [ 0.0255,  0.0057,  0.0250,  ..., -0.0450, -0.0438, -0.0264]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.1718e-02, -2.9917e-02,  1.1328e-01,  ..., -4.7791e-02,\n",
      "          4.3975e-02,  5.7743e-03],\n",
      "        [-6.0521e-02, -6.2392e-03,  2.7477e-02,  ..., -7.8585e-02,\n",
      "          4.4350e-02, -2.5286e-02],\n",
      "        [ 1.8577e-02,  3.7234e-02, -8.0172e-02,  ...,  7.5171e-02,\n",
      "         -1.5546e-02,  1.5149e-03],\n",
      "        ...,\n",
      "        [-3.0656e-02,  1.7677e-03, -4.9488e-02,  ..., -2.1687e-02,\n",
      "         -9.1418e-02, -4.2466e-02],\n",
      "        [ 6.0193e-02,  5.5207e-05, -5.5696e-02,  ...,  9.0077e-02,\n",
      "          4.1767e-02,  3.5368e-02],\n",
      "        [-2.8868e-02,  6.0010e-03,  1.4400e-02,  ..., -7.2626e-03,\n",
      "         -3.0722e-02, -2.8360e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0203, 0.9846, 0.9711, 1.0169, 0.9293, 1.0052, 0.9815, 0.9895, 0.9752,\n",
      "        0.9350, 1.0009, 0.9243, 0.9632, 1.0446, 1.0186, 0.8763, 1.0156, 0.9318,\n",
      "        0.9231, 1.0291, 0.9495, 0.9874, 0.9091, 1.0035, 1.0439, 1.0448, 0.9374,\n",
      "        1.0445, 1.0330, 0.9930, 0.9654, 0.9783, 1.0211, 0.9334, 0.9830, 0.9031,\n",
      "        0.9863, 0.9511, 0.8834, 1.0043, 0.8925, 0.9457, 1.0001, 0.9789, 1.0367,\n",
      "        0.9436, 0.9713, 0.9205, 0.9395, 0.9544, 1.0225, 0.9123, 1.0011, 0.9583,\n",
      "        1.0049, 1.0392, 0.9739, 0.9612, 1.0191, 0.9718, 0.9381, 0.9333, 0.9808,\n",
      "        0.9638, 0.9449, 0.9657, 0.9677, 0.9366, 1.0206, 0.9072, 0.9920, 1.0002,\n",
      "        0.9812, 0.9566, 0.9943, 1.0053, 1.0580, 0.7846, 1.0194, 0.9506, 0.9523,\n",
      "        1.0072, 0.9801, 1.0518, 0.9972, 0.9716, 1.0348, 1.0502, 0.9627, 1.0481,\n",
      "        1.0004, 1.0366, 0.9956, 0.9905, 0.9960, 0.9529, 0.9982, 0.9506, 0.9107,\n",
      "        1.0335, 0.9717, 0.9009, 1.0283, 0.9292, 0.9971, 0.9508, 1.0752, 1.0745,\n",
      "        0.9863, 1.0179, 0.9834, 1.0503, 0.9969, 0.9947, 0.9284, 0.9417, 0.8732,\n",
      "        1.0065, 0.9524, 1.0196, 0.7311, 0.9553, 0.9057, 1.0092, 0.9561, 0.9499,\n",
      "        0.9547, 0.9643, 0.9644, 0.9533, 0.9827, 0.9512, 1.0083, 0.9953, 1.0189,\n",
      "        1.0225, 0.9332, 0.9627, 1.0391, 0.9884, 0.9025, 0.9990, 0.9835, 1.0311,\n",
      "        0.8946, 0.9747, 0.9799, 1.0410, 1.0049, 1.1267, 1.0308, 0.8573, 1.0043,\n",
      "        0.9943, 1.0141, 1.0408, 0.9793, 1.0511, 0.9384, 0.9666, 0.9746, 0.9524,\n",
      "        0.9914, 1.0685, 0.9564, 1.0088, 1.0103, 0.9964, 0.9967, 0.9346, 1.0450,\n",
      "        0.9145, 1.0118, 0.9738, 0.9341, 0.9924, 1.0213, 0.9806, 0.9769, 0.9603,\n",
      "        1.0067, 0.9890, 0.8792, 0.8935, 0.9789, 1.0075, 0.9436, 0.9651, 1.0172,\n",
      "        0.9312, 0.8917, 0.9160, 0.9978, 0.9689, 0.9569, 0.9945, 0.9977, 0.9848,\n",
      "        1.0076, 0.9555, 1.0318, 0.9624, 0.9892, 0.9091, 1.0826, 0.9657, 1.0090,\n",
      "        1.0321, 0.8987, 0.9323, 0.9936, 0.9657, 0.9100, 0.9710, 0.9118, 0.9947,\n",
      "        0.9136, 0.9074, 0.9526, 0.9376, 0.9414, 0.9801, 0.9953, 1.0306, 0.9471,\n",
      "        0.9944, 0.9591, 0.9843, 1.0093, 1.0505, 0.9693, 1.0053, 1.0057, 0.9898,\n",
      "        0.9783, 0.9040, 0.7180, 1.0015, 1.0297, 1.0009, 0.9546, 0.9367, 1.0259,\n",
      "        1.0012, 0.9889, 0.9954, 0.9798, 1.0147, 1.0333, 0.9762, 1.0090, 1.0381,\n",
      "        0.9801, 0.9824, 1.0186, 1.1404], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 3.8119e-03,  3.8177e-02,  6.9990e-03,  9.6894e-03,  3.2399e-02,\n",
      "        -1.3644e-03, -4.8806e-03,  6.8410e-02,  1.7166e-02,  3.2262e-03,\n",
      "         2.7393e-03, -6.6631e-02,  3.3775e-02, -8.5258e-03,  7.1445e-03,\n",
      "         8.6662e-02,  7.6505e-03, -4.5709e-02, -9.0950e-03,  2.0194e-05,\n",
      "         7.5295e-03, -2.0260e-02,  8.8317e-04,  3.5465e-02,  9.7334e-03,\n",
      "         3.0819e-03, -1.4679e-04,  1.4542e-02,  1.8430e-02, -8.0988e-03,\n",
      "         9.2232e-02,  1.1906e-02,  1.5666e-02, -3.9719e-02,  3.6477e-03,\n",
      "         8.6168e-02, -8.4069e-03,  1.0302e-02,  4.7644e-02, -5.4905e-03,\n",
      "         6.0974e-02,  6.3192e-03,  9.7393e-03,  1.4286e-02,  6.9951e-03,\n",
      "         8.8925e-03,  9.7275e-03, -3.8403e-02,  9.1441e-02,  4.6654e-03,\n",
      "         7.2840e-03,  2.9561e-02,  1.4041e-03,  5.1609e-02, -9.5644e-04,\n",
      "         6.6798e-03,  1.0907e-02, -1.5502e-02,  1.3618e-02, -1.5326e-04,\n",
      "        -3.7344e-02, -5.2697e-03,  2.8573e-02,  1.5249e-02, -1.8482e-02,\n",
      "        -6.9354e-03, -5.3455e-03,  9.0002e-03,  6.3409e-03, -7.7744e-03,\n",
      "         2.9200e-04,  1.0547e-02,  2.2675e-02,  9.3820e-04, -2.6732e-03,\n",
      "         6.3204e-03,  5.2683e-03,  8.2943e-02, -2.6117e-03,  4.5462e-02,\n",
      "         7.4704e-03,  6.8631e-03,  2.9774e-02,  7.0087e-03,  2.5336e-02,\n",
      "         2.4416e-03,  4.8261e-03,  9.6204e-04,  3.0736e-02,  7.3701e-02,\n",
      "         7.2476e-03,  2.1270e-02,  6.2218e-02, -6.2100e-04,  4.7690e-03,\n",
      "         1.7456e-02, -6.9976e-04, -7.4280e-03,  5.0970e-02, -4.8748e-03,\n",
      "         2.4107e-03,  7.0591e-02, -1.8391e-02,  5.1744e-03,  2.0186e-02,\n",
      "         2.4474e-02,  7.3639e-03, -1.6508e-02, -3.5281e-03,  9.7725e-03,\n",
      "         2.7233e-02,  7.0440e-03, -6.5758e-03,  6.1620e-03, -1.1705e-02,\n",
      "         8.9157e-03,  5.7994e-02,  1.6628e-02, -1.9291e-02,  8.7073e-03,\n",
      "         1.4002e-01, -1.5261e-02, -6.0971e-02,  1.0134e-02,  1.5064e-02,\n",
      "         5.7091e-03,  7.4294e-03, -1.4062e-02,  3.4883e-02, -1.7965e-02,\n",
      "         5.6805e-02,  6.0898e-02,  1.6685e-02,  7.5363e-03, -3.0483e-03,\n",
      "         3.9367e-02, -2.5033e-03,  3.8646e-03, -4.7480e-03,  4.0575e-03,\n",
      "         8.3123e-02, -4.6954e-03,  1.3721e-02,  1.6572e-02, -1.2756e-02,\n",
      "         8.8422e-03,  9.8259e-03,  1.5537e-02,  4.2639e-02,  9.7967e-03,\n",
      "         2.3998e-02,  5.1640e-02,  5.7774e-02,  3.1030e-03,  6.3810e-03,\n",
      "         1.7521e-03,  7.8181e-03,  1.1055e-02, -3.8346e-02,  3.8536e-02,\n",
      "         3.7980e-02,  4.0273e-02, -2.0505e-02,  1.6925e-02,  3.5149e-02,\n",
      "         3.6797e-03,  2.4929e-03,  1.9278e-02,  4.6049e-03,  6.0404e-03,\n",
      "         3.6845e-03, -1.5401e-02,  2.0606e-02, -2.4169e-03,  5.5259e-04,\n",
      "        -5.2640e-03,  4.1190e-03,  1.1197e-02,  7.2244e-03, -3.3977e-03,\n",
      "        -1.6614e-02,  1.4606e-02,  4.2816e-02,  4.4576e-05,  1.3844e-02,\n",
      "         1.4159e-02,  4.0675e-02, -2.6011e-02,  2.0269e-02, -4.9863e-02,\n",
      "         2.8227e-02,  1.3006e-02,  6.0640e-03,  2.1583e-02, -3.6190e-02,\n",
      "         1.9728e-02, -2.9418e-03,  4.8121e-03,  1.6678e-03, -3.2749e-02,\n",
      "         7.7263e-03,  3.3800e-03,  3.9833e-03,  7.9649e-02,  1.3149e-02,\n",
      "         1.5028e-02, -1.3953e-03,  1.6469e-02, -2.8904e-02,  5.5175e-02,\n",
      "         1.3821e-02,  8.1063e-02,  7.1393e-03,  7.8546e-04, -5.4417e-02,\n",
      "        -4.8526e-05, -4.3056e-02,  8.3698e-02,  7.8085e-02,  1.8310e-02,\n",
      "         2.0470e-02,  1.2070e-02,  1.4483e-02, -4.0071e-03,  4.8631e-04,\n",
      "         1.5598e-02,  4.9331e-02,  1.2767e-03,  1.9493e-02,  9.7790e-03,\n",
      "         9.6202e-03,  4.2961e-02,  3.1150e-03,  1.6037e-02,  3.5686e-02,\n",
      "         4.9998e-02,  1.2299e-01,  1.4720e-02,  2.4978e-03,  9.9469e-03,\n",
      "        -4.6121e-02,  2.0983e-02, -9.3273e-03,  1.8835e-02, -2.4883e-02,\n",
      "         4.9889e-03,  1.1675e-02,  1.0383e-02,  5.0157e-04,  1.3499e-02,\n",
      "         3.0895e-03,  1.9035e-02,  2.9473e-02,  1.6928e-02,  5.2337e-03,\n",
      "         9.4246e-03], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9733, 1.0027, 0.9557, 1.0443, 0.9892, 0.9310, 1.0437, 0.9789, 0.9965,\n",
      "        1.0584, 1.0221, 0.8529, 1.0026, 0.8984, 0.9499, 0.9821, 0.9979, 0.8598,\n",
      "        1.0233, 0.9218, 1.0277, 0.9213, 1.0439, 0.9235, 1.0281, 0.9440, 1.0004,\n",
      "        1.0454, 0.9323, 1.0451, 1.0153, 1.0455, 0.9668, 0.8503, 0.9552, 0.9884,\n",
      "        0.8971, 0.9888, 0.8962, 0.9158, 0.9481, 1.0350, 0.9668, 0.9888, 0.9912,\n",
      "        1.0376, 1.0022, 0.8496, 1.0175, 1.0201, 1.0331, 1.0742, 1.0384, 0.9810,\n",
      "        0.9277, 0.9697, 0.9263, 0.7099, 1.0221, 1.0451, 0.8303, 1.0599, 1.0003,\n",
      "        1.0709, 0.8381, 0.9525, 0.9794, 1.0476, 1.0224, 0.7879, 1.0245, 0.9660,\n",
      "        0.9686, 1.0136, 0.9974, 1.0324, 1.0275, 1.0897, 0.9519, 0.9833, 1.0475,\n",
      "        1.0666, 0.9990, 1.0472, 0.9997, 0.9470, 0.9503, 1.0263, 0.9226, 0.9135,\n",
      "        0.9455, 0.8716, 0.9980, 1.0459, 1.0315, 1.0258, 1.0177, 0.9576, 1.0565,\n",
      "        1.0188, 1.0003, 1.0224, 0.9448, 1.0223, 0.9069, 1.0331, 1.0285, 1.0269,\n",
      "        1.0192, 1.0554, 1.0070, 0.9463, 0.9299, 1.0197, 1.0245, 1.0490, 1.0407,\n",
      "        1.0394, 0.9485, 1.0242, 0.9906, 0.9552, 0.7494, 1.0244, 1.0427, 0.8512,\n",
      "        1.0427, 1.0551, 0.9898, 0.9516, 1.0033, 0.9941, 1.0372, 1.0295, 1.0015,\n",
      "        1.0626, 1.0318, 1.0363, 0.9558, 1.0060, 0.9937, 1.0330, 1.0581, 1.0463,\n",
      "        0.8594, 0.9867, 1.0448, 0.9799, 1.0041, 1.0203, 0.8757, 0.9255, 0.8565,\n",
      "        1.0146, 0.9760, 1.0114, 1.0477, 0.9632, 0.9027, 1.0455, 0.9955, 1.0202,\n",
      "        0.8959, 1.0305, 0.9984, 0.9193, 0.8957, 1.0390, 0.9299, 1.0228, 1.0483,\n",
      "        0.9754, 0.9913, 0.9479, 1.0692, 1.0415, 1.0185, 0.9507, 1.0015, 1.0484,\n",
      "        0.9781, 0.9947, 1.0581, 1.0276, 0.9940, 1.0334, 1.0223, 0.8275, 0.9422,\n",
      "        0.7958, 1.1793, 1.0420, 0.9837, 0.9857, 0.8771, 0.9274, 0.9796, 1.0078,\n",
      "        0.9680, 0.8745, 1.0436, 0.9954, 1.0476, 0.9980, 0.8923, 1.0512, 1.0141,\n",
      "        1.0232, 0.9511, 0.9494, 0.9828, 1.0356, 1.0605, 1.0469, 0.8958, 1.0386,\n",
      "        0.8372, 0.8822, 1.0147, 1.0593, 1.0089, 1.0394, 1.0465, 0.8916, 1.0458,\n",
      "        1.0134, 0.9858, 0.9682, 1.0051, 1.0258, 1.0037, 1.0062, 0.9842, 1.0336,\n",
      "        0.9829, 1.0189, 1.1003, 1.0377, 1.0345, 1.0167, 0.8824, 1.0524, 0.9297,\n",
      "        1.0297, 0.9081, 1.0503, 1.0418, 0.9281, 0.9492, 1.0350, 0.9559, 1.0343,\n",
      "        1.0962, 1.0532, 0.9504, 1.0356], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 9.8037e-03, -4.5734e-03,  2.0086e-02, -7.1697e-02,  7.3941e-02,\n",
      "        -7.6357e-02,  7.9367e-02, -1.5723e-02, -1.4078e-02,  8.4158e-02,\n",
      "        -2.6998e-02, -9.3423e-02, -1.7850e-02, -1.5136e-01, -4.5721e-02,\n",
      "        -7.9614e-02, -4.3582e-02, -1.4565e-01,  8.4617e-02, -6.5437e-02,\n",
      "         8.8263e-02, -7.3389e-02,  1.0453e-01, -4.8395e-02,  1.1069e-01,\n",
      "         1.0123e-02,  6.8063e-02,  8.9341e-02,  1.8033e-03,  1.0659e-01,\n",
      "        -1.1968e-02,  6.4729e-02, -6.6243e-02, -9.6450e-02, -5.4023e-03,\n",
      "         4.2557e-03, -1.4886e-01, -2.3066e-02, -9.5487e-02, -4.4663e-02,\n",
      "        -1.9310e-02,  9.5592e-02, -1.4460e-02,  3.9265e-03, -2.7897e-03,\n",
      "         9.2952e-02,  5.9340e-03, -1.5110e-01, -1.2104e-02,  7.8164e-02,\n",
      "         9.5713e-02,  4.7695e-02,  8.0166e-02,  7.1706e-03, -9.2613e-02,\n",
      "        -3.4211e-02, -9.4888e-02, -1.9840e-01, -6.3759e-02,  1.0928e-01,\n",
      "        -2.0735e-01,  6.0623e-02,  8.1811e-03,  8.5857e-02, -1.0723e-01,\n",
      "        -2.0031e-02,  9.3840e-03,  6.4000e-02,  8.9712e-02, -8.6537e-02,\n",
      "        -2.7703e-02,  1.2238e-02, -8.2403e-03,  1.0788e-01,  8.2047e-02,\n",
      "         1.1128e-01,  7.9837e-02,  6.3123e-02, -2.7603e-02,  8.7239e-03,\n",
      "         1.1736e-01,  1.0467e-01,  1.2648e-02,  7.8672e-02, -1.2750e-02,\n",
      "        -3.8797e-02, -1.5372e-02,  8.4026e-02,  4.7397e-02, -3.8353e-02,\n",
      "        -5.6462e-02, -1.4082e-01,  3.4879e-03, -3.1645e-02,  8.7343e-02,\n",
      "         7.8745e-02, -3.7557e-02,  4.2121e-02,  1.1912e-01,  6.8874e-02,\n",
      "         9.5608e-02, -1.5355e-02, -3.5393e-02,  1.0939e-01, -3.1361e-02,\n",
      "         7.9480e-02,  8.7973e-02,  8.5297e-02,  8.3193e-02,  1.0989e-01,\n",
      "        -7.6628e-03,  3.2149e-04, -5.5494e-02,  8.5814e-02,  1.2667e-01,\n",
      "         1.0585e-01,  1.0555e-01,  8.7130e-02,  6.2104e-03,  8.5659e-02,\n",
      "        -8.4753e-02,  6.3898e-02, -1.7935e-01,  9.7714e-02,  1.2325e-01,\n",
      "        -8.9774e-02,  1.1748e-01,  1.2920e-01, -1.1605e-02, -2.4712e-02,\n",
      "        -4.5063e-02, -2.7944e-02,  1.0112e-01, -4.2883e-02,  7.6910e-02,\n",
      "         1.0639e-01,  9.3122e-02,  6.4908e-02, -2.1962e-02,  7.5633e-02,\n",
      "        -1.8397e-02,  1.0557e-01, -5.6854e-02,  1.2175e-01, -3.4773e-02,\n",
      "        -5.1894e-03, -5.5503e-02,  5.6286e-04, -2.7060e-02,  8.6852e-02,\n",
      "        -1.7341e-01, -9.6242e-02, -1.1864e-01,  7.1336e-02, -6.1632e-05,\n",
      "         1.0783e-01, -4.0559e-02, -2.8796e-02, -9.0886e-02,  8.6388e-02,\n",
      "         1.1834e-02,  1.4714e-02, -6.1037e-02,  1.1586e-01, -5.7647e-03,\n",
      "        -1.6563e-02, -5.7306e-02, -3.5009e-02, -1.0409e-01,  1.0387e-01,\n",
      "         1.1092e-01,  4.3635e-02, -1.4342e-02,  5.2153e-03,  7.6263e-02,\n",
      "         1.5220e-01,  9.3629e-02, -4.2170e-02,  6.3143e-03,  1.0219e-01,\n",
      "         5.3132e-02,  2.1087e-02,  1.3682e-01,  9.0442e-02, -4.3146e-02,\n",
      "        -5.7287e-02, -1.3983e-02, -1.8302e-01, -6.7405e-03, -1.4536e-01,\n",
      "         9.4529e-02,  9.1148e-02, -5.6314e-02, -1.0129e-02, -1.6601e-01,\n",
      "         4.1234e-02,  2.9675e-02,  7.8949e-02, -1.4916e-02, -1.1074e-01,\n",
      "         1.0757e-01,  2.3846e-02, -3.0111e-02, -1.9152e-02, -1.2436e-01,\n",
      "         1.0686e-01,  9.7467e-02,  7.4347e-02,  2.5759e-02, -3.7647e-02,\n",
      "        -8.4331e-03, -2.2993e-02,  7.0887e-02,  5.0685e-02, -9.2355e-02,\n",
      "        -4.1922e-02, -1.4808e-01, -7.2227e-02, -1.0971e-02,  1.1178e-01,\n",
      "         8.1408e-02, -5.1114e-02,  8.0935e-02, -1.3932e-01,  5.4874e-02,\n",
      "        -1.5488e-02,  8.1775e-03, -1.2950e-02,  8.5813e-02,  9.4968e-02,\n",
      "         8.2395e-02,  6.4042e-03,  2.8804e-02, -6.4693e-02, -4.4210e-03,\n",
      "        -1.9547e-02,  2.7095e-01,  1.0064e-01,  1.0071e-01,  8.1247e-02,\n",
      "        -7.4531e-02,  8.2953e-02, -4.0602e-02,  7.8867e-02, -6.7902e-02,\n",
      "         1.0515e-01,  9.9464e-02, -9.1957e-02, -5.1141e-03, -4.6425e-02,\n",
      "        -6.8413e-03,  8.1517e-02,  1.2271e-01,  9.3832e-02, -7.3877e-04,\n",
      "         7.9989e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 6.3232e-02,  9.4176e-02, -2.7378e-02,  1.3296e-01, -4.6786e-02,\n",
      "          1.6797e-02, -1.0292e-01,  6.1204e-02,  9.1172e-02, -1.2645e-01,\n",
      "          1.0918e-01,  1.5545e-03,  8.8893e-02,  1.3830e-02,  3.1867e-02,\n",
      "          7.8331e-02,  8.4120e-02, -2.0245e-03, -8.9317e-02,  1.7053e-02,\n",
      "         -9.1429e-02, -1.1840e-02, -1.0047e-01,  3.0139e-02, -1.0851e-01,\n",
      "         -3.0254e-02, -7.2285e-02, -1.1182e-01, -3.2922e-02, -1.3443e-01,\n",
      "          1.0700e-01, -1.2573e-01,  5.7505e-02,  9.1952e-04, -3.5588e-02,\n",
      "          7.2708e-02,  1.2630e-02,  7.9216e-02,  3.1956e-02, -1.5538e-02,\n",
      "          4.1764e-02, -8.5669e-02,  4.2955e-02,  8.5656e-02,  6.9746e-02,\n",
      "         -9.9822e-02,  8.1795e-02, -1.4721e-03,  8.9837e-02, -9.0458e-02,\n",
      "         -1.2615e-01, -1.0777e-01, -1.1566e-01,  7.5089e-02,  1.3620e-02,\n",
      "          4.3608e-02,  1.6570e-02,  4.7459e-03,  9.8996e-02, -1.1492e-01,\n",
      "         -2.0561e-03, -1.2703e-01,  6.5403e-02, -1.0567e-01,  3.7577e-03,\n",
      "         -2.7218e-02,  7.2662e-02, -1.0746e-01, -9.6263e-02, -8.1375e-03,\n",
      "          1.1534e-01,  3.8199e-02,  6.8247e-02, -1.0106e-01, -9.7715e-02,\n",
      "         -1.1602e-01, -1.0226e-01,  1.5447e-01,  3.1782e-02,  7.6241e-02,\n",
      "         -1.0739e-01, -1.3287e-01,  7.3473e-02, -9.8475e-02,  7.7647e-02,\n",
      "         -3.0404e-02,  3.4163e-02, -1.0386e-01, -3.3629e-02,  3.2799e-02,\n",
      "          2.4136e-02,  2.3862e-02,  7.5280e-02,  1.1695e-01, -1.0984e-01,\n",
      "         -9.2902e-02,  1.0754e-01, -3.0189e-02, -1.1858e-01, -1.1398e-01,\n",
      "         -7.7236e-02,  8.2372e-02, -2.1455e-02, -1.0292e-01, -3.7096e-02,\n",
      "         -1.1782e-01, -1.1594e-01, -9.5638e-02, -1.0603e-01, -1.1879e-01,\n",
      "          1.0736e-01, -3.1485e-02,  1.9997e-02, -1.0962e-01, -1.0068e-01,\n",
      "         -9.9118e-02, -1.1641e-01, -1.2441e-01, -3.2005e-02, -9.7436e-02,\n",
      "          1.9242e-02, -3.4930e-02,  2.0731e-03, -1.0371e-01, -1.1866e-01,\n",
      "          2.3822e-02, -1.0294e-01, -1.2926e-01,  8.1595e-02, -2.1729e-02,\n",
      "          9.3400e-02,  6.6026e-02, -1.2006e-01,  1.0486e-01, -6.1769e-02,\n",
      "         -1.0569e-01, -1.1670e-01, -1.2500e-01,  3.0286e-02, -6.0586e-02,\n",
      "          6.2651e-02, -1.1637e-01,  1.3250e-01, -1.1816e-01, -2.0235e-02,\n",
      "          4.8005e-02,  1.0657e-01,  7.2301e-02,  9.9101e-02, -1.0527e-01,\n",
      "          1.9094e-02, -3.0609e-02,  3.5972e-02, -9.4195e-02,  7.4773e-02,\n",
      "         -9.1376e-02,  1.0878e-01,  3.7469e-02,  7.3037e-03, -1.0361e-01,\n",
      "          9.2917e-02,  7.6887e-02, -2.3197e-02, -1.1946e-01,  6.8483e-02,\n",
      "         -2.2930e-02,  3.4878e-02,  1.2324e-01,  2.1323e-02, -9.3279e-02,\n",
      "         -9.8031e-02, -6.2637e-02,  7.0791e-02, -2.5860e-02, -1.2534e-01,\n",
      "         -8.7617e-02, -9.6833e-02,  3.0767e-02,  9.0475e-02, -1.3448e-01,\n",
      "         -7.5578e-02,  7.0264e-02, -1.1413e-01, -8.7459e-02,  6.8869e-02,\n",
      "          9.6845e-02,  8.4672e-02, -2.3667e-03, -1.9085e-02, -8.5534e-05,\n",
      "         -1.6582e-01, -9.2628e-02,  6.5681e-02,  7.9951e-02, -8.0076e-03,\n",
      "         -4.1173e-02, -5.8121e-02, -7.5983e-02,  3.6082e-02, -3.7635e-04,\n",
      "         -1.2867e-01, -6.1377e-02,  1.2952e-01,  7.0369e-02,  1.6732e-02,\n",
      "         -1.1113e-01, -9.0985e-02, -1.1104e-01, -3.6700e-02,  4.2152e-02,\n",
      "          6.6751e-02,  9.4768e-02, -1.3846e-01, -1.0612e-01, -3.0057e-04,\n",
      "          1.2861e-01,  1.1726e-04,  3.7424e-02,  8.1323e-02, -1.0453e-01,\n",
      "         -8.7213e-02,  1.1464e-01, -9.4030e-02,  1.3508e-02, -1.3279e-01,\n",
      "          9.3415e-02,  7.2691e-02,  4.1476e-02, -8.6703e-02, -1.1805e-01,\n",
      "         -9.2914e-02,  9.0189e-02,  6.1025e-02,  1.1359e-01,  6.0345e-02,\n",
      "          7.4145e-02, -9.5465e-02, -1.1383e-01, -1.1616e-01, -1.0821e-01,\n",
      "          2.8034e-03, -1.0514e-01, -1.9063e-02, -9.2613e-02, -9.8147e-03,\n",
      "         -1.1894e-01, -1.0637e-01,  1.5943e-02, -2.1327e-02,  1.0287e-01,\n",
      "         -3.6905e-02, -1.1532e-01, -1.1318e-01, -1.0390e-01, -2.2574e-02,\n",
      "         -1.2387e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0045], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2908,  0.0154, -0.0186, -0.0027,  0.0020,  0.0065,  0.0149,  0.0074,\n",
      "          0.0211, -0.0076, -0.0036, -0.0023,  0.0095]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([3.6522e-05], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# A_GNN 2 layers\n",
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 2\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN_2layer'\n",
    "\n",
    "model2 = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model2.load()\n",
    "\n",
    "for parameters in model2.model.parameters():\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spanalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
