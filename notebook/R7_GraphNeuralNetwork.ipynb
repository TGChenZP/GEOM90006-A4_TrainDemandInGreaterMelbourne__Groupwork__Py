{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = '../'\n",
    "home_directory = '../'\n",
    "\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "from model.model_class.environment import *\n",
    "\n",
    "from model.model_class import GNN\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_train_data = pd.read_parquet('../data/curated/ML_data/gnn_train_data.parquet')\n",
    "gnn_val_data = pd.read_parquet('../data/curated/ML_data/gnn_val_data.parquet')\n",
    "gnn_test_data = pd.read_parquet('../data/curated/ML_data/gnn_test_data.parquet')\n",
    "\n",
    "SA2_gnn_data = pd.read_parquet('../data/curated/ML_data/SA2_gnn_data.parquet')\n",
    "SA2_gnn_data['Station Name'] = SA2_gnn_data['Station Name'].apply(lambda x: '(SA2)'+x)\n",
    "station_inference_gnn_data = pd.read_parquet('../data/curated/ML_data/station_inference_gnn_data.parquet')\n",
    "\n",
    "station_inference_gnn_data = station_inference_gnn_data.rename({'Station_Name': 'Station Name'}, axis=1)\n",
    "inference_data = pd.concat([SA2_gnn_data, station_inference_gnn_data], axis=0)\n",
    "inference_data.drop(columns=['Station_Na'], axis=1, inplace=True)\n",
    "inference_data = inference_data.rename({'Station Name': 'Station_Name'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open npy\n",
    "station_weights_matrix = np.load('../data/curated/ML_data/station_weights_matrix.npy')\n",
    "SA2_weights_matrix = np.load('../data/curated/ML_data/station_weights_withSA2_matrix.npy')\n",
    "\n",
    "with open('../data/curated/ML_features/station_weights_withSA2.json', 'r') as f:\n",
    "    station_weights_withSA2 = json.load(f)\n",
    "\n",
    "with open('../data/curated/ML_features/station_weights.json', 'r') as f:\n",
    "    station_weights = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit SA2_weights_matrix matrix: columns after 223 masked out to 0\n",
    "SA2_weights_matrix[:, 223:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_features = ['log_Total_Demand']\n",
    "non_geospatial_features = ['Weekday', 'mean_rainfall_value', 'has_school',\n",
    "       'has_sport_facility', 'has_shopping_centre', 'has_hospital',\n",
    "       'total_population', ' med_rent_weekly_c2021',\n",
    "       ' med_mortg_rep_mon_c2021', ' med_person_inc_we_c2021',\n",
    "       ' med_famly_inc_we_c2021']\n",
    "label_columns = ['log_Total_Demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFactory(raw_dataset, geospatial_features, non_geospatial_features, label_columns, stations_index, inference = False):\n",
    "\n",
    "    \"\"\" Data Factory of GNN \"\"\"\n",
    "    \n",
    "    geospatial_x_batches = []\n",
    "    non_geospatial_x_batches = []\n",
    "    y_batches = []\n",
    "    masks = []\n",
    "\n",
    "    if inference:\n",
    "        groupby_column = 'Weekday'\n",
    "    else:\n",
    "        groupby_column = 'Business_Date'\n",
    "\n",
    "    for day, daily_df in tqdm(raw_dataset.groupby(groupby_column)):\n",
    "\n",
    "        geospatial_x = np.zeros([len(stations_index), len(geospatial_features)])\n",
    "        y = np.zeros([len(stations_index), len(label_columns)])\n",
    "        mask = np.zeros([len(stations_index), 1])\n",
    "        non_geospatial_x = np.zeros([len(stations_index), len(non_geospatial_features)])\n",
    "\n",
    "        daily_df.set_index('Station_Name', inplace=True)\n",
    "\n",
    "        for station in daily_df.index:\n",
    "\n",
    "            geospatial_x[stations_index[station]] = daily_df.loc[station][geospatial_features] # todo inference. \n",
    "            if not inference:\n",
    "                y[stations_index[station]] = daily_df.loc[station][label_columns]\n",
    "            mask[stations_index[station]] = 1\n",
    "            non_geospatial_x[stations_index[station]] = daily_df.loc[station][non_geospatial_features]\n",
    "                \n",
    "        geospatial_x = np.nan_to_num(geospatial_x)\n",
    "        geospatial_x_batches.append(geospatial_x)\n",
    "        y_batches.append(y)\n",
    "        masks.append(mask.flatten())\n",
    "\n",
    "        non_geospatial_x_batches.append(non_geospatial_x)\n",
    "\n",
    "        \n",
    "    return geospatial_x_batches, non_geospatial_x_batches, y_batches, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [01:11<00:00,  5.34it/s]\n",
      "100%|██████████| 82/82 [00:15<00:00,  5.42it/s]\n",
      "100%|██████████| 82/82 [00:14<00:00,  5.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_geospatial_X_batches, train_non_geospatial_X_batches, train_y_batches, train_masks = DataFactory(gnn_train_data, geospatial_features, non_geospatial_features, label_columns, station_weights)\n",
    "val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks = DataFactory(gnn_val_data, geospatial_features, non_geospatial_features, label_columns, station_weights)\n",
    "test_geospatial_X_batches, test_non_geospatial_X_batches, test_y_batches, test_masks = DataFactory(gnn_test_data, geospatial_features, non_geospatial_features, label_columns, station_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "all_inference_geospatial_X_batches, all_inference_non_geospatial_X_batches, all_inference_y_batches, all_inference_masks = DataFactory(inference_data, geospatial_features, non_geospatial_features, label_columns, station_weights_withSA2, inference = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:16<00:00, 22.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 Train | Loss:  0.0931 | R2:  0.8988| MSE:  0.0928 | RMSE:  0.3047 | MAE:  0.1941 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 83.27it/s]\n",
      "/Users/tg.chenny/Desktop/1. University/2. Masters/9. Geospatial Data Analysis/A4/GEOM90006-A4_TrainDemandInGreaterMelbourne__Groupwork__Py/model/model_class/__template__.py:193: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  val_y_tensor = torch.FloatTensor(val_y).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Val | Loss:  0.0182 | R2:  0.9818| MSE:  0.0182 | RMSE:  0.1348 | MAE:  0.1072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 27.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2 Train | Loss:  0.0246 | R2:  0.9729| MSE:  0.0247 | RMSE:  0.1570 | MAE:  0.1081 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 105.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Val | Loss:  0.0073 | R2:  0.9926| MSE:  0.0073 | RMSE:  0.0856 | MAE:  0.0701 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 28.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3 Train | Loss:  0.0165 | R2:  0.9818| MSE:  0.0166 | RMSE:  0.1289 | MAE:  0.0827 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 118.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Val | Loss:  0.0033 | R2:  0.9966| MSE:  0.0033 | RMSE:  0.0579 | MAE:  0.0462 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4 Train | Loss:  0.0141 | R2:  0.9844| MSE:  0.0142 | RMSE:  0.1192 | MAE:  0.0720 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 111.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Val | Loss:  0.0030 | R2:  0.9970| MSE:  0.0030 | RMSE:  0.0551 | MAE:  0.0471 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5 Train | Loss:  0.0131 | R2:  0.9855| MSE:  0.0132 | RMSE:  0.1148 | MAE:  0.0678 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 119.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Val | Loss:  0.0026 | R2:  0.9974| MSE:  0.0026 | RMSE:  0.0508 | MAE:  0.0396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:14<00:00, 26.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6 Train | Loss:  0.0127 | R2:  0.9860| MSE:  0.0127 | RMSE:  0.1128 | MAE:  0.0667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 104.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Val | Loss:  0.0049 | R2:  0.9951| MSE:  0.0049 | RMSE:  0.0702 | MAE:  0.0623 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 30.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7 Train | Loss:  0.0125 | R2:  0.9862| MSE:  0.0125 | RMSE:  0.1120 | MAE:  0.0655 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 101.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Val | Loss:  0.0035 | R2:  0.9965| MSE:  0.0035 | RMSE:  0.0590 | MAE:  0.0404 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 29.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 8 Train | Loss:  0.0125 | R2:  0.9863| MSE:  0.0125 | RMSE:  0.1120 | MAE:  0.0661 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 93.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0021 | R2:  0.9979| MSE:  0.0021 | RMSE:  0.0459 | MAE:  0.0332 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 9 Train | Loss:  0.0118 | R2:  0.9870| MSE:  0.0119 | RMSE:  0.1090 | MAE:  0.0641 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 104.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Val | Loss:  0.0050 | R2:  0.9949| MSE:  0.0050 | RMSE:  0.0710 | MAE:  0.0627 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:13<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 Train | Loss:  0.0116 | R2:  0.9872| MSE:  0.0116 | RMSE:  0.1079 | MAE:  0.0645 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 109.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Val | Loss:  0.0038 | R2:  0.9962| MSE:  0.0038 | RMSE:  0.0614 | MAE:  0.0449 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:12<00:00, 29.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 Train | Loss:  0.0128 | R2:  0.9859| MSE:  0.0128 | RMSE:  0.1134 | MAE:  0.0676 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 86.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val | Loss:  0.0044 | R2:  0.9956| MSE:  0.0044 | RMSE:  0.0660 | MAE:  0.0501 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 115.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0021 | R2:  0.9979| MSE:  0.0021 | RMSE:  0.0459 | MAE:  0.0332 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 125.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0022 | R2:  0.9975| MSE:  0.0022 | RMSE:  0.0470 | MAE:  0.0343 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 1\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN'\n",
    "\n",
    "model1 = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# train the model (all cells except this one will print training log and evaluation at each batch)\n",
    "best_epoch = model1.fit(train_geospatial_X_batches, train_non_geospatial_X_batches, train_y_batches, train_masks, val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix)\n",
    "print('\\n\\n')\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model1.load()\n",
    "model1.eval(val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix, best_epoch, evaluation_mode = True)\n",
    "model1.eval(test_geospatial_X_batches, test_non_geospatial_X_batches, test_y_batches, test_masks, station_weights_matrix, best_epoch, evaluation_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:23<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 Train | Loss:  0.1195 | R2:  0.8701| MSE:  0.1191 | RMSE:  0.3452 | MAE:  0.2217 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 63.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Val | Loss:  0.0248 | R2:  0.9751| MSE:  0.0248 | RMSE:  0.1576 | MAE:  0.1200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2 Train | Loss:  0.0350 | R2:  0.9617| MSE:  0.0348 | RMSE:  0.1866 | MAE:  0.1311 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 52.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Val | Loss:  0.0204 | R2:  0.9796| MSE:  0.0204 | RMSE:  0.1428 | MAE:  0.0976 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3 Train | Loss:  0.0253 | R2:  0.9722| MSE:  0.0254 | RMSE:  0.1593 | MAE:  0.1069 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:02<00:00, 40.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Val | Loss:  0.0078 | R2:  0.9922| MSE:  0.0078 | RMSE:  0.0884 | MAE:  0.0666 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4 Train | Loss:  0.0211 | R2:  0.9768| MSE:  0.0211 | RMSE:  0.1453 | MAE:  0.0951 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Val | Loss:  0.0182 | R2:  0.9818| MSE:  0.0182 | RMSE:  0.1348 | MAE:  0.1128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5 Train | Loss:  0.0191 | R2:  0.9788| MSE:  0.0192 | RMSE:  0.1387 | MAE:  0.0897 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 55.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Val | Loss:  0.0077 | R2:  0.9923| MSE:  0.0077 | RMSE:  0.0875 | MAE:  0.0636 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 15.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6 Train | Loss:  0.0180 | R2:  0.9801| MSE:  0.0180 | RMSE:  0.1343 | MAE:  0.0859 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 49.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Val | Loss:  0.0072 | R2:  0.9928| MSE:  0.0072 | RMSE:  0.0848 | MAE:  0.0589 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7 Train | Loss:  0.0241 | R2:  0.9733| MSE:  0.0242 | RMSE:  0.1554 | MAE:  0.1012 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 55.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Val | Loss:  0.0091 | R2:  0.9909| MSE:  0.0091 | RMSE:  0.0954 | MAE:  0.0670 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 8 Train | Loss:  0.0181 | R2:  0.9801| MSE:  0.0182 | RMSE:  0.1348 | MAE:  0.0870 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val | Loss:  0.0109 | R2:  0.9890| MSE:  0.0109 | RMSE:  0.1045 | MAE:  0.0707 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:27<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 9 Train | Loss:  0.0173 | R2:  0.9809| MSE:  0.0174 | RMSE:  0.1318 | MAE:  0.0841 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 52.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Val | Loss:  0.0094 | R2:  0.9906| MSE:  0.0094 | RMSE:  0.0967 | MAE:  0.0719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:24<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 Train | Loss:  0.0156 | R2:  0.9829| MSE:  0.0156 | RMSE:  0.1250 | MAE:  0.0767 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 57.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Val | Loss:  0.0071 | R2:  0.9929| MSE:  0.0071 | RMSE:  0.0841 | MAE:  0.0635 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:26<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 Train | Loss:  0.0142 | R2:  0.9843| MSE:  0.0143 | RMSE:  0.1194 | MAE:  0.0741 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 51.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val | Loss:  0.0051 | R2:  0.9948| MSE:  0.0051 | RMSE:  0.0717 | MAE:  0.0536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:24<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 Train | Loss:  0.0141 | R2:  0.9845| MSE:  0.0142 | RMSE:  0.1190 | MAE:  0.0726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 56.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Val | Loss:  0.0047 | R2:  0.9952| MSE:  0.0047 | RMSE:  0.0689 | MAE:  0.0515 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:25<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 Train | Loss:  0.0139 | R2:  0.9846| MSE:  0.0140 | RMSE:  0.1183 | MAE:  0.0716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 54.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val | Loss:  0.0044 | R2:  0.9956| MSE:  0.0044 | RMSE:  0.0663 | MAE:  0.0538 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:24<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 Train | Loss:  0.0144 | R2:  0.9842| MSE:  0.0145 | RMSE:  0.1202 | MAE:  0.0739 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Val | Loss:  0.0057 | R2:  0.9943| MSE:  0.0057 | RMSE:  0.0753 | MAE:  0.0541 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 53.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val | Loss:  0.0044 | R2:  0.9956| MSE:  0.0044 | RMSE:  0.0663 | MAE:  0.0538 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 56.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val | Loss:  0.0043 | R2:  0.9952| MSE:  0.0043 | RMSE:  0.0659 | MAE:  0.0533 \n"
     ]
    }
   ],
   "source": [
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 2\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN_2layer'\n",
    "\n",
    "model2 = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# train the model (all cells except this one will print training log and evaluation at each batch)\n",
    "best_epoch = model2.fit(train_geospatial_X_batches, train_non_geospatial_X_batches, train_y_batches, train_masks, val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix)\n",
    "print('\\n\\n')\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model2.load()\n",
    "model2.eval(val_geospatial_X_batches, val_non_geospatial_X_batches, val_y_batches, val_masks, station_weights_matrix, best_epoch, evaluation_mode = True)\n",
    "model2.eval(test_geospatial_X_batches, test_non_geospatial_X_batches, test_y_batches, test_masks, station_weights_matrix, best_epoch, evaluation_mode = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../output', exist_ok=True)\n",
    "\n",
    "# read in y scale\n",
    "with open('../data/curated/ML_data/y_scaler_gnn.pickle', 'rb') as f:\n",
    "    y_scaler_gnn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 29.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Predicted_Log_Total_Demand</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Unscaled_Predicted_Log_Total_Demand</th>\n",
       "      <th>Unscaled_Predicted_Total_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aircraft</td>\n",
       "      <td>2.885838</td>\n",
       "      <td>0</td>\n",
       "      <td>12.258663</td>\n",
       "      <td>210799.561393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alamein</td>\n",
       "      <td>2.880375</td>\n",
       "      <td>0</td>\n",
       "      <td>12.248887</td>\n",
       "      <td>208748.728791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albion</td>\n",
       "      <td>2.902173</td>\n",
       "      <td>0</td>\n",
       "      <td>12.287896</td>\n",
       "      <td>217052.903606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphington</td>\n",
       "      <td>2.916082</td>\n",
       "      <td>0</td>\n",
       "      <td>12.312788</td>\n",
       "      <td>222523.576722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Altona</td>\n",
       "      <td>2.900282</td>\n",
       "      <td>0</td>\n",
       "      <td>12.284512</td>\n",
       "      <td>216319.642428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>(SA2)Whittlesea</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>1</td>\n",
       "      <td>7.128467</td>\n",
       "      <td>1246.964479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>(SA2)Wollert</td>\n",
       "      <td>-0.413111</td>\n",
       "      <td>1</td>\n",
       "      <td>6.354812</td>\n",
       "      <td>575.254399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>(SA2)Wyndham Vale - North</td>\n",
       "      <td>0.147060</td>\n",
       "      <td>1</td>\n",
       "      <td>7.357303</td>\n",
       "      <td>1567.602840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>(SA2)Wyndham Vale - South</td>\n",
       "      <td>0.052260</td>\n",
       "      <td>1</td>\n",
       "      <td>7.187648</td>\n",
       "      <td>1322.987988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>(SA2)Yarra Valley</td>\n",
       "      <td>-0.044684</td>\n",
       "      <td>1</td>\n",
       "      <td>7.014156</td>\n",
       "      <td>1112.267860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>884 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Station Name  Predicted_Log_Total_Demand  Weekday  \\\n",
       "0                     Aircraft                    2.885838        0   \n",
       "1                      Alamein                    2.880375        0   \n",
       "2                       Albion                    2.902173        0   \n",
       "3                   Alphington                    2.916082        0   \n",
       "4                       Altona                    2.900282        0   \n",
       "..                         ...                         ...      ...   \n",
       "879            (SA2)Whittlesea                    0.019191        1   \n",
       "880               (SA2)Wollert                   -0.413111        1   \n",
       "881  (SA2)Wyndham Vale - North                    0.147060        1   \n",
       "882  (SA2)Wyndham Vale - South                    0.052260        1   \n",
       "883          (SA2)Yarra Valley                   -0.044684        1   \n",
       "\n",
       "     Unscaled_Predicted_Log_Total_Demand  Unscaled_Predicted_Total_Demand  \n",
       "0                              12.258663                    210799.561393  \n",
       "1                              12.248887                    208748.728791  \n",
       "2                              12.287896                    217052.903606  \n",
       "3                              12.312788                    222523.576722  \n",
       "4                              12.284512                    216319.642428  \n",
       "..                                   ...                              ...  \n",
       "879                             7.128467                      1246.964479  \n",
       "880                             6.354812                       575.254399  \n",
       "881                             7.357303                      1567.602840  \n",
       "882                             7.187648                      1322.987988  \n",
       "883                             7.014156                      1112.267860  \n",
       "\n",
       "[884 rows x 5 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions = model2.predict(all_inference_geospatial_X_batches, all_inference_non_geospatial_X_batches, all_inference_masks, SA2_weights_matrix)\n",
    "all_predictions = np.array(all_predictions).flatten()\n",
    "\n",
    "all_predictions_df = pd.DataFrame({'Station Name': list(station_weights_withSA2.keys()) * 2,\n",
    "              'Predicted_Log_Total_Demand': all_predictions,\n",
    "              'Weekday': [0 for _ in range(len(station_weights_withSA2))] + [1 for _ in range(len(station_weights_withSA2))]})\n",
    "all_predictions_df['Unscaled_Predicted_Log_Total_Demand'] = y_scaler_gnn.inverse_transform(all_predictions_df['Predicted_Log_Total_Demand'].values.reshape(-1, 1))\n",
    "all_predictions_df['Unscaled_Predicted_Total_Demand'] = np.exp(all_predictions_df['Unscaled_Predicted_Log_Total_Demand'])\n",
    "all_predictions_df.to_csv('../output/agnn2_predictions.csv', index=False)\n",
    "\n",
    "all_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_25905/2378514990.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  weekday_weekend_scaled_predictions = all_predictions_df[['Station Name', 'Weekday', 'Unscaled_Predicted_Total_Demand']].groupby('Station Name').apply(lambda x: 5/7 * x[x['Weekday'] == 1]['Unscaled_Predicted_Total_Demand'].values[0] + 2/7 * x[x['Weekday'] == 0]['Unscaled_Predicted_Total_Demand'].values[0]).reset_index().rename({0: 'Predicted_Total_Demand'}, axis=1).loc[:218]\n"
     ]
    }
   ],
   "source": [
    "# want 5/7 * weekday = 1 + 2/7 * weekend = 0\n",
    "weekday_weekend_scaled_predictions = all_predictions_df[['Station Name', 'Weekday', 'Unscaled_Predicted_Total_Demand']].groupby('Station Name').apply(lambda x: 5/7 * x[x['Weekday'] == 1]['Unscaled_Predicted_Total_Demand'].values[0] + 2/7 * x[x['Weekday'] == 0]['Unscaled_Predicted_Total_Demand'].values[0]).reset_index().rename({0: 'Predicted_Total_Demand'}, axis=1).loc[:218]\n",
    "weekday_weekend_scaled_predictions.to_csv('../output/agnn2_predictions_weekday_weekend_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 2 tuples correspond to weights for: 'Nearby Train Demand Aggregate', 'Weekday', 'PublicHoliday', 'mean_rainfall_value', 'has_school',\n",
    "       'has_sport_facility', 'has_shopping_centre', 'has_hospital',\n",
    "       'total_population', ' med_rent_weekly_c2021',\n",
    "       ' med_mortg_rep_mon_c2021', ' med_person_inc_we_c2021',\n",
    "       ' med_famly_inc_we_c2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.7480],\n",
      "        [ 0.8614],\n",
      "        [-0.2957],\n",
      "        [ 0.9152],\n",
      "        [-0.2137],\n",
      "        [ 0.1957],\n",
      "        [-0.5804],\n",
      "        [ 0.6436],\n",
      "        [ 0.8857],\n",
      "        [-0.7353],\n",
      "        [ 0.9511],\n",
      "        [ 0.1574],\n",
      "        [ 0.7965],\n",
      "        [ 0.1313],\n",
      "        [ 0.4371],\n",
      "        [-0.1369],\n",
      "        [ 0.7657],\n",
      "        [ 0.1818],\n",
      "        [-0.4912],\n",
      "        [ 0.2355],\n",
      "        [-0.4309],\n",
      "        [-0.0742],\n",
      "        [-0.4500],\n",
      "        [ 0.7314],\n",
      "        [-0.7856],\n",
      "        [-0.5282],\n",
      "        [-0.1489],\n",
      "        [-0.6174],\n",
      "        [ 0.0915],\n",
      "        [-0.9699],\n",
      "        [ 0.9564],\n",
      "        [-0.8120],\n",
      "        [ 0.7544],\n",
      "        [ 0.0969],\n",
      "        [-0.3586],\n",
      "        [ 0.6360],\n",
      "        [ 0.1512],\n",
      "        [ 0.8130],\n",
      "        [ 0.0952],\n",
      "        [-0.2518],\n",
      "        [ 0.3636],\n",
      "        [-0.1584],\n",
      "        [ 0.4639],\n",
      "        [ 0.9584],\n",
      "        [ 0.6344],\n",
      "        [-0.4793],\n",
      "        [ 0.6207],\n",
      "        [ 0.1576],\n",
      "        [ 0.5306],\n",
      "        [-0.6351],\n",
      "        [-0.9789],\n",
      "        [-0.4559],\n",
      "        [-0.7658],\n",
      "        [ 0.8712],\n",
      "        [ 0.2284],\n",
      "        [ 0.4158],\n",
      "        [ 0.2823],\n",
      "        [ 0.0325],\n",
      "        [ 0.7685],\n",
      "        [-0.7233],\n",
      "        [ 0.1120],\n",
      "        [-0.7286],\n",
      "        [ 0.3834],\n",
      "        [-0.3350],\n",
      "        [ 0.3858],\n",
      "        [-0.2896],\n",
      "        [ 0.8218],\n",
      "        [-0.6150],\n",
      "        [-0.6654],\n",
      "        [-0.6569],\n",
      "        [ 0.9181],\n",
      "        [ 0.4638],\n",
      "        [ 0.9742],\n",
      "        [-0.8376],\n",
      "        [-0.9247],\n",
      "        [-0.7963],\n",
      "        [-0.6860],\n",
      "        [ 0.4479],\n",
      "        [ 0.3299],\n",
      "        [ 0.8324],\n",
      "        [-0.5423],\n",
      "        [-0.7033],\n",
      "        [ 0.5341],\n",
      "        [-0.4527],\n",
      "        [ 0.6518],\n",
      "        [-0.1777],\n",
      "        [ 0.5881],\n",
      "        [-0.7532],\n",
      "        [-0.5357],\n",
      "        [ 0.3539],\n",
      "        [ 0.2272],\n",
      "        [-0.2705],\n",
      "        [ 0.6244],\n",
      "        [ 0.7543],\n",
      "        [-0.7389],\n",
      "        [-0.5438],\n",
      "        [ 0.9001],\n",
      "        [-0.3582],\n",
      "        [-0.4361],\n",
      "        [-0.9464],\n",
      "        [-0.5838],\n",
      "        [ 0.2723],\n",
      "        [-0.1280],\n",
      "        [-0.7152],\n",
      "        [ 0.0227],\n",
      "        [-0.6993],\n",
      "        [-0.8433],\n",
      "        [-0.5790],\n",
      "        [-0.8732],\n",
      "        [-0.7008],\n",
      "        [ 1.0029],\n",
      "        [ 0.1832],\n",
      "        [ 0.2839],\n",
      "        [-0.9095],\n",
      "        [-0.6330],\n",
      "        [-0.4013],\n",
      "        [ 0.1517],\n",
      "        [-0.8861],\n",
      "        [-0.4193],\n",
      "        [-0.6039],\n",
      "        [ 0.0422],\n",
      "        [-0.3609],\n",
      "        [-0.0200],\n",
      "        [-0.7038],\n",
      "        [-0.6908],\n",
      "        [-0.6444],\n",
      "        [-0.3024],\n",
      "        [-0.7893],\n",
      "        [ 0.8895],\n",
      "        [-0.1377],\n",
      "        [ 0.8858],\n",
      "        [ 0.3439],\n",
      "        [-0.8487],\n",
      "        [ 0.7581],\n",
      "        [-0.2269],\n",
      "        [-0.3542],\n",
      "        [-0.8239],\n",
      "        [-0.9593],\n",
      "        [ 0.2986],\n",
      "        [-0.1455],\n",
      "        [ 0.3931],\n",
      "        [-0.8354],\n",
      "        [ 0.7744],\n",
      "        [-0.7442],\n",
      "        [-0.0863],\n",
      "        [ 0.1744],\n",
      "        [ 0.5673],\n",
      "        [ 0.8529],\n",
      "        [ 0.9838],\n",
      "        [-0.7752],\n",
      "        [ 0.2441],\n",
      "        [-0.3603],\n",
      "        [-0.1063],\n",
      "        [-0.7611],\n",
      "        [ 0.9658],\n",
      "        [-0.7284],\n",
      "        [ 0.5634],\n",
      "        [ 0.3328],\n",
      "        [ 0.2303],\n",
      "        [-0.5815],\n",
      "        [ 0.9691],\n",
      "        [ 0.1286],\n",
      "        [ 0.1248],\n",
      "        [-0.8681],\n",
      "        [ 0.4477],\n",
      "        [-0.0953],\n",
      "        [-0.5044],\n",
      "        [ 0.8626],\n",
      "        [ 0.1915],\n",
      "        [-0.5998],\n",
      "        [-0.5155],\n",
      "        [-0.0463],\n",
      "        [ 0.5900],\n",
      "        [-0.1722],\n",
      "        [-0.6320],\n",
      "        [-0.3975],\n",
      "        [-0.7074],\n",
      "        [ 0.3644],\n",
      "        [ 0.8219],\n",
      "        [-0.8780],\n",
      "        [ 0.2983],\n",
      "        [ 0.5195],\n",
      "        [ 0.1309],\n",
      "        [-0.3795],\n",
      "        [ 0.5805],\n",
      "        [ 0.5252],\n",
      "        [ 0.3605],\n",
      "        [-0.0965],\n",
      "        [-0.1955],\n",
      "        [ 0.1038],\n",
      "        [-0.1713],\n",
      "        [-0.4231],\n",
      "        [ 0.6613],\n",
      "        [ 0.9112],\n",
      "        [-0.0291],\n",
      "        [-0.2172],\n",
      "        [ 0.0142],\n",
      "        [-0.0497],\n",
      "        [ 0.1960],\n",
      "        [ 0.2744],\n",
      "        [-0.8961],\n",
      "        [-0.3615],\n",
      "        [ 0.8857],\n",
      "        [ 0.4130],\n",
      "        [-0.0171],\n",
      "        [-0.6539],\n",
      "        [-0.6785],\n",
      "        [-0.8685],\n",
      "        [-0.2582],\n",
      "        [ 0.3555],\n",
      "        [ 0.6362],\n",
      "        [ 0.4938],\n",
      "        [-0.8606],\n",
      "        [-0.6264],\n",
      "        [-0.0963],\n",
      "        [ 0.9400],\n",
      "        [ 0.1733],\n",
      "        [-0.1983],\n",
      "        [ 0.4722],\n",
      "        [-0.4384],\n",
      "        [-0.6438],\n",
      "        [ 0.7377],\n",
      "        [-0.5089],\n",
      "        [-0.0572],\n",
      "        [-0.9647],\n",
      "        [ 0.7227],\n",
      "        [ 0.8085],\n",
      "        [ 0.4046],\n",
      "        [-0.6952],\n",
      "        [-0.9654],\n",
      "        [-0.7994],\n",
      "        [ 0.7897],\n",
      "        [ 0.4789],\n",
      "        [ 0.8066],\n",
      "        [ 0.5442],\n",
      "        [ 0.2204],\n",
      "        [ 0.0371],\n",
      "        [-0.7941],\n",
      "        [-0.8501],\n",
      "        [-0.9183],\n",
      "        [ 0.4001],\n",
      "        [-0.5374],\n",
      "        [-0.1303],\n",
      "        [-0.5835],\n",
      "        [-0.0761],\n",
      "        [-0.7134],\n",
      "        [-0.7018],\n",
      "        [ 0.1836],\n",
      "        [-0.2620],\n",
      "        [ 0.6250],\n",
      "        [-0.3314],\n",
      "        [-0.7447],\n",
      "        [-0.0711],\n",
      "        [-0.5034],\n",
      "        [-0.3954],\n",
      "        [-0.9351]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 5.0167e-01, -6.3476e-01,  3.5788e-01,  3.9645e-01,  6.0545e-01,\n",
      "        -7.4394e-01,  5.9680e-01, -4.2694e-01,  3.3063e-01,  8.0761e-01,\n",
      "        -1.5716e-01, -5.7465e-02, -2.1052e-01, -8.0982e-01,  4.3546e-01,\n",
      "        -9.6280e-01,  5.6390e-01,  7.2468e-01,  8.0533e-01, -2.5875e-01,\n",
      "        -8.5796e-01,  2.1450e-01,  4.9602e-01, -9.5693e-01, -2.6814e-01,\n",
      "        -6.6425e-01, -1.3523e-01, -5.3003e-01, -3.9645e-01, -3.6985e-01,\n",
      "        -8.5746e-01,  7.0931e-01,  7.8383e-01, -2.1701e-01, -2.3528e-01,\n",
      "        -4.4880e-01, -8.7585e-01, -9.6980e-01,  3.7967e-01, -6.7660e-01,\n",
      "        -5.6380e-01, -6.5173e-02, -3.1627e-01, -3.1216e-01, -2.9290e-02,\n",
      "        -2.2205e-01, -3.1741e-01, -4.8036e-01, -8.5543e-01,  6.4263e-01,\n",
      "        -3.9151e-01,  2.0404e-01, -3.5548e-01,  9.0282e-02,  9.0554e-01,\n",
      "         4.2505e-01, -8.6445e-01,  3.7683e-01,  8.5848e-01,  2.3235e-01,\n",
      "         6.3878e-01,  8.6629e-01, -1.5501e-01,  1.7871e-01, -6.4441e-01,\n",
      "        -2.6506e-01,  6.7318e-01,  4.7322e-01, -5.9124e-01, -7.9078e-01,\n",
      "        -6.2741e-01, -8.5019e-01, -7.2792e-01, -2.3657e-01,  5.9804e-01,\n",
      "         1.2422e-01, -8.3538e-01, -7.5411e-01,  4.1617e-01, -7.6598e-01,\n",
      "        -1.2935e-01,  4.2147e-01, -4.6305e-01, -1.0490e-01, -1.1126e-01,\n",
      "        -3.8335e-01, -5.0349e-01, -9.6015e-01, -9.1752e-01, -4.8053e-01,\n",
      "         9.1341e-01, -5.7490e-01, -6.5575e-01,  2.1543e-01,  2.2422e-01,\n",
      "         4.4915e-01,  6.7309e-01,  4.9506e-01, -9.9088e-01,  6.5178e-02,\n",
      "         5.4510e-01, -1.1704e-01, -5.7152e-01,  7.9740e-01, -3.6276e-01,\n",
      "        -5.7466e-01, -9.4773e-01,  3.4548e-02,  3.8873e-01,  1.9501e-01,\n",
      "         1.7100e-01, -7.3553e-01, -9.2071e-01, -3.5309e-02,  7.7698e-01,\n",
      "         5.0014e-01, -5.6469e-01, -1.0424e-01, -8.3413e-01, -4.3882e-01,\n",
      "         1.6532e-01,  4.7308e-01,  7.8989e-01, -9.5376e-01,  5.7805e-01,\n",
      "        -6.9705e-01,  3.3588e-01,  7.5066e-01,  1.3877e-02,  8.3136e-01,\n",
      "        -8.0481e-01, -3.5852e-01,  5.0394e-01, -1.8678e-01, -2.0765e-01,\n",
      "        -5.7083e-01,  6.0655e-01,  3.9785e-01,  2.8904e-01, -6.1055e-01,\n",
      "        -7.7891e-01,  8.3013e-02,  2.6576e-01, -4.5440e-01, -3.4589e-01,\n",
      "         6.8531e-01,  5.5812e-02, -3.0129e-02, -2.4441e-01, -9.6357e-01,\n",
      "        -9.1192e-01, -6.7977e-01, -4.9301e-01,  2.5117e-01, -2.8144e-01,\n",
      "        -4.1242e-01,  8.3412e-01,  3.0102e-01,  6.6802e-01, -4.7941e-01,\n",
      "        -3.6868e-01,  3.2701e-01, -6.4619e-01, -6.8606e-01, -7.8854e-02,\n",
      "        -4.0386e-01, -7.9949e-01,  5.3938e-01,  8.0334e-01,  1.1982e-01,\n",
      "        -2.1241e-01, -8.9836e-01, -3.1601e-01,  2.1735e-01,  3.8629e-01,\n",
      "        -3.0720e-02, -4.4094e-01,  4.7364e-01, -7.5722e-01,  5.6219e-01,\n",
      "        -3.3982e-01,  1.2167e-02, -2.2710e-01,  1.0311e-01, -2.5253e-01,\n",
      "         6.5207e-01, -3.5650e-02,  7.3565e-01,  8.9839e-01, -4.7251e-01,\n",
      "        -7.0753e-01,  6.8967e-01,  7.1037e-01, -6.8422e-01, -1.3540e-01,\n",
      "        -9.5641e-01, -7.9393e-01,  1.4942e-01,  2.2257e-01,  1.8849e-01,\n",
      "        -2.9491e-01,  8.2362e-01,  9.3802e-02, -5.5938e-01, -8.5225e-02,\n",
      "         2.0829e-01,  3.0939e-01, -7.4352e-01,  3.1973e-01, -5.1690e-01,\n",
      "        -8.4796e-01, -5.6600e-01,  8.3423e-01,  7.5223e-01,  8.4027e-01,\n",
      "         5.2905e-01,  7.4096e-01, -2.9022e-01, -5.0113e-01,  4.6016e-01,\n",
      "        -5.3152e-01, -6.6357e-01, -2.9640e-01,  1.5863e-01,  4.1387e-01,\n",
      "        -3.3957e-01, -4.9986e-01,  1.1302e-01, -6.1593e-01, -6.8283e-01,\n",
      "         4.3568e-01, -1.7476e-01,  8.2384e-01,  8.3839e-01,  2.7857e-01,\n",
      "         3.0415e-01,  2.0893e-01,  1.4009e-03, -1.2678e-01,  3.6663e-04,\n",
      "         3.3843e-01,  7.9609e-01, -3.5842e-01, -4.4120e-01, -3.1526e-01,\n",
      "        -4.9855e-01,  1.3406e-01,  7.2781e-01,  7.1198e-01,  4.0728e-01,\n",
      "        -8.2374e-01, -5.5811e-01, -2.9468e-01, -2.0784e-01,  6.1108e-02,\n",
      "        -9.5130e-01], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0503,  0.0697, -0.0071,  ...,  0.0105,  0.0081, -0.0068],\n",
      "        [ 0.0347, -0.0534,  0.0549,  ..., -0.0025,  0.0355, -0.0502],\n",
      "        [ 0.0088,  0.0371, -0.0783,  ...,  0.0274,  0.0125, -0.0779],\n",
      "        ...,\n",
      "        [-0.0187, -0.0133, -0.0555,  ...,  0.0088, -0.0150,  0.0847],\n",
      "        [ 0.0170,  0.0064,  0.0131,  ...,  0.0727,  0.0312,  0.0274],\n",
      "        [ 0.0047, -0.0407, -0.0512,  ..., -0.0231,  0.0367, -0.0188]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0326,  0.0683,  0.0565,  ...,  0.0608,  0.0473,  0.0036],\n",
      "        [-0.0068, -0.0339,  0.0042,  ..., -0.1167, -0.0329, -0.0799],\n",
      "        [-0.0062,  0.0992,  0.0282,  ...,  0.1110,  0.0531,  0.1452],\n",
      "        ...,\n",
      "        [ 0.0280,  0.0097, -0.0522,  ...,  0.0765,  0.0563, -0.0327],\n",
      "        [-0.0203,  0.0209, -0.0428,  ...,  0.0471,  0.0039,  0.0325],\n",
      "        [ 0.0449, -0.0069, -0.0388,  ...,  0.0032, -0.0282,  0.0058]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0213,  0.0271, -0.0338,  ...,  0.0195,  0.0511, -0.0225],\n",
      "        [ 0.0537, -0.0522,  0.0095,  ...,  0.0290, -0.0265, -0.0556],\n",
      "        [-0.0073,  0.0604,  0.0082,  ...,  0.0476,  0.0488, -0.0147],\n",
      "        ...,\n",
      "        [-0.0297, -0.0271,  0.0083,  ..., -0.0250,  0.0550, -0.0230],\n",
      "        [-0.0565, -0.0124, -0.0246,  ..., -0.0683,  0.0471, -0.0132],\n",
      "        [ 0.0389,  0.0069,  0.0368,  ...,  0.0278,  0.0350,  0.0194]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0341,  0.0422,  0.0267,  ..., -0.0230,  0.0585,  0.0232],\n",
      "        [-0.0221,  0.0051,  0.0490,  ..., -0.0537, -0.0403,  0.0006],\n",
      "        [-0.0397, -0.0030, -0.0412,  ..., -0.0079, -0.0266,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0239,  0.0228,  0.0398,  ..., -0.0134, -0.0295,  0.0514],\n",
      "        [ 0.0027, -0.0075, -0.0001,  ..., -0.0440, -0.0312, -0.0499],\n",
      "        [ 0.0170,  0.0137, -0.0499,  ..., -0.0537,  0.0233,  0.0395]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0150, -0.0068,  0.0031,  ..., -0.0449,  0.0426, -0.0010],\n",
      "        [-0.0558,  0.0352,  0.0531,  ..., -0.0300, -0.0128,  0.0714],\n",
      "        [-0.0229,  0.0174,  0.0045,  ..., -0.0522, -0.0251, -0.0375],\n",
      "        ...,\n",
      "        [-0.0004, -0.0543,  0.0125,  ..., -0.0050,  0.0446, -0.0268],\n",
      "        [ 0.0143, -0.0467,  0.0400,  ..., -0.0281,  0.0465, -0.0296],\n",
      "        [ 0.0178, -0.0236,  0.0500,  ..., -0.0463, -0.0201,  0.0104]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0469,  0.0333,  0.0405,  ..., -0.0212, -0.0048, -0.0034],\n",
      "        [-0.0169,  0.0143, -0.0284,  ..., -0.0266,  0.0371, -0.0800],\n",
      "        [-0.0223,  0.0910, -0.0409,  ...,  0.0046, -0.0167,  0.0137],\n",
      "        ...,\n",
      "        [-0.0273,  0.0286, -0.0083,  ..., -0.0538, -0.0093, -0.0404],\n",
      "        [ 0.0047,  0.0589, -0.0320,  ...,  0.0125,  0.0052,  0.0600],\n",
      "        [-0.0352, -0.0125,  0.0539,  ..., -0.0078,  0.0140, -0.0439]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9014, 0.9075, 0.8950, 0.9112, 1.0391, 1.0320, 0.9135, 0.9137, 0.9090,\n",
      "        0.9093, 0.9523, 0.9440, 0.9200, 0.9204, 0.9554, 0.9046, 0.9180, 0.9995,\n",
      "        0.9238, 0.9523, 1.0200, 1.0195, 0.9328, 1.0267, 0.9430, 1.1034, 0.8960,\n",
      "        0.9975, 0.9252, 0.9658, 0.9934, 0.9232, 0.9317, 0.9447, 0.8811, 0.8747,\n",
      "        0.9687, 0.9393, 1.0092, 0.9482, 0.8939, 0.9198, 0.9040, 0.9474, 0.9176,\n",
      "        0.9502, 0.8990, 0.9902, 1.0262, 0.8496, 0.9199, 0.9437, 0.9683, 0.9226,\n",
      "        1.1195, 0.9346, 1.0424, 0.9537, 0.9220, 0.8825, 0.9722, 0.8983, 0.8905,\n",
      "        0.8972, 0.9480, 0.8708, 0.9249, 0.8945, 0.9817, 1.0473, 0.9801, 0.8868,\n",
      "        0.9483, 0.9157, 0.8880, 0.9046, 1.0747, 0.9370, 0.9221, 0.9789, 0.9392,\n",
      "        0.8938, 0.9266, 0.8730, 0.9463, 0.9215, 0.9705, 1.0826, 1.0639, 0.8331,\n",
      "        1.0740, 0.9591, 0.9619, 0.9487, 0.8609, 0.8941, 0.9364, 0.9556, 1.0228,\n",
      "        0.9197, 0.9196, 0.9437, 0.9750, 0.9257, 0.9308, 1.0149, 1.0426, 0.8940,\n",
      "        0.9036, 0.8988, 0.9182, 1.0004, 1.0310, 0.9459, 0.9342, 0.9564, 0.9465,\n",
      "        0.9538, 1.0070, 0.9743, 0.9767, 0.9544, 0.9725, 1.0695, 0.8892, 1.0362,\n",
      "        0.9580, 0.9387, 0.9464, 0.9349, 0.9651, 0.9359, 0.8738, 0.9012, 0.9304,\n",
      "        0.9871, 0.8810, 0.8475, 0.9181, 0.9663, 0.9952, 0.9192, 0.9658, 0.9471,\n",
      "        0.9079, 1.0434, 0.8740, 0.9160, 0.9417, 1.0581, 0.9169, 0.9903, 0.9490,\n",
      "        0.8855, 0.9636, 0.9715, 0.8882, 0.9205, 0.9810, 1.0354, 0.9478, 0.9644,\n",
      "        0.9664, 0.9720, 0.9251, 0.9903, 0.9670, 0.9437, 1.0637, 0.8846, 0.9712,\n",
      "        0.8880, 0.9311, 0.9651, 0.8494, 0.9229, 0.9588, 0.8870, 0.9387, 0.9186,\n",
      "        0.9559, 0.9701, 0.9460, 0.9546, 0.9073, 0.8988, 0.9878, 0.9494, 0.8992,\n",
      "        0.9613, 0.9368, 0.9439, 0.9173, 0.9367, 0.9166, 0.9519, 0.9016, 1.0014,\n",
      "        0.9514, 0.9259, 0.9450, 0.9597, 0.9341, 0.8768, 0.9484, 0.8693, 0.8923,\n",
      "        0.9739, 0.9280, 0.9481, 0.9763, 0.9925, 0.8837, 0.9382, 0.9364, 0.9321,\n",
      "        1.0582, 0.9295, 0.8883, 0.9600, 0.9971, 0.9517, 0.9205, 0.9585, 0.8867,\n",
      "        0.9616, 0.9636, 0.9509, 0.9773, 0.9624, 0.8722, 0.9418, 0.8675, 0.9286,\n",
      "        0.9306, 0.9636, 0.9290, 0.9477, 1.0002, 0.9385, 0.9081, 0.9473, 0.9606,\n",
      "        0.9729, 0.9479, 1.0090, 0.8805, 1.0427, 1.0002, 0.9309, 0.9939, 1.0035,\n",
      "        0.9993, 0.9658, 0.9180, 0.9911], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0248,  0.0299,  0.0499,  0.0229, -0.0346, -0.0157, -0.0287,  0.0439,\n",
      "         0.0409, -0.0377,  0.0282,  0.0213,  0.0308,  0.0678,  0.0164,  0.0768,\n",
      "         0.0064, -0.0448, -0.0255, -0.0086, -0.0089, -0.0243, -0.0239,  0.0401,\n",
      "         0.0145,  0.0265,  0.0097,  0.0329,  0.0613, -0.0019,  0.0281, -0.0289,\n",
      "         0.0059, -0.0391,  0.0905,  0.0868, -0.0153,  0.0599, -0.0469,  0.0270,\n",
      "         0.0687, -0.0027,  0.0374,  0.0367,  0.0261,  0.0059,  0.0491, -0.0223,\n",
      "         0.0401, -0.0378, -0.0160, -0.0256, -0.0094,  0.0252, -0.0023,  0.0191,\n",
      "        -0.0092, -0.0549,  0.0113, -0.0267, -0.0416, -0.0331,  0.0626, -0.0430,\n",
      "         0.0418,  0.0928,  0.0155, -0.0344,  0.0154,  0.0174,  0.0350,  0.0779,\n",
      "         0.0418, -0.0160, -0.0373, -0.0246,  0.0357,  0.0727,  0.0096,  0.0299,\n",
      "         0.0098, -0.0231,  0.0481,  0.0156,  0.0385,  0.0165,  0.0444,  0.0055,\n",
      "         0.0557,  0.1161, -0.0396,  0.0539,  0.0411,  0.0184, -0.0304, -0.0196,\n",
      "         0.0175, -0.0245,  0.0609, -0.0086, -0.0309,  0.0460, -0.0180, -0.0259,\n",
      "         0.0393, -0.0031,  0.0309, -0.0366, -0.0325, -0.0357,  0.0294, -0.0164,\n",
      "        -0.0209, -0.0093, -0.0310, -0.0482,  0.0074, -0.0104,  0.0293, -0.0127,\n",
      "        -0.0402, -0.0380, -0.0439,  0.0208, -0.0287,  0.0235, -0.0262, -0.0269,\n",
      "         0.0334, -0.0645,  0.0358,  0.0680, -0.0392,  0.0587,  0.0015,  0.0545,\n",
      "        -0.0351, -0.0438,  0.0212, -0.0449,  0.0028, -0.0222,  0.0259,  0.0036,\n",
      "         0.0181, -0.0369,  0.0325,  0.0427,  0.0436,  0.0222,  0.0438,  0.0572,\n",
      "         0.0442, -0.0314,  0.0221,  0.0255,  0.0137,  0.0237, -0.0401,  0.0223,\n",
      "         0.0428,  0.0060, -0.0360,  0.0104,  0.0155, -0.0415,  0.0494,  0.0498,\n",
      "        -0.0466, -0.0229,  0.0213, -0.0800,  0.0251, -0.0403, -0.0346, -0.0162,\n",
      "         0.0052,  0.0250,  0.0585, -0.0292,  0.0470,  0.0066, -0.0206, -0.0277,\n",
      "         0.0327,  0.0097,  0.0096, -0.0637, -0.0755, -0.0431, -0.0512, -0.0327,\n",
      "         0.0280,  0.0476, -0.0382,  0.0244,  0.0740, -0.0295, -0.0155,  0.0278,\n",
      "        -0.0090, -0.0414,  0.0181,  0.0921, -0.0417, -0.0141, -0.0312,  0.0134,\n",
      "        -0.0453,  0.0526,  0.0230,  0.0711, -0.0333, -0.0296, -0.0786,  0.0117,\n",
      "        -0.0215,  0.0539,  0.0846, -0.0187,  0.0237,  0.0436, -0.0022, -0.0517,\n",
      "        -0.0367,  0.0261,  0.0379,  0.0339,  0.0163,  0.0148, -0.0225,  0.0189,\n",
      "         0.0043,  0.0065,  0.0472,  0.0030, -0.0539,  0.0046, -0.0090, -0.0011,\n",
      "         0.0331, -0.0313,  0.0192,  0.0072,  0.0100,  0.0173, -0.0294, -0.0218,\n",
      "        -0.0224,  0.0312,  0.0570,  0.0158, -0.0091, -0.0030, -0.0135,  0.0060],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0232, 1.0399, 1.0098, 1.0248, 1.0327, 0.9668, 1.0641, 1.0241, 1.0347,\n",
      "        1.0238, 1.0976, 0.9829, 1.0582, 0.9470, 0.9819, 0.9751, 1.0289, 0.9206,\n",
      "        1.0412, 0.8588, 1.0223, 0.9624, 1.0407, 1.0201, 1.0540, 1.0413, 0.9550,\n",
      "        1.0420, 0.9273, 1.0608, 0.9979, 1.0265, 0.9962, 0.9300, 1.0353, 0.9812,\n",
      "        0.9029, 1.0533, 0.8686, 0.9745, 1.0412, 0.9931, 0.9986, 1.0800, 1.0350,\n",
      "        1.0503, 1.0050, 0.9343, 0.9828, 1.0282, 1.0605, 1.0585, 1.0368, 1.0406,\n",
      "        0.9617, 1.0175, 0.9610, 0.8293, 0.9865, 1.0446, 0.7674, 1.0278, 1.0033,\n",
      "        1.0271, 0.9881, 1.0123, 1.0031, 1.0451, 1.0496, 1.0960, 0.9897, 1.0955,\n",
      "        1.0090, 1.0617, 1.0181, 1.0612, 1.0326, 0.9504, 1.0027, 1.0044, 1.0432,\n",
      "        1.0594, 1.0072, 1.0717, 1.0226, 0.9264, 0.9882, 1.0218, 1.0080, 0.9961,\n",
      "        0.9249, 0.9873, 1.0304, 1.0547, 1.0462, 1.0427, 0.9974, 1.0663, 0.9532,\n",
      "        1.0440, 1.0294, 0.9256, 0.9740, 1.0247, 0.9332, 1.0586, 1.0262, 1.0579,\n",
      "        1.0457, 1.0799, 1.0626, 0.8899, 0.9619, 1.0364, 1.0223, 1.0583, 0.9588,\n",
      "        1.0630, 1.0249, 1.0324, 0.8106, 1.0283, 0.8933, 1.0228, 1.0514, 1.0859,\n",
      "        1.0343, 1.0224, 1.0605, 0.9380, 0.9997, 0.9351, 1.0409, 1.0687, 1.0378,\n",
      "        0.9462, 1.0352, 1.0395, 1.0201, 0.9323, 0.9917, 1.0559, 1.0412, 1.0565,\n",
      "        0.9694, 0.9248, 1.0295, 1.0444, 1.0663, 1.0145, 0.9676, 0.9469, 0.9930,\n",
      "        1.0566, 1.0895, 1.0329, 1.0072, 1.0025, 0.9471, 1.0560, 1.0506, 0.9764,\n",
      "        0.8564, 1.0510, 1.0104, 0.9381, 1.0459, 1.0185, 0.9161, 1.0664, 1.0400,\n",
      "        0.8536, 1.0057, 0.9802, 1.0978, 1.0571, 1.0217, 0.9995, 1.0752, 1.0249,\n",
      "        0.8397, 0.9856, 0.9464, 1.0495, 1.0112, 1.0129, 0.9950, 0.9283, 0.9437,\n",
      "        0.8852, 0.8706, 1.0519, 1.0127, 1.0118, 0.8882, 0.9612, 0.9592, 0.9725,\n",
      "        0.9713, 1.0041, 1.0634, 1.0320, 1.0596, 0.9835, 0.9022, 1.0648, 1.0638,\n",
      "        1.0374, 1.0187, 0.9616, 0.9985, 1.0016, 1.0118, 1.0237, 0.9389, 1.0098,\n",
      "        0.8854, 0.9349, 0.9932, 1.0500, 1.0387, 1.0109, 1.0680, 0.9613, 1.0337,\n",
      "        1.0000, 0.9981, 1.0257, 1.0389, 1.0438, 1.0457, 1.0336, 0.9986, 0.9820,\n",
      "        1.0154, 0.9798, 0.8734, 1.0538, 1.0546, 1.0509, 1.0096, 1.0328, 1.0116,\n",
      "        1.0347, 0.9574, 1.0519, 1.0488, 0.9498, 1.0357, 1.0329, 0.9763, 1.0499,\n",
      "        0.9538, 1.0352, 1.0339, 1.0581], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.5676e-02,  5.0667e-02,  1.6916e-01, -3.0488e-02, -2.2617e-02,\n",
      "        -7.8886e-02,  2.2006e-02,  7.8877e-02, -1.5570e-02, -8.4498e-03,\n",
      "         1.8057e-02, -4.6706e-02,  2.8657e-02, -7.0065e-02, -5.4972e-02,\n",
      "        -5.2109e-03, -4.3216e-02, -5.9491e-02,  3.3297e-03, -1.4442e-01,\n",
      "         4.6488e-02, -1.1408e-01,  4.5165e-02,  3.3439e-02,  1.1090e-01,\n",
      "         7.5399e-02, -7.4340e-02,  1.0621e-01, -6.4366e-02,  9.1283e-02,\n",
      "         2.2050e-02, -1.1744e-02, -6.5549e-02, -1.4231e-01,  1.7705e-01,\n",
      "        -4.5289e-02, -1.6645e-01,  4.2450e-02, -1.5469e-01, -3.9019e-02,\n",
      "         7.4277e-02,  3.6001e-03,  3.1441e-03,  1.4024e-02,  3.8915e-02,\n",
      "         8.3529e-02,  6.5144e-02, -1.6903e-01, -1.7443e-02,  1.4053e-02,\n",
      "         8.0949e-02,  8.3900e-02,  7.3119e-02, -3.7733e-03, -1.2820e-01,\n",
      "        -1.8449e-02, -8.9725e-02, -1.1433e-01, -8.2323e-02,  5.9949e-02,\n",
      "        -1.9854e-01, -1.7676e-02,  9.7759e-03,  6.6088e-02, -2.5913e-02,\n",
      "         2.3579e-01, -6.3990e-02,  3.6541e-02,  9.8025e-02,  1.5656e-01,\n",
      "         2.2963e-03,  1.6121e-01,  1.5865e-02,  9.2709e-02, -5.5469e-03,\n",
      "         6.7132e-02,  7.5601e-02,  1.4977e-02, -1.4486e-02,  5.7736e-02,\n",
      "         1.0726e-01,  5.0342e-02,  9.6910e-03,  1.1583e-01,  1.4922e-02,\n",
      "        -1.2607e-01, -1.7852e-02,  8.2428e-02,  1.6439e-02,  1.5413e-01,\n",
      "        -1.8252e-01, -2.8213e-02,  1.4300e-01,  7.5333e-03,  5.6613e-02,\n",
      "         5.0797e-02, -5.6811e-02,  4.5567e-02, -6.9314e-02,  5.1166e-02,\n",
      "         2.5967e-02, -6.2594e-02, -9.3724e-02, -1.4680e-03, -8.5033e-02,\n",
      "         1.2649e-01,  6.5856e-02,  1.0380e-01,  2.4361e-02,  9.5898e-02,\n",
      "        -2.2257e-02, -2.1593e-01, -1.1178e-01,  8.4961e-02, -2.5340e-03,\n",
      "         5.2860e-02, -7.1639e-02,  6.2484e-02,  2.7664e-02,  6.9976e-02,\n",
      "        -1.8282e-01,  3.7642e-02, -6.7878e-02,  7.3310e-02,  3.6874e-02,\n",
      "         1.4408e-01,  3.7661e-02, -8.2399e-03,  1.1131e-02, -4.5119e-02,\n",
      "         1.2813e-02,  4.0039e-02,  2.3021e-02,  2.5137e-02,  3.3084e-02,\n",
      "         1.0205e-02,  6.8133e-03,  2.8170e-02,  7.3415e-03, -8.9527e-02,\n",
      "        -5.2665e-02,  6.3806e-02,  2.8050e-03,  1.1962e-01, -6.0442e-02,\n",
      "        -8.8586e-02,  4.2518e-02,  1.0626e-02,  8.7669e-03,  6.1393e-02,\n",
      "        -3.3728e-02, -6.7572e-02, -4.9945e-03,  5.6894e-02,  2.2497e-02,\n",
      "         6.6319e-02, -6.8822e-02, -3.9190e-03, -1.0617e-01,  9.8993e-02,\n",
      "         2.4960e-02, -6.3727e-02, -5.7753e-02,  1.1079e-01,  2.3337e-02,\n",
      "        -1.2494e-01,  1.2521e-01, -4.5297e-02, -8.0988e-02,  8.6506e-02,\n",
      "         8.0810e-02, -9.3618e-02,  1.6876e-02, -3.9620e-02,  7.9509e-02,\n",
      "         8.6137e-02,  8.0830e-02, -3.6651e-02,  9.7236e-02,  3.7996e-03,\n",
      "        -3.6098e-02, -6.4960e-03, -9.9521e-02,  6.5546e-02,  6.8699e-02,\n",
      "        -4.2811e-02, -2.3881e-02, -3.4293e-02, -1.0998e-02, -7.4663e-02,\n",
      "        -6.1125e-02,  2.4039e-02, -5.1378e-02,  2.2622e-02, -7.3641e-02,\n",
      "        -6.5404e-02,  1.4481e-02, -7.0257e-02, -6.9982e-02, -1.4625e-02,\n",
      "         7.8829e-02, -1.0519e-03, -9.4758e-04,  5.4071e-02, -7.0862e-02,\n",
      "         6.8057e-02,  6.4280e-02,  8.4007e-02,  3.1010e-02, -3.2443e-02,\n",
      "         2.5566e-04, -4.9136e-03, -3.4014e-02,  2.1301e-04, -2.0049e-02,\n",
      "        -5.0332e-02, -9.6982e-02,  4.0018e-02, -2.8802e-02,  4.3889e-02,\n",
      "         6.7674e-02,  3.4618e-02,  1.1352e-01, -1.0951e-01,  1.6555e-02,\n",
      "         2.8241e-02,  1.4370e-02,  5.1999e-02,  8.9632e-02,  8.6408e-02,\n",
      "         3.4434e-02,  7.8874e-03, -7.1891e-02, -6.3838e-02, -5.6339e-03,\n",
      "        -9.1277e-02, -9.6850e-02,  5.8513e-02,  1.0911e-01,  6.1175e-02,\n",
      "        -1.7127e-03, -2.1789e-04,  5.5683e-03,  9.5771e-02, -9.6563e-02,\n",
      "         1.0701e-01,  5.0006e-02, -1.4135e-01,  3.8130e-03, -7.5651e-03,\n",
      "        -4.6542e-02,  9.1578e-02, -1.0749e-01,  5.1978e-02,  8.7930e-02,\n",
      "         7.7075e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 8.8644e-02,  1.1600e-01, -6.5899e-02,  1.0329e-01, -6.7537e-02,\n",
      "         -4.0615e-02, -9.9106e-02,  9.0455e-02,  1.1159e-01, -9.2210e-02,\n",
      "          1.5333e-01,  5.1500e-02,  1.1555e-01,  4.5003e-02,  4.1677e-02,\n",
      "          4.8364e-02,  9.7677e-02,  2.9068e-03, -8.5269e-02,  4.8988e-02,\n",
      "         -7.3755e-02, -1.9590e-02, -8.5678e-02,  9.2542e-02, -1.2285e-01,\n",
      "         -9.0140e-02, -3.5342e-02, -9.9613e-02,  5.4423e-02, -1.3853e-01,\n",
      "          8.5079e-02, -1.0014e-01,  7.2413e-02, -2.5724e-02, -1.0583e-01,\n",
      "          5.3548e-02,  3.6001e-02,  1.1835e-01,  4.4436e-03, -3.0015e-02,\n",
      "         -1.3382e-01, -4.0096e-02,  6.0673e-02,  1.4216e-01,  9.7617e-02,\n",
      "         -9.7280e-02,  7.8228e-02,  2.8739e-02,  5.7145e-02, -8.6317e-02,\n",
      "         -1.3798e-01, -1.0033e-01, -1.0419e-01,  1.0441e-01,  2.9084e-02,\n",
      "          6.8094e-02,  3.8367e-02,  2.9913e-03,  6.5073e-02, -1.0676e-01,\n",
      "          1.7556e-03, -9.2053e-02,  5.9485e-02, -7.3383e-02,  6.1528e-02,\n",
      "         -1.3783e-01,  8.5641e-02, -9.8700e-02, -1.0382e-01, -1.4955e-01,\n",
      "          7.4265e-02, -1.2475e-01,  9.9038e-02, -1.2936e-01, -1.0289e-01,\n",
      "         -1.2686e-01, -9.4936e-02,  4.5347e-02,  5.7377e-02,  8.5324e-02,\n",
      "         -9.8435e-02, -1.1721e-01,  7.1655e-02, -1.0482e-01,  8.2733e-02,\n",
      "         -1.5676e-02,  5.6502e-02, -9.5701e-02, -6.9943e-02, -8.6760e-02,\n",
      "          1.7642e-02, -3.9271e-02,  1.0236e-01,  1.0900e-01, -1.0871e-01,\n",
      "         -9.2140e-02,  8.5970e-02, -9.4304e-02,  3.6158e-02, -1.2410e-01,\n",
      "         -8.7394e-02,  4.7191e-02, -2.9725e-02, -9.2504e-02, -3.1597e-02,\n",
      "         -1.2469e-01, -1.0212e-01, -1.1153e-01, -1.1798e-01, -1.2725e-01,\n",
      "          1.4046e-01,  3.0820e-02,  3.4380e-02, -1.1659e-01, -8.3535e-02,\n",
      "         -9.5607e-02, -3.4454e-02, -1.3376e-01, -7.4290e-02, -9.1341e-02,\n",
      "          4.3964e-03, -6.9796e-02,  1.5637e-03, -8.6362e-02, -1.1159e-01,\n",
      "         -1.3723e-01, -7.0223e-02, -9.2488e-02,  1.2491e-01, -1.9838e-03,\n",
      "          8.5441e-02,  5.8012e-02, -1.1194e-01,  1.2497e-01, -6.6716e-02,\n",
      "         -4.4422e-02, -1.0756e-01, -1.2021e-01,  6.6431e-02, -3.7319e-03,\n",
      "          4.4237e-02, -1.2283e-01,  9.9725e-02, -1.2197e-01, -2.9827e-02,\n",
      "          4.1902e-03,  9.2081e-02,  1.1128e-01,  1.2631e-01, -9.1007e-02,\n",
      "          3.9884e-02,  4.2356e-02, -6.8418e-02, -1.1677e-01,  1.5143e-01,\n",
      "         -9.9159e-02,  6.6108e-02,  6.0356e-02,  1.1317e-02, -1.1305e-01,\n",
      "          1.2921e-01,  3.7518e-02,  1.2544e-04, -1.2618e-01,  7.0808e-02,\n",
      "         -1.0933e-02, -1.1520e-01,  9.3682e-02,  1.2005e-03, -1.1752e-01,\n",
      "         -9.3525e-02,  2.6630e-03,  7.0226e-02, -3.1312e-02, -1.3710e-01,\n",
      "         -1.0209e-01, -9.0733e-02,  5.3225e-02,  1.4606e-01, -1.0346e-01,\n",
      "          2.4054e-02,  4.8780e-02, -3.3252e-02, -9.1670e-02,  8.2629e-02,\n",
      "          6.6182e-02,  4.8562e-02, -2.4370e-03,  3.7571e-04,  3.2804e-03,\n",
      "          8.1414e-04, -8.4269e-02,  7.7304e-02,  9.2997e-02,  5.7456e-04,\n",
      "         -3.2823e-02,  5.1594e-02, -3.4896e-02,  3.2481e-02,  5.4921e-02,\n",
      "         -1.3711e-01, -7.2966e-02,  1.2345e-01, -8.9722e-02, -6.8787e-04,\n",
      "         -1.1055e-01, -1.1495e-01, -1.1485e-01, -6.3227e-02,  4.4472e-02,\n",
      "          6.9111e-02,  6.2097e-02, -9.2186e-02, -8.4019e-02,  7.4778e-05,\n",
      "          9.5938e-02,  2.5477e-03,  4.9157e-02,  4.3295e-02, -9.2333e-02,\n",
      "         -1.0015e-01,  8.7209e-02, -1.1924e-01, -2.3595e-02, -1.1615e-01,\n",
      "          7.1919e-02,  7.5976e-02,  8.4025e-02, -1.0181e-01, -1.2616e-01,\n",
      "         -1.1531e-01,  9.9232e-02,  5.8544e-02,  6.6591e-02,  7.1080e-02,\n",
      "          3.7028e-02,  2.0702e-03, -1.1791e-01, -1.2700e-01, -1.2748e-01,\n",
      "          6.6230e-02, -8.1693e-02, -5.3184e-02, -9.6787e-02, -2.9628e-02,\n",
      "         -1.1575e-01, -1.0341e-01,  2.1037e-02, -6.8231e-02,  8.5764e-02,\n",
      "         -3.4755e-02, -1.1602e-01, -1.8209e-02, -8.5166e-02, -7.9904e-02,\n",
      "         -1.3527e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0707], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3094,  0.0046,  0.0010, -0.0018, -0.0008,  0.0086,  0.0056,  0.0145,\n",
      "          0.0005, -0.0102, -0.0073,  0.0130]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1092], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# A_GNN features\n",
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 1\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN'\n",
    "\n",
    "model1 = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model1.load()\n",
    "\n",
    "for parameters in model1.model.parameters():\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.7566],\n",
      "        [ 0.8149],\n",
      "        [-0.2277],\n",
      "        [ 0.9544],\n",
      "        [-0.1765],\n",
      "        [ 0.1935],\n",
      "        [-0.5477],\n",
      "        [ 0.6236],\n",
      "        [ 0.8285],\n",
      "        [-0.7118],\n",
      "        [ 0.8722],\n",
      "        [ 0.0569],\n",
      "        [ 0.7579],\n",
      "        [ 0.1298],\n",
      "        [ 0.4313],\n",
      "        [-0.1354],\n",
      "        [ 0.7726],\n",
      "        [ 0.1683],\n",
      "        [-0.2830],\n",
      "        [ 0.2171],\n",
      "        [-0.3417],\n",
      "        [-0.0364],\n",
      "        [-0.4924],\n",
      "        [ 0.6870],\n",
      "        [-0.8058],\n",
      "        [-0.3944],\n",
      "        [-0.1358],\n",
      "        [-0.6120],\n",
      "        [ 0.0905],\n",
      "        [-1.0056],\n",
      "        [ 0.9355],\n",
      "        [-0.8550],\n",
      "        [ 0.7969],\n",
      "        [ 0.0743],\n",
      "        [-0.2128],\n",
      "        [ 0.6609],\n",
      "        [ 0.1494],\n",
      "        [ 0.7959],\n",
      "        [ 0.0850],\n",
      "        [-0.1499],\n",
      "        [ 0.3227],\n",
      "        [-0.0836],\n",
      "        [ 0.4428],\n",
      "        [ 0.9318],\n",
      "        [ 0.6178],\n",
      "        [-0.4134],\n",
      "        [ 0.6152],\n",
      "        [ 0.1558],\n",
      "        [ 0.5816],\n",
      "        [-0.5914],\n",
      "        [-0.9899],\n",
      "        [-0.3985],\n",
      "        [-0.7651],\n",
      "        [ 0.8308],\n",
      "        [ 0.2294],\n",
      "        [ 0.3605],\n",
      "        [ 0.2805],\n",
      "        [ 0.0717],\n",
      "        [ 0.7698],\n",
      "        [-0.6997],\n",
      "        [ 0.1164],\n",
      "        [-0.8024],\n",
      "        [ 0.3713],\n",
      "        [-0.3192],\n",
      "        [ 0.3542],\n",
      "        [-0.1724],\n",
      "        [ 0.8833],\n",
      "        [-0.6345],\n",
      "        [-0.6001],\n",
      "        [-0.6197],\n",
      "        [ 0.9095],\n",
      "        [ 0.4400],\n",
      "        [ 0.9533],\n",
      "        [-0.8344],\n",
      "        [-1.0474],\n",
      "        [-0.7927],\n",
      "        [-0.6915],\n",
      "        [ 0.4306],\n",
      "        [ 0.2577],\n",
      "        [ 0.7951],\n",
      "        [-0.5364],\n",
      "        [-0.7271],\n",
      "        [ 0.5288],\n",
      "        [-0.3864],\n",
      "        [ 0.6207],\n",
      "        [-0.1653],\n",
      "        [ 0.5803],\n",
      "        [-0.7539],\n",
      "        [-0.5302],\n",
      "        [ 0.3339],\n",
      "        [ 0.2183],\n",
      "        [-0.2966],\n",
      "        [ 0.6155],\n",
      "        [ 0.6720],\n",
      "        [-0.7378],\n",
      "        [-0.5006],\n",
      "        [ 0.9116],\n",
      "        [-0.2580],\n",
      "        [-0.4436],\n",
      "        [-0.9282],\n",
      "        [-0.5639],\n",
      "        [ 0.3074],\n",
      "        [-0.1265],\n",
      "        [-0.7910],\n",
      "        [ 0.0225],\n",
      "        [-0.6628],\n",
      "        [-0.8263],\n",
      "        [-0.5798],\n",
      "        [-0.8647],\n",
      "        [-0.7099],\n",
      "        [ 1.0533],\n",
      "        [ 0.1811],\n",
      "        [ 0.2775],\n",
      "        [-0.9181],\n",
      "        [-0.7143],\n",
      "        [-0.3422],\n",
      "        [ 0.1499],\n",
      "        [-0.8774],\n",
      "        [-0.4566],\n",
      "        [-0.5941],\n",
      "        [ 0.0057],\n",
      "        [-0.2609],\n",
      "        [-0.0126],\n",
      "        [-0.6305],\n",
      "        [-0.6640],\n",
      "        [-0.5789],\n",
      "        [-0.2809],\n",
      "        [-0.8342],\n",
      "        [ 0.8648],\n",
      "        [-0.1175],\n",
      "        [ 0.8891],\n",
      "        [ 0.3406],\n",
      "        [-0.9365],\n",
      "        [ 0.7378],\n",
      "        [-0.2044],\n",
      "        [-0.2534],\n",
      "        [-0.8056],\n",
      "        [-0.9948],\n",
      "        [ 0.1946],\n",
      "        [-0.1414],\n",
      "        [ 0.4232],\n",
      "        [-0.8204],\n",
      "        [ 0.7664],\n",
      "        [-0.7385],\n",
      "        [-0.1195],\n",
      "        [ 0.1612],\n",
      "        [ 0.5110],\n",
      "        [ 0.8130],\n",
      "        [ 0.9607],\n",
      "        [-0.8060],\n",
      "        [ 0.2413],\n",
      "        [-0.4164],\n",
      "        [-0.1051],\n",
      "        [-0.7626],\n",
      "        [ 0.8960],\n",
      "        [-0.7678],\n",
      "        [ 0.5081],\n",
      "        [ 0.2537],\n",
      "        [ 0.2461],\n",
      "        [-0.5603],\n",
      "        [ 0.9237],\n",
      "        [ 0.1520],\n",
      "        [ 0.1233],\n",
      "        [-0.8838],\n",
      "        [ 0.4113],\n",
      "        [-0.0916],\n",
      "        [-0.4805],\n",
      "        [ 0.9082],\n",
      "        [ 0.1956],\n",
      "        [-0.5726],\n",
      "        [-0.4840],\n",
      "        [-0.0458],\n",
      "        [ 0.5542],\n",
      "        [-0.0950],\n",
      "        [-0.5741],\n",
      "        [-0.3237],\n",
      "        [-0.7560],\n",
      "        [ 0.3316],\n",
      "        [ 0.8098],\n",
      "        [-0.9459],\n",
      "        [ 0.2577],\n",
      "        [ 0.4552],\n",
      "        [ 0.1443],\n",
      "        [-0.4090],\n",
      "        [ 0.5584],\n",
      "        [ 0.5081],\n",
      "        [ 0.3163],\n",
      "        [-0.0654],\n",
      "        [-0.1799],\n",
      "        [ 0.1026],\n",
      "        [-0.1694],\n",
      "        [-0.2249],\n",
      "        [ 0.6256],\n",
      "        [ 0.9000],\n",
      "        [-0.0158],\n",
      "        [-0.2147],\n",
      "        [ 0.0140],\n",
      "        [-0.0239],\n",
      "        [ 0.0803],\n",
      "        [ 0.1370],\n",
      "        [-0.8870],\n",
      "        [-0.2682],\n",
      "        [ 0.8569],\n",
      "        [ 0.3637],\n",
      "        [-0.0076],\n",
      "        [-0.6289],\n",
      "        [-0.6585],\n",
      "        [-0.8608],\n",
      "        [-0.2463],\n",
      "        [ 0.3555],\n",
      "        [ 0.6513],\n",
      "        [ 0.4627],\n",
      "        [-0.9336],\n",
      "        [-0.6332],\n",
      "        [-0.0754],\n",
      "        [ 1.0687],\n",
      "        [ 0.1750],\n",
      "        [-0.2487],\n",
      "        [ 0.4362],\n",
      "        [-0.4158],\n",
      "        [-0.6578],\n",
      "        [ 0.7321],\n",
      "        [-0.4987],\n",
      "        [-0.0509],\n",
      "        [-1.0051],\n",
      "        [ 0.7212],\n",
      "        [ 0.8119],\n",
      "        [ 0.3605],\n",
      "        [-0.6715],\n",
      "        [-0.9524],\n",
      "        [-0.8070],\n",
      "        [ 0.7551],\n",
      "        [ 0.4451],\n",
      "        [ 0.8341],\n",
      "        [ 0.5214],\n",
      "        [ 0.1844],\n",
      "        [ 0.0146],\n",
      "        [-0.8024],\n",
      "        [-0.8524],\n",
      "        [-0.9176],\n",
      "        [ 0.3830],\n",
      "        [-0.6176],\n",
      "        [-0.1323],\n",
      "        [-0.6109],\n",
      "        [-0.0817],\n",
      "        [-0.7018],\n",
      "        [-0.6539],\n",
      "        [ 0.2680],\n",
      "        [-0.2230],\n",
      "        [ 0.6381],\n",
      "        [-0.3622],\n",
      "        [-0.7432],\n",
      "        [-0.0685],\n",
      "        [-0.4170],\n",
      "        [-0.1650],\n",
      "        [-0.9340]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 4.4126e-01, -7.2800e-01,  3.0285e-01,  4.0406e-01,  5.5719e-01,\n",
      "        -7.3544e-01,  5.4709e-01, -4.9732e-01,  2.9402e-01,  7.4479e-01,\n",
      "        -2.0655e-01, -6.5287e-02, -2.8041e-01, -8.0058e-01,  4.0512e-01,\n",
      "        -9.5183e-01,  5.7739e-01,  6.6800e-01,  8.2282e-01, -3.2141e-01,\n",
      "        -9.1318e-01,  1.8321e-01,  4.4627e-01, -1.0568e+00, -2.6844e-01,\n",
      "        -7.7815e-01, -2.1624e-01, -5.8090e-01, -3.9193e-01, -3.2564e-01,\n",
      "        -9.6732e-01,  6.3633e-01,  7.7715e-01, -2.2655e-01, -2.1728e-01,\n",
      "        -4.1171e-01, -8.6585e-01, -9.9443e-01,  3.4912e-01, -6.3977e-01,\n",
      "        -5.9228e-01, -9.5971e-02, -3.9541e-01, -3.5215e-01, -3.6284e-02,\n",
      "        -2.0088e-01, -3.5106e-01, -4.7447e-01, -8.3606e-01,  6.2598e-01,\n",
      "        -4.2945e-01,  1.0224e-02, -3.9962e-01, -2.1674e-02,  9.0919e-01,\n",
      "         3.7571e-01, -8.5303e-01,  3.4209e-01,  8.4561e-01,  1.3224e-01,\n",
      "         6.1631e-01,  8.3672e-01, -1.8139e-01,  5.0279e-02, -6.6233e-01,\n",
      "        -3.1220e-01,  6.8550e-01,  4.5192e-01, -7.1758e-01, -8.6837e-01,\n",
      "        -6.8832e-01, -8.6446e-01, -7.6770e-01, -2.6932e-01,  5.6961e-01,\n",
      "         7.3915e-02, -8.4450e-01, -7.7930e-01,  3.0602e-01, -8.1611e-01,\n",
      "        -1.6435e-01,  3.2465e-01, -5.0939e-01, -2.2100e-01, -1.2854e-01,\n",
      "        -3.3345e-01, -4.9565e-01, -9.9013e-01, -8.8909e-01, -5.3375e-01,\n",
      "         8.4568e-01, -5.4944e-01, -6.6907e-01,  1.1212e-01,  1.2341e-01,\n",
      "         4.5433e-01,  6.4606e-01,  4.1910e-01, -9.8194e-01,  1.8336e-02,\n",
      "         4.9068e-01, -1.2544e-01, -5.6497e-01,  7.7697e-01, -3.5862e-01,\n",
      "        -6.9071e-01, -9.7847e-01, -3.9775e-02,  2.8485e-01,  1.5215e-01,\n",
      "         1.4590e-01, -7.2716e-01, -9.1294e-01, -3.4920e-02,  7.0005e-01,\n",
      "         3.5012e-01, -5.5824e-01, -1.7401e-01, -8.0420e-01, -5.9922e-01,\n",
      "         1.0073e-01,  3.8344e-01,  7.5473e-01, -1.0273e+00,  5.4174e-01,\n",
      "        -8.1564e-01,  2.9309e-01,  7.0063e-01, -4.8814e-02,  7.7699e-01,\n",
      "        -8.5841e-01, -3.7879e-01,  4.9221e-01, -2.8543e-01, -1.6073e-01,\n",
      "        -5.1042e-01,  5.1771e-01,  3.9796e-01,  1.9848e-01, -6.0572e-01,\n",
      "        -7.7816e-01,  2.1132e-02,  2.1232e-01, -5.2909e-01, -3.3128e-01,\n",
      "         6.4818e-01, -2.4853e-02, -3.6467e-02, -2.5769e-01, -9.6403e-01,\n",
      "        -9.0151e-01, -5.9567e-01, -4.8739e-01,  1.5550e-01, -3.4493e-01,\n",
      "        -3.9207e-01,  8.3256e-01,  2.1558e-01,  5.6872e-01, -5.8016e-01,\n",
      "        -4.3973e-01,  2.7092e-01, -6.3881e-01, -7.1114e-01, -1.0398e-01,\n",
      "        -4.0302e-01, -8.2349e-01,  5.2531e-01,  7.6227e-01, -2.9231e-05,\n",
      "        -2.8855e-01, -8.8810e-01, -3.8843e-01,  1.7806e-01,  3.1433e-01,\n",
      "        -2.2186e-01, -4.5706e-01,  3.9689e-01, -8.1467e-01,  5.1131e-01,\n",
      "        -3.9677e-01, -2.5104e-02, -2.5839e-01,  9.4992e-03, -3.1917e-01,\n",
      "         6.1087e-01, -5.8844e-02,  6.9582e-01,  8.5170e-01, -4.6711e-01,\n",
      "        -6.9945e-01,  6.4695e-01,  6.8692e-01, -7.8082e-01, -6.7915e-02,\n",
      "        -9.4548e-01, -7.8489e-01,  6.8508e-02,  2.5321e-01,  1.5227e-01,\n",
      "        -3.7047e-01,  8.0075e-01,  5.8483e-02, -6.3187e-01, -7.2017e-02,\n",
      "         1.4860e-01,  2.4138e-01, -7.8420e-01,  2.8201e-01, -5.3219e-01,\n",
      "        -8.1847e-01, -5.7274e-01,  8.1820e-01,  7.0846e-01,  8.0238e-01,\n",
      "         5.3844e-01,  6.9191e-01, -2.6414e-01, -5.6490e-01,  3.9402e-01,\n",
      "        -5.8609e-01, -6.8594e-01, -3.9193e-01,  1.5061e-01,  3.5205e-01,\n",
      "        -3.5090e-01, -5.4111e-01, -1.4960e-02, -6.1904e-01, -7.0667e-01,\n",
      "         3.5649e-01, -2.4926e-01,  7.8490e-01,  8.3414e-01,  2.1622e-01,\n",
      "         1.8063e-01,  1.6315e-01, -2.2781e-03, -1.6595e-01, -1.5001e-02,\n",
      "         2.5437e-01,  7.7539e-01, -3.5740e-01, -4.1428e-01, -3.3938e-01,\n",
      "        -5.5814e-01, -1.3524e-02,  6.4425e-01,  6.9726e-01,  3.0637e-01,\n",
      "        -7.9062e-01, -5.7374e-01, -3.0084e-01, -2.2994e-01,  9.6759e-03,\n",
      "        -9.6298e-01], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0182, -0.0313, -0.0166,  ...,  0.0305, -0.0026, -0.0298],\n",
      "        [ 0.0715, -0.0239,  0.0677,  ...,  0.0056,  0.0149, -0.0418],\n",
      "        [ 0.0294, -0.0165, -0.0812,  ...,  0.0257,  0.0178, -0.0717],\n",
      "        ...,\n",
      "        [-0.0155, -0.0284, -0.0576,  ...,  0.0167, -0.0092,  0.0728],\n",
      "        [ 0.0379,  0.0176,  0.0238,  ...,  0.0204,  0.0335, -0.0239],\n",
      "        [-0.0153, -0.0660, -0.0577,  ..., -0.0649, -0.0060, -0.0461]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0343,  0.0406,  0.0571,  ...,  0.0560,  0.0595, -0.0181],\n",
      "        [-0.0243, -0.0613, -0.0158,  ..., -0.1946, -0.0323, -0.1466],\n",
      "        [ 0.0454,  0.1082,  0.0486,  ...,  0.1517,  0.0276,  0.2068],\n",
      "        ...,\n",
      "        [ 0.0469, -0.0115, -0.0347,  ...,  0.0187,  0.0084, -0.0590],\n",
      "        [-0.0330,  0.0173, -0.0050,  ...,  0.0228, -0.0474,  0.0110],\n",
      "        [-0.0094,  0.0133, -0.0217,  ...,  0.0181, -0.0104,  0.0429]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0245,  0.0406, -0.0342,  ...,  0.0166,  0.0451, -0.0340],\n",
      "        [ 0.0494, -0.0083,  0.0090,  ...,  0.0233, -0.0325, -0.0594],\n",
      "        [ 0.0062,  0.0497,  0.0066,  ...,  0.0361,  0.0284,  0.0042],\n",
      "        ...,\n",
      "        [-0.0281, -0.0396,  0.0161,  ..., -0.0496,  0.0495, -0.0647],\n",
      "        [-0.0548, -0.0172, -0.0254,  ..., -0.0598,  0.0300, -0.0277],\n",
      "        [ 0.0486,  0.0003,  0.0326,  ...,  0.0073,  0.0053,  0.0149]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0341,  0.0422,  0.0267,  ..., -0.0230,  0.0585,  0.0232],\n",
      "        [-0.0221,  0.0051,  0.0490,  ..., -0.0537, -0.0403,  0.0006],\n",
      "        [-0.0397, -0.0030, -0.0412,  ..., -0.0079, -0.0266,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0239,  0.0228,  0.0398,  ..., -0.0134, -0.0295,  0.0514],\n",
      "        [ 0.0027, -0.0075, -0.0001,  ..., -0.0440, -0.0312, -0.0499],\n",
      "        [ 0.0170,  0.0137, -0.0499,  ..., -0.0537,  0.0233,  0.0395]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0051, -0.0036, -0.0057,  ..., -0.0245,  0.0398,  0.0082],\n",
      "        [-0.0523,  0.0475,  0.0191,  ..., -0.0508, -0.0117,  0.0698],\n",
      "        [ 0.0313,  0.0169, -0.0663,  ..., -0.0474,  0.0034, -0.0462],\n",
      "        ...,\n",
      "        [-0.0019, -0.0699,  0.0289,  ...,  0.0349,  0.0689,  0.0222],\n",
      "        [ 0.0196,  0.0016,  0.0078,  ..., -0.0485,  0.0182, -0.0377],\n",
      "        [ 0.0221, -0.0211,  0.0547,  ..., -0.0630, -0.0391, -0.0050]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0526,  0.0422,  0.1047,  ..., -0.0220, -0.0239,  0.0048],\n",
      "        [ 0.0143,  0.0625,  0.0235,  ..., -0.0391,  0.1035, -0.0485],\n",
      "        [-0.0580,  0.0371, -0.1067,  ..., -0.0086,  0.0615,  0.0234],\n",
      "        ...,\n",
      "        [-0.0302, -0.0149,  0.0048,  ..., -0.0517,  0.0014, -0.0552],\n",
      "        [ 0.0086,  0.0179, -0.0477,  ...,  0.0002,  0.0646,  0.0142],\n",
      "        [-0.0750, -0.0013,  0.0261,  ..., -0.0374,  0.0292, -0.0277]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9096, 0.9458, 0.9114, 0.9008, 0.9246, 0.9390, 0.9260, 0.8927, 0.9128,\n",
      "        0.9137, 0.9466, 0.9179, 0.9671, 0.8971, 0.9497, 0.8824, 0.9108, 1.0058,\n",
      "        0.9394, 0.8898, 0.9803, 0.9830, 0.9592, 1.0451, 0.9438, 1.0312, 0.9017,\n",
      "        0.9422, 0.8798, 0.9268, 1.0138, 0.9356, 0.9034, 0.8999, 0.8357, 0.9166,\n",
      "        0.8906, 0.9815, 0.9991, 0.8724, 0.9066, 0.9357, 0.8640, 0.9958, 0.9418,\n",
      "        0.8775, 0.9260, 0.8861, 0.9523, 0.8857, 0.9460, 0.9269, 0.9180, 0.9807,\n",
      "        1.1097, 0.8899, 1.0146, 0.9917, 0.9011, 0.9148, 1.0265, 0.9145, 0.8644,\n",
      "        0.8319, 0.9079, 0.8186, 0.8735, 0.9498, 0.9679, 1.0239, 0.9861, 0.8835,\n",
      "        0.9537, 0.9089, 0.9217, 0.9090, 1.0389, 0.8970, 0.9281, 0.9332, 0.8854,\n",
      "        0.8765, 0.9180, 0.8752, 0.9927, 0.8837, 0.9460, 1.0008, 1.0332, 0.9292,\n",
      "        1.0293, 0.9297, 0.9171, 0.9145, 0.9008, 0.9424, 0.9145, 0.9479, 0.9407,\n",
      "        0.9240, 0.9326, 0.9039, 0.8794, 0.9242, 0.8462, 0.9454, 0.9517, 0.8924,\n",
      "        0.9155, 0.9478, 0.9277, 0.9866, 0.9671, 0.8958, 0.9306, 0.9073, 0.8993,\n",
      "        0.9237, 0.9210, 0.9860, 0.9810, 0.9499, 1.0150, 1.0931, 0.8989, 0.9766,\n",
      "        0.9654, 0.9482, 0.9358, 0.9919, 0.9705, 0.8892, 0.8991, 0.9615, 0.9456,\n",
      "        0.9226, 0.8868, 0.8577, 0.8416, 0.9549, 0.8828, 0.8681, 0.9478, 0.9461,\n",
      "        0.7857, 1.0053, 0.9346, 0.9290, 0.9507, 1.0630, 0.8467, 0.9492, 0.8902,\n",
      "        0.9111, 0.9643, 0.9303, 0.9049, 0.8872, 0.9111, 1.0070, 0.9857, 0.9180,\n",
      "        0.9778, 0.9761, 0.8898, 1.0357, 1.0012, 0.8910, 1.0121, 0.9503, 0.8770,\n",
      "        0.9464, 0.9306, 0.9057, 0.8492, 0.8461, 0.9494, 0.9556, 0.9938, 0.9073,\n",
      "        0.9218, 0.9406, 0.9063, 0.8416, 0.8700, 0.8518, 0.9702, 1.0175, 1.0152,\n",
      "        0.9467, 0.9209, 0.9449, 0.8696, 0.9425, 0.8713, 0.8669, 0.9147, 0.9212,\n",
      "        0.9309, 0.9225, 0.9403, 0.9491, 0.9345, 0.8730, 0.9760, 0.9314, 0.9205,\n",
      "        0.9283, 0.9029, 0.9111, 0.9434, 0.8950, 0.8798, 0.9282, 0.9958, 0.8753,\n",
      "        1.0220, 0.8376, 0.9164, 0.9573, 0.9275, 0.9355, 0.9205, 0.9228, 0.8696,\n",
      "        0.9935, 0.9493, 0.9184, 0.9965, 0.8881, 0.9251, 1.0234, 0.8476, 0.9024,\n",
      "        0.8913, 0.8104, 0.9105, 0.9384, 0.9448, 0.9291, 0.8773, 0.9364, 0.8939,\n",
      "        0.9182, 0.8711, 0.9798, 0.8845, 0.9685, 0.9912, 0.8809, 0.9255, 0.9912,\n",
      "        0.9032, 0.8697, 0.8884, 0.9834], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.4855e-02,  3.0140e-03,  8.6568e-03,  2.2885e-02, -2.9469e-02,\n",
      "        -7.6030e-04, -3.7813e-02,  4.6861e-02,  3.8823e-02, -4.9965e-02,\n",
      "         2.9287e-02, -3.0747e-02,  3.5959e-02,  5.7324e-02,  1.2933e-02,\n",
      "         9.4957e-02,  2.3175e-03, -5.0685e-02, -2.4561e-02,  5.4636e-02,\n",
      "        -2.7010e-03, -1.0227e-02, -2.7879e-02,  1.2824e-02,  3.6110e-02,\n",
      "         5.0354e-02,  9.5025e-03,  5.1982e-02,  8.5156e-02,  3.1288e-02,\n",
      "         4.2489e-02, -6.0964e-02, -1.6497e-02,  6.7345e-03,  5.3479e-02,\n",
      "         4.2066e-02,  6.7480e-02,  3.3881e-02, -3.6112e-02, -2.3296e-02,\n",
      "         4.6825e-02, -3.3499e-02,  2.7863e-02,  5.1965e-02,  3.3483e-02,\n",
      "        -2.1206e-02,  2.6359e-02,  8.3593e-02,  5.9488e-02, -7.3462e-02,\n",
      "         2.7278e-02,  4.3422e-02,  1.4032e-02,  3.6789e-02, -1.7465e-02,\n",
      "         1.5416e-03, -1.9467e-02, -2.5009e-02,  2.2748e-03, -1.2912e-02,\n",
      "        -1.8570e-02, -7.5919e-02,  6.7868e-02,  9.1783e-03,  1.8488e-03,\n",
      "         1.0557e-01, -2.7672e-03, -4.0284e-02,  4.4436e-02,  3.6662e-02,\n",
      "         2.5325e-02,  2.3568e-02,  4.0235e-02,  3.2119e-02, -4.2911e-02,\n",
      "         1.0596e-02,  5.1774e-02,  7.2135e-02, -8.7798e-04,  3.4492e-02,\n",
      "         2.8165e-02, -1.3353e-02,  1.9013e-02,  5.6244e-02,  4.1004e-02,\n",
      "        -1.1516e-02,  3.0974e-02,  2.6526e-02,  5.8655e-02,  5.8170e-02,\n",
      "        -2.7297e-02,  7.4413e-02,  2.8821e-02,  5.4296e-03, -3.5461e-06,\n",
      "        -1.3290e-02,  2.1667e-02, -3.0643e-02,  8.7416e-02,  3.9651e-02,\n",
      "        -2.5141e-02,  6.2186e-02,  1.1068e-02, -4.1725e-02,  9.2077e-02,\n",
      "         3.4474e-02,  7.9123e-02,  1.9767e-02, -5.2289e-03, -1.3149e-02,\n",
      "         4.2817e-02, -1.7557e-03, -1.4073e-02,  1.8345e-02, -5.0653e-02,\n",
      "         3.6699e-02,  4.6838e-02,  2.6628e-02,  8.7701e-02,  3.7567e-02,\n",
      "         1.8821e-02, -4.2148e-02, -2.9367e-02,  2.9352e-02, -3.9566e-02,\n",
      "         4.0994e-02, -2.0429e-02, -4.0527e-02,  2.5530e-02, -3.8163e-02,\n",
      "         2.3494e-02,  5.7924e-02, -2.0331e-02,  2.3954e-02,  1.3168e-02,\n",
      "         4.7543e-02, -5.3894e-02, -5.1889e-02,  3.2404e-02, -1.7155e-02,\n",
      "         5.5115e-02,  6.4614e-03,  2.4026e-02,  2.4994e-02,  3.7543e-02,\n",
      "        -2.1415e-02,  3.6480e-02,  1.5241e-02,  5.1054e-02,  2.9063e-02,\n",
      "         6.1433e-02,  5.5793e-02,  5.1498e-02, -5.0385e-03,  2.1659e-02,\n",
      "         5.1376e-02, -3.9816e-03,  2.2057e-02, -1.3007e-02,  5.1593e-02,\n",
      "         3.9302e-02,  5.1275e-03, -2.6942e-02,  1.7310e-02,  9.5239e-03,\n",
      "        -1.8354e-02,  4.7332e-02,  4.1218e-02, -4.2977e-02,  1.7233e-02,\n",
      "         5.2446e-02, -9.0691e-05,  1.1972e-02, -3.6534e-02, -6.0585e-03,\n",
      "         5.6127e-02,  4.0291e-02,  1.7830e-02,  2.2139e-02, -3.2082e-02,\n",
      "         4.8199e-02, -1.1390e-02,  3.4597e-02,  3.3093e-02,  3.0234e-02,\n",
      "        -2.2854e-02,  9.6809e-03, -3.4559e-02, -1.7859e-02, -2.4420e-02,\n",
      "        -8.6346e-03, -3.6303e-02,  2.3257e-02,  3.4239e-02,  2.5453e-03,\n",
      "         5.0605e-02,  6.1553e-02,  1.8129e-02, -2.1508e-02, -1.1695e-02,\n",
      "         3.0720e-02, -4.2279e-02,  2.1568e-02,  2.2198e-02, -9.7319e-03,\n",
      "         2.3749e-02, -1.3283e-02,  4.3950e-02, -5.8549e-02,  5.1602e-02,\n",
      "         3.1443e-03,  7.1955e-02, -4.0686e-02, -3.6562e-02, -5.9297e-02,\n",
      "         1.8372e-02, -2.1340e-02,  9.4028e-02,  6.5796e-02, -3.0825e-02,\n",
      "         6.9734e-02,  4.0212e-03,  1.4814e-02, -3.4615e-02, -5.3618e-03,\n",
      "         2.6136e-03,  1.7890e-02,  2.4828e-02,  3.3648e-02,  2.9694e-02,\n",
      "        -2.6000e-02,  1.6316e-02, -3.1173e-02, -1.5981e-02,  2.7495e-02,\n",
      "         6.7657e-02, -9.7680e-04,  2.9696e-02,  8.2362e-03,  4.0310e-02,\n",
      "         3.3850e-03, -5.4235e-02,  4.2202e-02,  2.8698e-02,  4.7921e-02,\n",
      "         4.6687e-02, -1.1975e-02,  2.1105e-03, -1.9416e-02,  2.7552e-02,\n",
      "         7.8970e-02,  2.1501e-02,  2.1637e-02,  2.4403e-02,  1.4717e-02,\n",
      "         3.8872e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9618, 1.0441, 0.7399, 1.0122, 0.6566, 0.8086, 0.9372, 1.0273, 0.9600,\n",
      "        0.8501, 0.9322, 0.9266, 0.9862, 0.6663, 0.9592, 1.0155, 1.0059, 0.9288,\n",
      "        0.8528, 0.9014, 0.9006, 0.9075, 0.9682, 0.9955, 0.9856, 0.8894, 0.7719,\n",
      "        1.0172, 0.9363, 0.9930, 1.0640, 0.9236, 0.9942, 0.9341, 0.8838, 1.0236,\n",
      "        0.9156, 0.9204, 0.9485, 0.9118, 0.8905, 0.8818, 1.0112, 1.0414, 0.9930,\n",
      "        0.8701, 0.9573, 0.9164, 1.0080, 0.9060, 0.9529, 0.8467, 0.9837, 1.0179,\n",
      "        0.9186, 0.9458, 0.7371, 0.9524, 0.9763, 0.9522, 0.9265, 0.9511, 0.9664,\n",
      "        0.9214, 0.9345, 0.7525, 1.0165, 0.9661, 0.9934, 1.0137, 0.9894, 0.6967,\n",
      "        1.0005, 0.9945, 0.9584, 0.9600, 1.0392, 1.0882, 0.9271, 0.9636, 0.9602,\n",
      "        0.9538, 0.9550, 0.9318, 0.8950, 0.8923, 0.8769, 0.9859, 0.9710, 0.8467,\n",
      "        0.8561, 0.8421, 0.9931, 0.9635, 0.9622, 0.9274, 0.9696, 0.8966, 1.0270,\n",
      "        0.9200, 0.9387, 1.0356, 0.9502, 0.9324, 0.8807, 0.9936, 1.0141, 1.0102,\n",
      "        0.9215, 0.9612, 1.0363, 0.8901, 0.7471, 0.9328, 0.9355, 0.8663, 0.9218,\n",
      "        0.9761, 0.9327, 1.0069, 0.9340, 0.9167, 0.8966, 0.8955, 0.9100, 0.9003,\n",
      "        0.9056, 0.9368, 0.9945, 0.9021, 1.0552, 0.9742, 0.9873, 0.9917, 0.9013,\n",
      "        0.9090, 0.8995, 0.9427, 0.9563, 0.9338, 0.7971, 0.9470, 0.9846, 1.0137,\n",
      "        0.7991, 0.9293, 0.9788, 0.9703, 1.0049, 1.0309, 0.8894, 0.8352, 0.8808,\n",
      "        0.9658, 0.9845, 0.9999, 0.9629, 0.9329, 0.9080, 1.0092, 1.0001, 0.8814,\n",
      "        0.9363, 1.0205, 0.9599, 0.8950, 0.9269, 1.0136, 0.9218, 0.9617, 0.9153,\n",
      "        0.8216, 0.8428, 0.9469, 0.9733, 0.8957, 1.0056, 0.8678, 1.0547, 0.9401,\n",
      "        0.7795, 0.9258, 0.9137, 0.9691, 0.9459, 0.9485, 0.9059, 0.9075, 0.8605,\n",
      "        0.9399, 0.9778, 0.7847, 0.9794, 0.9875, 0.8018, 0.7808, 0.7424, 0.8712,\n",
      "        0.9476, 0.8751, 0.9920, 0.8642, 0.9811, 0.9880, 0.9686, 0.9173, 0.9676,\n",
      "        0.9826, 0.9270, 0.7903, 0.9500, 0.7886, 0.9430, 0.9082, 0.9266, 1.0336,\n",
      "        0.9656, 0.8560, 0.9667, 0.9176, 1.0136, 0.9870, 0.9697, 0.9033, 0.9512,\n",
      "        0.9576, 0.9717, 0.9497, 0.9359, 0.9832, 0.9355, 0.9722, 0.8874, 0.9779,\n",
      "        0.9627, 0.8830, 0.9024, 0.9608, 1.0072, 0.9452, 0.9654, 0.9260, 0.9565,\n",
      "        0.9396, 0.7879, 0.9561, 0.9849, 0.8847, 0.8963, 0.9747, 0.7774, 0.9546,\n",
      "        0.9785, 0.9159, 0.9498, 0.9487], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.7922e-02,  3.5110e-02, -2.0445e-01,  4.8639e-02, -2.4520e-01,\n",
      "        -1.4010e-01, -6.4589e-02,  3.1971e-02, -2.3563e-02, -1.0995e-01,\n",
      "        -2.4574e-02, -1.0122e-01,  2.8656e-02, -2.4278e-01, -3.4104e-02,\n",
      "        -1.4829e-01,  2.1852e-02, -9.4571e-02, -1.7489e-01, -4.6590e-02,\n",
      "        -9.2546e-02, -1.3635e-01, -1.1792e-02, -4.1600e-03, -2.2009e-02,\n",
      "        -8.0557e-02, -1.3869e-01,  7.5911e-03, -9.1520e-02,  5.9756e-03,\n",
      "         2.8779e-02, -7.9640e-02,  2.5211e-03, -1.2226e-01, -7.6779e-02,\n",
      "         3.4360e-02, -1.1125e-01, -1.7021e-02, -8.4983e-02, -9.6640e-02,\n",
      "        -1.3373e-02, -6.5654e-02,  9.6241e-03,  6.6051e-03,  4.1353e-02,\n",
      "        -6.3504e-02,  2.0573e-03, -1.5541e-01, -2.0988e-02, -1.0519e-01,\n",
      "        -3.4759e-02, -7.0067e-02, -1.7674e-02, -1.9119e-03, -7.5969e-02,\n",
      "        -1.3285e-02, -1.9849e-01, -7.3045e-02, -1.7259e-02, -4.1903e-02,\n",
      "        -8.3675e-02, -6.4880e-02, -7.1020e-03, -7.3031e-02, -7.0153e-02,\n",
      "        -2.0232e-01,  1.8248e-02,  6.2055e-03,  9.9338e-03,  4.0433e-02,\n",
      "         2.0863e-02, -2.2335e-01,  2.1306e-03, -9.3353e-03, -4.2540e-02,\n",
      "        -2.8914e-02,  4.0416e-02,  3.4357e-02, -6.5855e-02,  1.3358e-02,\n",
      "        -1.3259e-02, -5.1417e-02,  3.5353e-02, -6.8686e-02, -5.5926e-02,\n",
      "        -8.0325e-02, -7.1373e-02,  2.0842e-02, -2.7587e-02, -1.3003e-01,\n",
      "        -1.5972e-01, -1.1126e-01,  2.7653e-02,  1.0401e-02, -3.5204e-02,\n",
      "        -4.2035e-02,  1.7861e-03, -9.7772e-02, -7.6732e-03, -6.4072e-02,\n",
      "        -5.9774e-02, -2.0015e-02, -4.2677e-02, -1.0418e-01, -1.0244e-01,\n",
      "        -2.3020e-02, -1.2604e-02,  1.3753e-02, -7.9091e-02,  1.5498e-02,\n",
      "         6.0210e-02, -1.2981e-01, -2.2756e-01, -4.6075e-02, -8.1801e-02,\n",
      "        -1.3824e-01, -6.1189e-02, -2.8875e-02, -4.1894e-02, -2.6366e-03,\n",
      "        -1.0026e-01, -7.0559e-02, -1.0872e-01, -3.4233e-02, -8.7089e-02,\n",
      "        -6.3412e-02, -7.9310e-02, -9.7662e-02,  1.7059e-02, -1.4031e-01,\n",
      "         2.7384e-02, -7.0223e-04, -2.1935e-02, -6.3981e-03, -9.4686e-02,\n",
      "        -7.0784e-02, -8.9577e-02, -2.8382e-02, -1.3363e-02, -9.1262e-02,\n",
      "        -1.0090e-01, -4.1201e-02,  1.8255e-02, -7.5751e-03, -1.4208e-01,\n",
      "        -7.6268e-02,  2.1089e-02,  1.9838e-03,  1.5058e-02,  1.3635e-02,\n",
      "        -6.4390e-02, -1.5080e-01, -6.8097e-02, -3.5620e-02,  1.5896e-03,\n",
      "        -3.6061e-03, -4.4734e-02, -6.0579e-02, -5.7677e-02,  1.9433e-02,\n",
      "         2.0936e-02, -7.4670e-02, -8.9260e-02,  2.0336e-03, -1.3415e-02,\n",
      "        -1.5902e-01, -2.0807e-02,  5.8100e-02, -6.4207e-02, -2.2963e-02,\n",
      "        -4.0253e-02, -1.8748e-01, -8.2444e-02, -8.2718e-02, -3.8165e-02,\n",
      "        -5.3919e-02,  1.2104e-04, -5.6645e-02,  6.1911e-02, -6.4130e-02,\n",
      "        -1.2416e-01, -4.5627e-02, -9.1394e-02,  1.8323e-02, -1.7065e-02,\n",
      "        -2.0161e-03, -6.3933e-02, -1.2787e-01, -2.0583e-01, -8.7911e-02,\n",
      "        -9.8910e-02, -1.1969e-01, -8.2722e-03,  2.7903e-02, -1.7206e-01,\n",
      "        -1.3493e-01, -1.9621e-01, -1.0186e-01, -8.1006e-02, -1.1086e-01,\n",
      "        -1.5096e-02, -1.7663e-01,  1.5345e-02, -6.2496e-02, -5.9964e-02,\n",
      "        -5.0827e-02, -1.2870e-03, -3.6315e-02, -4.0014e-02, -1.8804e-01,\n",
      "        -2.4508e-02, -2.0167e-01, -8.8103e-02, -7.4028e-02, -1.2883e-01,\n",
      "         5.1604e-02, -9.8055e-02, -6.9262e-02, -7.5288e-02, -5.0114e-02,\n",
      "         8.1560e-03, -1.4193e-02, -2.1509e-02, -1.0524e-01, -4.7725e-02,\n",
      "        -2.2456e-02, -2.5478e-02,  2.0869e-02, -4.0194e-02, -3.6204e-02,\n",
      "        -6.0480e-02,  1.6641e-02, -5.1530e-02, -1.0098e-02,  7.5894e-03,\n",
      "        -3.9476e-02, -1.3565e-01, -3.1289e-02, -2.8253e-02, -5.4149e-02,\n",
      "        -2.8356e-02, -5.6630e-02, -5.2294e-02,  9.4299e-03, -1.2880e-01,\n",
      "        -2.1337e-02, -1.8749e-02, -9.2260e-02, -1.4647e-01,  2.3111e-02,\n",
      "        -1.4277e-01,  2.0577e-02, -2.5469e-02, -5.9845e-02, -6.5748e-02,\n",
      "        -3.1129e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0477,  0.0055,  0.0183,  ..., -0.0284, -0.0924, -0.1473],\n",
      "        [ 0.0314, -0.0538, -0.0047,  ..., -0.0050,  0.0231, -0.1049],\n",
      "        [-0.0293, -0.0677,  0.0397,  ..., -0.0085, -0.0269, -0.0970],\n",
      "        ...,\n",
      "        [-0.0158,  0.1789, -0.1341,  ...,  0.0272,  0.0151,  0.0677],\n",
      "        [-0.0108,  0.0210,  0.0674,  ...,  0.0283,  0.0086, -0.0063],\n",
      "        [ 0.0626, -0.0609, -0.1881,  ..., -0.0278,  0.0626, -0.0251]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0180,  0.0265,  0.1127,  ...,  0.0204,  0.0120, -0.0074],\n",
      "        [-0.0092, -0.0212, -0.0647,  ..., -0.0477,  0.0116, -0.0163],\n",
      "        [ 0.0610,  0.0554,  0.1045,  ..., -0.0019,  0.0181,  0.0297],\n",
      "        ...,\n",
      "        [ 0.0518, -0.0200, -0.0643,  ...,  0.0412,  0.0218, -0.0263],\n",
      "        [-0.0186,  0.0266, -0.1278,  ...,  0.0334, -0.0484, -0.0256],\n",
      "        [ 0.0499, -0.0843,  0.0377,  ..., -0.0310, -0.0259, -0.0224]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0311,  0.0410, -0.0162,  ...,  0.0147,  0.0440, -0.0321],\n",
      "        [ 0.0335, -0.0695,  0.0304,  ...,  0.0283, -0.0219, -0.0560],\n",
      "        [-0.0093,  0.0279,  0.0069,  ...,  0.0296,  0.0476, -0.0527],\n",
      "        ...,\n",
      "        [-0.0367, -0.0468, -0.0117,  ..., -0.0396,  0.0360, -0.0486],\n",
      "        [-0.0622, -0.0194, -0.0219,  ..., -0.0545, -0.0085, -0.0163],\n",
      "        [ 0.0415, -0.0051,  0.0203,  ...,  0.0067,  0.0141,  0.0103]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0341,  0.0422,  0.0267,  ..., -0.0230,  0.0585,  0.0232],\n",
      "        [-0.0221,  0.0051,  0.0490,  ..., -0.0537, -0.0403,  0.0006],\n",
      "        [-0.0397, -0.0030, -0.0412,  ..., -0.0079, -0.0266,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0239,  0.0228,  0.0398,  ..., -0.0134, -0.0295,  0.0514],\n",
      "        [ 0.0027, -0.0075, -0.0001,  ..., -0.0440, -0.0312, -0.0499],\n",
      "        [ 0.0170,  0.0137, -0.0499,  ..., -0.0537,  0.0233,  0.0395]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0233, -0.0124, -0.0224,  ...,  0.0024,  0.0522,  0.0733],\n",
      "        [-0.0624,  0.0578,  0.0355,  ...,  0.0117, -0.0483,  0.0967],\n",
      "        [ 0.0013,  0.0015,  0.0192,  ..., -0.0735, -0.0692, -0.0440],\n",
      "        ...,\n",
      "        [ 0.0225, -0.0116,  0.0123,  ...,  0.0127,  0.0205, -0.0232],\n",
      "        [ 0.0192,  0.0159,  0.0193,  ..., -0.0185, -0.0709,  0.0233],\n",
      "        [ 0.0057, -0.0306,  0.0246,  ...,  0.0155, -0.0114,  0.0767]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0073,  0.0208,  0.0293,  ..., -0.0252, -0.0341, -0.0403],\n",
      "        [-0.1187,  0.0379,  0.0254,  ..., -0.0443,  0.0091, -0.1084],\n",
      "        [-0.1547,  0.0108,  0.0712,  ..., -0.0014,  0.0270, -0.0358],\n",
      "        ...,\n",
      "        [-0.0150,  0.0056,  0.0125,  ..., -0.0369,  0.0673, -0.0104],\n",
      "        [ 0.0985, -0.0173, -0.0044,  ...,  0.0281, -0.0966,  0.0280],\n",
      "        [-0.0325,  0.0031, -0.0126,  ..., -0.0220,  0.0807, -0.0038]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9870, 0.9593, 0.9125, 1.0052, 0.8536, 0.9893, 0.9237, 0.9587, 0.9595,\n",
      "        0.9398, 0.9164, 0.9533, 0.9553, 0.8571, 1.0539, 0.9362, 0.9848, 0.9129,\n",
      "        0.9681, 0.9398, 0.9587, 1.0314, 0.9203, 1.0184, 1.0608, 0.9779, 0.9753,\n",
      "        0.9271, 1.0432, 1.0098, 0.9468, 0.9445, 1.0086, 0.9681, 0.8943, 0.9459,\n",
      "        1.0351, 1.0109, 0.8838, 0.9959, 0.8820, 0.9975, 0.9517, 0.9517, 0.9812,\n",
      "        0.9146, 0.9380, 1.0090, 0.9540, 0.9469, 1.0107, 0.8906, 0.9691, 0.9600,\n",
      "        0.9541, 0.9815, 0.8761, 0.9689, 1.0214, 0.9550, 0.8975, 0.9321, 0.9756,\n",
      "        0.8213, 0.8892, 0.8635, 1.0049, 0.9493, 1.0309, 0.9174, 0.9814, 0.8179,\n",
      "        0.9627, 1.0274, 0.9488, 0.9912, 1.0949, 1.0199, 1.0065, 0.9408, 0.9861,\n",
      "        1.0146, 0.8936, 0.8794, 1.0242, 0.9731, 1.0177, 1.0783, 0.9185, 0.8429,\n",
      "        1.0277, 0.8687, 0.9159, 0.9830, 1.0344, 0.9380, 0.9816, 0.9480, 0.9150,\n",
      "        0.9608, 0.9780, 0.9354, 0.9710, 0.9813, 0.9073, 0.8870, 1.0705, 1.0887,\n",
      "        1.0131, 0.9578, 0.9786, 0.9581, 0.8613, 0.9686, 0.9198, 0.8348, 0.9770,\n",
      "        0.9891, 0.9608, 1.0649, 0.9850, 0.9690, 0.8962, 0.9154, 0.9786, 0.9175,\n",
      "        0.9305, 0.9625, 0.9593, 0.9467, 0.9701, 0.9677, 0.9536, 0.9944, 1.0037,\n",
      "        0.9371, 0.9943, 0.9378, 0.8888, 0.9976, 0.9193, 1.0054, 0.9787, 1.0856,\n",
      "        0.9860, 0.9388, 0.9600, 0.9724, 0.9440, 1.0612, 0.8890, 0.9672, 0.8176,\n",
      "        1.0023, 0.9667, 1.0070, 1.0393, 0.9960, 1.0261, 1.0382, 0.9753, 1.0385,\n",
      "        0.9823, 1.0753, 0.9481, 1.0017, 0.8502, 0.9867, 0.9659, 0.9953, 1.0535,\n",
      "        0.9775, 0.9235, 1.0071, 0.9378, 1.0139, 1.0776, 1.0044, 0.9893, 0.9758,\n",
      "        0.8794, 1.0025, 0.9109, 0.9928, 0.9783, 1.0118, 1.0406, 0.9560, 0.9263,\n",
      "        0.9610, 1.0390, 0.8948, 1.0103, 0.9477, 0.9641, 0.9322, 0.7613, 0.9813,\n",
      "        0.9462, 0.9676, 1.0380, 0.9177, 0.9594, 0.8854, 1.0284, 0.9456, 0.9717,\n",
      "        1.0886, 0.9134, 0.8483, 0.9550, 0.8321, 0.9241, 0.9137, 0.9065, 0.9895,\n",
      "        1.0238, 0.8339, 0.9398, 0.9406, 1.0613, 0.9744, 1.0747, 0.9527, 0.9488,\n",
      "        0.9342, 0.9699, 0.9863, 0.9812, 1.0905, 0.9744, 1.0240, 1.0081, 0.9715,\n",
      "        0.9381, 0.8872, 0.9969, 0.9990, 1.0784, 0.9814, 0.8955, 0.9525, 1.0044,\n",
      "        0.9182, 0.8964, 0.9609, 1.0442, 1.0128, 0.9843, 0.9586, 0.9086, 0.9686,\n",
      "        0.9878, 0.9302, 0.9633, 1.0242], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.0532e-02,  4.4746e-02,  7.8876e-02,  2.7729e-02,  7.6223e-02,\n",
      "         8.1950e-03, -1.4826e-02,  8.4810e-02,  3.7157e-02,  3.8731e-03,\n",
      "         1.6306e-02, -5.0400e-02,  6.0044e-02,  8.4306e-02,  2.2008e-02,\n",
      "         9.0227e-02,  2.4497e-02, -5.6357e-02,  7.6910e-04,  3.2734e-02,\n",
      "        -1.3506e-02,  1.0310e-03, -7.4885e-03,  5.7204e-02, -9.3578e-04,\n",
      "        -3.1501e-02,  2.5137e-02,  2.5155e-02,  1.9279e-02, -2.1531e-02,\n",
      "         8.8181e-02, -1.0847e-04,  2.2746e-02,  2.2228e-02, -1.1562e-02,\n",
      "         8.5514e-02,  1.4951e-02,  7.7130e-02, -4.6137e-02,  1.1818e-02,\n",
      "         2.7512e-02,  2.3258e-02,  6.3373e-02,  1.2950e-02,  2.0807e-02,\n",
      "        -3.3127e-03,  4.9971e-02, -1.1609e-02,  8.9726e-02, -1.2953e-02,\n",
      "         2.8299e-03,  4.3990e-02, -2.9154e-02,  7.3944e-02,  4.5575e-04,\n",
      "         2.4991e-02,  7.9121e-02, -9.5792e-03,  2.9834e-02, -5.2706e-03,\n",
      "        -3.0844e-02, -6.1084e-03,  2.2049e-02,  3.9020e-02,  4.6946e-02,\n",
      "         6.0703e-02,  2.1465e-02, -1.6161e-02,  1.0972e-04,  3.0802e-02,\n",
      "         5.0283e-02,  1.1440e-01,  4.7919e-02,  1.1187e-02, -1.9042e-02,\n",
      "        -3.9897e-03, -1.3833e-02,  6.9676e-02,  8.4931e-03,  9.7205e-02,\n",
      "        -6.2957e-03, -5.1545e-03,  9.4869e-02,  4.9051e-02,  3.7398e-02,\n",
      "        -1.3347e-02,  2.8225e-02, -2.0284e-02,  5.3067e-02,  8.1925e-02,\n",
      "         4.4835e-03,  6.7357e-02,  8.2529e-02,  1.9523e-02,  5.9778e-03,\n",
      "        -3.4138e-03,  2.2841e-02, -7.6451e-03,  3.0115e-02,  1.6551e-02,\n",
      "        -1.5819e-02,  8.5478e-02, -3.0555e-02, -9.8735e-03,  7.2680e-02,\n",
      "         8.0203e-02, -1.1217e-02, -1.0437e-02, -6.1678e-03, -3.2672e-03,\n",
      "         2.5811e-02, -6.1042e-03,  1.2072e-01,  1.3166e-02, -1.3506e-02,\n",
      "         6.9235e-02,  5.0915e-03,  4.5139e-03,  1.3632e-03,  1.7561e-02,\n",
      "         2.1007e-02, -8.8059e-03, -5.4333e-02, -1.0144e-02, -7.5702e-03,\n",
      "         1.6890e-02, -1.5028e-02, -1.8565e-02,  3.1299e-02, -1.4972e-02,\n",
      "         9.5729e-02,  6.6219e-02, -1.3019e-03, -1.2936e-03,  6.5690e-03,\n",
      "        -2.2526e-03, -2.6211e-03, -2.5451e-02,  4.2781e-02, -1.5291e-02,\n",
      "         8.0441e-02, -1.0481e-02,  2.3655e-02,  1.5146e-02,  8.7427e-03,\n",
      "        -3.8222e-02,  3.1724e-02,  4.0814e-02,  3.0060e-02,  2.6625e-02,\n",
      "         3.9835e-02,  1.4997e-04, -4.8905e-02, -5.9465e-03,  1.8246e-02,\n",
      "         1.6477e-02,  3.4959e-02,  2.4390e-02,  1.1954e-02, -2.8612e-03,\n",
      "         1.2427e-02,  1.7749e-02, -1.4213e-02,  1.0028e-02,  3.7762e-02,\n",
      "        -1.1678e-02,  7.3502e-02,  3.2029e-02, -2.4989e-02,  3.4822e-03,\n",
      "        -1.3965e-02, -2.2341e-02,  4.1437e-02,  6.8244e-03,  2.8987e-02,\n",
      "         6.0958e-03,  1.1706e-02,  2.8800e-02,  4.5040e-02, -9.3153e-03,\n",
      "         6.0752e-02,  1.7095e-02,  1.6030e-02,  3.0518e-02,  4.3522e-02,\n",
      "         2.0137e-02,  1.5738e-02, -3.3584e-02, -9.3545e-03, -5.2349e-02,\n",
      "         2.1744e-03,  2.8069e-02,  2.9305e-02,  8.0136e-02, -1.9444e-02,\n",
      "        -3.1708e-02,  1.2038e-01, -7.2316e-03, -4.9354e-02, -3.4407e-02,\n",
      "         3.3286e-03, -5.8681e-03,  1.7286e-02,  8.4790e-02, -7.5388e-03,\n",
      "         3.2357e-03,  5.4236e-03,  1.2145e-02, -6.5330e-03,  6.7855e-02,\n",
      "         2.3542e-02,  1.1711e-01, -4.8941e-03, -3.9908e-03, -5.4688e-02,\n",
      "         1.2287e-02, -4.5910e-02,  7.9576e-02,  7.3617e-02, -4.8303e-03,\n",
      "         6.7724e-03,  3.7548e-02,  1.1509e-02, -3.1969e-02, -1.3467e-02,\n",
      "         1.2078e-02,  2.2674e-02,  2.0470e-02,  3.7730e-03,  2.3537e-04,\n",
      "        -1.4260e-03,  1.8764e-02,  1.6752e-02,  3.0457e-02,  3.4406e-02,\n",
      "         5.0284e-02, -1.2799e-02,  1.2956e-02,  6.3962e-03,  2.3373e-03,\n",
      "         2.8981e-02,  4.6285e-03, -1.1906e-02,  6.4146e-03, -3.7051e-02,\n",
      "        -1.9462e-03,  2.0252e-04,  2.5693e-02,  6.3173e-03,  2.1891e-02,\n",
      "         4.7456e-02,  1.9689e-02, -1.5613e-02, -1.5261e-02, -2.3074e-02,\n",
      "         1.8911e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0296, 0.9880, 0.8813, 1.0354, 0.8845, 0.9081, 1.0483, 0.9765, 0.9707,\n",
      "        1.0276, 0.9861, 0.7601, 0.9839, 0.9930, 0.9110, 0.9104, 1.0411, 0.8145,\n",
      "        0.9473, 0.9309, 1.0201, 0.9297, 1.0596, 0.9352, 1.0247, 0.9343, 0.9895,\n",
      "        1.0585, 0.9358, 1.0736, 1.0149, 1.0456, 1.0263, 0.9290, 0.9460, 0.9811,\n",
      "        0.9157, 0.9574, 0.7519, 0.9248, 0.9756, 1.0201, 1.0017, 1.0594, 1.0673,\n",
      "        1.0269, 0.9876, 0.8857, 0.9724, 0.9996, 1.0387, 0.9163, 1.0296, 1.0015,\n",
      "        0.8554, 1.0166, 0.9112, 0.8062, 1.0122, 1.0354, 0.8075, 1.0537, 0.9782,\n",
      "        1.0298, 0.9230, 0.9492, 1.0295, 1.0432, 1.0158, 1.0130, 0.9625, 1.0004,\n",
      "        0.9727, 1.0302, 1.0369, 1.0443, 1.0192, 0.9758, 0.9516, 0.9651, 1.0426,\n",
      "        1.0403, 0.9914, 0.9570, 0.9861, 1.0088, 0.9289, 1.0238, 1.0932, 1.0093,\n",
      "        0.9005, 0.9520, 0.9883, 1.0502, 1.0122, 1.0415, 1.0324, 1.0022, 0.8801,\n",
      "        0.9974, 1.0292, 0.9849, 0.9557, 1.0446, 0.9649, 1.0232, 1.0305, 1.0275,\n",
      "        1.0016, 1.0603, 1.0587, 0.9409, 0.9488, 1.0162, 1.0267, 1.0027, 0.9245,\n",
      "        1.0242, 0.9368, 1.0231, 0.8238, 1.0119, 0.8325, 1.0055, 1.0278, 0.9158,\n",
      "        1.0121, 1.0434, 1.0342, 0.9267, 1.0150, 0.9815, 1.0535, 1.0570, 1.0203,\n",
      "        1.0106, 1.0237, 1.0514, 0.9779, 0.9435, 0.9243, 1.0239, 1.0320, 1.0271,\n",
      "        0.9487, 0.7838, 1.0296, 1.0375, 1.0248, 1.0366, 0.9262, 0.9434, 0.9557,\n",
      "        1.0426, 1.0425, 1.0304, 1.0043, 0.9212, 0.9065, 1.0244, 0.9978, 0.9175,\n",
      "        0.9309, 1.0185, 0.9926, 0.9322, 1.0391, 1.0564, 0.7938, 1.0286, 1.0208,\n",
      "        0.9690, 0.8856, 0.9309, 1.0672, 1.0497, 1.0142, 0.9501, 0.9781, 1.0381,\n",
      "        0.9356, 0.9915, 0.9452, 1.0648, 0.9758, 1.0143, 0.9203, 0.8900, 0.9353,\n",
      "        0.7760, 0.9952, 1.0619, 1.0056, 0.9804, 0.9365, 0.9951, 0.9186, 0.9765,\n",
      "        0.8045, 0.7896, 1.0098, 0.9998, 1.0564, 0.9911, 0.9414, 1.0212, 1.0310,\n",
      "        1.0033, 0.9916, 0.9748, 0.9640, 0.9584, 1.0529, 1.0461, 0.8955, 1.0614,\n",
      "        0.7045, 0.8864, 0.9722, 1.0370, 1.0244, 1.0007, 1.0259, 0.8999, 1.0322,\n",
      "        1.0382, 1.0154, 0.9893, 1.0177, 1.0269, 1.0023, 0.9707, 0.9525, 1.0296,\n",
      "        1.0417, 1.0009, 0.9423, 1.0261, 1.0231, 1.0320, 0.9639, 1.0514, 0.9423,\n",
      "        1.0382, 1.0228, 1.0432, 1.0203, 0.9152, 0.9492, 1.0426, 0.8793, 1.0461,\n",
      "        0.9496, 1.0038, 0.9580, 1.0202], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0675, -0.0235, -0.0478, -0.0737, -0.0940, -0.0776,  0.1163, -0.0033,\n",
      "        -0.0109,  0.1273, -0.0258, -0.1344, -0.0277, -0.0092, -0.1297, -0.0376,\n",
      "        -0.0725, -0.1101, -0.0023, -0.0389,  0.1109, -0.0061,  0.1170, -0.0447,\n",
      "         0.1167,  0.0240,  0.0578,  0.1426, -0.0616,  0.1230, -0.0308,  0.0797,\n",
      "        -0.0961, -0.0251,  0.0491, -0.0134, -0.0943, -0.0371, -0.1540,  0.0106,\n",
      "         0.0192,  0.0622, -0.0217, -0.0392, -0.0595,  0.1135, -0.0093, -0.1325,\n",
      "        -0.0263,  0.1232,  0.1223, -0.0321,  0.1102, -0.0201, -0.1308, -0.0900,\n",
      "        -0.0853, -0.1210, -0.1200,  0.1011, -0.1046,  0.0287,  0.0067,  0.1873,\n",
      "        -0.0154, -0.0332, -0.0775,  0.0856,  0.1022,  0.1265, -0.0156,  0.0039,\n",
      "        -0.0085,  0.1509,  0.0464,  0.1339,  0.0933, -0.0238,  0.0166,  0.0011,\n",
      "         0.1307,  0.1355, -0.0183, -0.0638, -0.0942,  0.0929, -0.0596,  0.0979,\n",
      "         0.1520, -0.0180, -0.0992, -0.0092, -0.0290, -0.0664,  0.0932,  0.0928,\n",
      "        -0.0644,  0.0969, -0.0571,  0.0951,  0.0985,  0.0047,  0.0407,  0.0598,\n",
      "        -0.0284,  0.1642,  0.1003,  0.1260,  0.0907,  0.1024, -0.1012, -0.0064,\n",
      "        -0.0600,  0.1238,  0.1038,  0.1578, -0.0220,  0.1064,  0.0321,  0.0950,\n",
      "        -0.1903,  0.0920, -0.0898,  0.1168,  0.1370, -0.0822,  0.1249,  0.0784,\n",
      "        -0.0197, -0.0291, -0.0542,  0.0175,  0.0644, -0.0575,  0.1194,  0.1118,\n",
      "         0.1024,  0.0868,  0.0064, -0.0136, -0.0907,  0.1039, -0.0745,  0.1177,\n",
      "         0.0032, -0.1424, -0.0358, -0.0550, -0.0573,  0.0965, -0.0425,  0.0232,\n",
      "         0.0197,  0.1101, -0.0299,  0.1140, -0.0756, -0.0149, -0.1027,  0.1016,\n",
      "        -0.0239, -0.0713, -0.0154,  0.1293,  0.0066, -0.0087,  0.1333, -0.0779,\n",
      "        -0.1172,  0.1183,  0.1017,  0.0568, -0.1112,  0.0133,  0.1405,  0.1435,\n",
      "         0.1030, -0.0468, -0.0209,  0.0737, -0.0145, -0.0667,  0.0227,  0.1400,\n",
      "        -0.0208, -0.1126, -0.0649, -0.0619,  0.0046, -0.1267,  0.0935,  0.1371,\n",
      "        -0.1171, -0.0194,  0.0062,  0.0771, -0.0436,  0.0631, -0.1153, -0.0956,\n",
      "         0.0992,  0.0776, -0.0613, -0.0099, -0.0118,  0.1096,  0.1141,  0.1126,\n",
      "         0.0809, -0.0276,  0.0136, -0.0326,  0.0666,  0.1122, -0.0629, -0.0820,\n",
      "        -0.2010, -0.0847, -0.0258,  0.1171,  0.0977, -0.0394,  0.1146, -0.0633,\n",
      "         0.0937, -0.0403, -0.0183, -0.0042,  0.1358,  0.1173,  0.1095, -0.0073,\n",
      "        -0.0681, -0.0825, -0.1031, -0.0398, -0.0120,  0.1109,  0.1085,  0.1184,\n",
      "        -0.0038,  0.0719,  0.0151,  0.1212,  0.0864,  0.1427,  0.1234, -0.0740,\n",
      "         0.0206, -0.0650, -0.0825,  0.1367,  0.0356,  0.0910,  0.0514,  0.1069],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.0486e-01,  8.1718e-02,  2.1006e-02,  1.2193e-01,  1.9320e-02,\n",
      "          2.1213e-02, -1.1386e-01,  6.2046e-02,  7.4253e-02, -1.0446e-01,\n",
      "          7.6016e-02,  2.1743e-03,  7.6354e-02,  5.7322e-02,  1.4462e-02,\n",
      "          4.8305e-02,  1.2049e-01,  8.0329e-04, -2.6292e-02,  2.4795e-02,\n",
      "         -8.4156e-02, -1.4854e-02, -1.1330e-01,  3.8722e-02, -1.0956e-01,\n",
      "         -2.5186e-02, -6.1517e-02, -1.2959e-01,  2.3329e-02, -1.6152e-01,\n",
      "          1.0877e-01, -1.2508e-01,  1.0563e-01,  2.2441e-02, -3.7566e-02,\n",
      "          6.8129e-02,  1.5966e-02,  5.8804e-02,  7.8725e-04, -2.3925e-02,\n",
      "          4.6447e-02, -7.1107e-02,  7.5519e-02,  1.4225e-01,  1.2957e-01,\n",
      "         -8.9693e-02,  6.9307e-02,  1.4049e-02,  6.0771e-02, -8.2547e-02,\n",
      "         -1.3407e-01,  3.4625e-02, -1.1107e-01,  8.8262e-02,  2.4781e-03,\n",
      "          8.6096e-02,  2.3117e-02,  3.7895e-04,  9.9278e-02, -1.1502e-01,\n",
      "          5.3069e-04, -1.1952e-01,  5.0871e-02, -9.2991e-02,  2.7963e-02,\n",
      "          4.6741e-02,  1.1150e-01, -1.0843e-01, -9.1938e-02, -1.1293e-01,\n",
      "          6.5950e-02,  7.1785e-02,  7.8213e-02, -1.1854e-01, -1.2663e-01,\n",
      "         -1.2788e-01, -9.8919e-02,  5.2659e-02,  3.6327e-02,  6.5228e-02,\n",
      "         -1.0213e-01, -1.1726e-01,  6.5868e-02, -5.9746e-02,  6.9182e-02,\n",
      "         -7.6106e-02,  2.5988e-02, -1.0933e-01, -1.6356e-01,  7.7939e-02,\n",
      "          1.3464e-02, -3.4091e-02,  6.6052e-02,  1.1964e-01, -9.5963e-02,\n",
      "         -1.0500e-01,  1.3004e-01, -6.6577e-02, -1.2390e-02, -1.0043e-01,\n",
      "         -1.0174e-01,  5.1766e-02, -2.7255e-02, -1.1688e-01,  4.0773e-02,\n",
      "         -1.2627e-01, -1.1724e-01, -9.7907e-02, -9.4872e-02, -1.2279e-01,\n",
      "          1.5594e-01, -3.0400e-02,  3.7044e-02, -1.1149e-01, -9.9612e-02,\n",
      "         -9.2565e-02,  1.8460e-02, -1.1559e-01, -3.2026e-02, -9.5217e-02,\n",
      "          1.4424e-02, -7.0779e-02,  1.2656e-04, -9.0282e-02, -1.0868e-01,\n",
      "         -3.7396e-02, -8.1400e-02, -1.1774e-01,  1.2119e-01, -1.4875e-02,\n",
      "          1.0245e-01,  5.7076e-02, -1.3318e-01,  1.2485e-01, -7.9561e-02,\n",
      "         -7.8779e-02, -1.0822e-01, -1.4106e-01,  4.8597e-02, -1.9954e-02,\n",
      "          3.2754e-02, -1.1241e-01,  1.1069e-01, -1.0753e-01, -2.1559e-02,\n",
      "          1.2987e-03,  1.0227e-01,  1.1891e-01,  1.1456e-01, -1.1875e-01,\n",
      "          2.4552e-02, -3.4537e-02, -3.3737e-02, -1.1799e-01,  1.2642e-01,\n",
      "         -1.0592e-01,  7.7062e-02,  1.9319e-02,  1.2295e-02, -9.6850e-02,\n",
      "          9.8062e-02,  1.9637e-02, -1.8669e-02, -1.1212e-01,  6.4762e-02,\n",
      "         -1.7444e-02, -1.0705e-01,  1.4406e-01,  1.3759e-03, -9.5008e-02,\n",
      "         -8.6732e-02, -4.7016e-02,  2.4574e-02, -1.6704e-02, -1.2234e-01,\n",
      "         -9.3648e-02, -9.7980e-02,  3.9345e-02,  7.2205e-02, -1.2407e-01,\n",
      "          4.0383e-02,  6.7850e-02,  2.6622e-02, -1.0450e-01,  6.0129e-02,\n",
      "          8.4356e-02,  2.0978e-02, -1.6617e-03, -1.4329e-02,  9.2140e-04,\n",
      "         -5.4482e-02, -9.2841e-02,  8.8556e-02,  7.7650e-02, -2.2006e-02,\n",
      "         -6.4806e-02,  2.6791e-02, -6.0864e-02,  8.8058e-04, -8.8582e-04,\n",
      "         -1.0559e-01, -6.8082e-02,  1.4112e-01,  6.6157e-02, -1.6904e-02,\n",
      "         -9.6467e-02, -1.0237e-01, -1.0045e-01, -6.5879e-02,  5.8375e-02,\n",
      "          5.5294e-02,  4.9740e-02, -1.3588e-01, -1.1629e-01, -2.8236e-03,\n",
      "          1.4666e-01,  1.1396e-03,  2.7612e-02,  5.1196e-02, -9.1470e-02,\n",
      "         -1.0294e-01,  9.1095e-02, -9.1110e-02, -6.2889e-03, -1.2538e-01,\n",
      "          1.1271e-01,  1.0136e-01,  6.1006e-02, -9.8476e-02, -1.2412e-01,\n",
      "         -9.4944e-02,  5.9717e-02,  4.0724e-02,  1.1277e-01,  1.0859e-01,\n",
      "          5.8924e-02, -2.5068e-02, -1.0883e-01, -1.0983e-01, -1.2683e-01,\n",
      "          4.7123e-02, -1.0554e-01, -1.8542e-02, -1.0309e-01, -8.1863e-02,\n",
      "         -1.1942e-01, -9.8456e-02,  1.7723e-02, -2.2973e-02,  1.0923e-01,\n",
      "          2.7458e-02, -1.3141e-01, -2.7725e-02, -7.6644e-02, -3.4326e-02,\n",
      "         -1.1817e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1033], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3009,  0.0085, -0.0023,  0.0003,  0.0020,  0.0121,  0.0025,  0.0218,\n",
      "         -0.0027, -0.0074, -0.0047,  0.0109]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0755], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# A_GNN 2 layers\n",
    "class GNN_config:\n",
    "    # ----------------- architectual hyperparameters ----------------- #\n",
    "    d_model = 256\n",
    "    n_heads = 8\n",
    "    dropout = 0.1\n",
    "    n_gnn_layers = 2\n",
    "    activation = nn.ReLU()\n",
    "    res_learning = False\n",
    "    bottleneck = True\n",
    "    # ----------------- optimisation hyperparameters ----------------- #\n",
    "    random_state = SEED\n",
    "    epochs = 32\n",
    "    lr = 1e-3\n",
    "    patience = 5\n",
    "    loss = nn.MSELoss()\n",
    "    validation_loss = nn.MSELoss()\n",
    "    alpha = 0.1\n",
    "    scheduler = True\n",
    "    grad_clip = False\n",
    "    # ----------------- operation hyperparameters ----------------- #\n",
    "    spatial_input_dim = 1\n",
    "    nonspatial_input_dim = 11\n",
    "    # ----------------- saving hyperparameters ----------------- #\n",
    "    rootpath = home_directory\n",
    "    name = f'AGNN_2layer'\n",
    "\n",
    "model2 = GNN(GNN_config) # initialise the model\n",
    "\n",
    "# as model automatically saves best epoch, will now load the best epoch and evaluate on test set\n",
    "model2.load()\n",
    "\n",
    "for parameters in model2.model.parameters():\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spanalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
