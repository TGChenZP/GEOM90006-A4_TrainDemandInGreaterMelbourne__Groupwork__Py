{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create instances with all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_trains_demand_pre_covid = pd.read_csv('../data/curated/train_demand/daily_trains_demand_pre_covid.csv')\n",
    "daily_trains_demand_post_covid = pd.read_csv('../data/curated/train_demand/daily_trains_demand_post_covid.csv')\n",
    "mean_daily_trains_demand_post_covid = pd.read_csv('../data/curated/train_demand/mean_daily_trains_demand_post_covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_trains_demand_post_covid_weekday = daily_trains_demand_post_covid[(daily_trains_demand_post_covid['Weekday'] == 1)]\n",
    "daily_trains_demand_post_covid_weekend = daily_trains_demand_post_covid[(daily_trains_demand_post_covid['Weekday'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rows together\n",
    "mean_daily_trains_demand_post_covid_weekday = pd.DataFrame()\n",
    "\n",
    "for id, station_data in daily_trains_demand_post_covid_weekday.drop(['Business_Date', 'Weekday', 'PublicHoliday', 'Unnamed: 0'], axis=1).groupby('Station_Name'):\n",
    "    station_data = station_data.drop('Station_Name', axis=1)\n",
    "    station_data_mean = station_data.mean()\n",
    "    station_data_mean = pd.DataFrame(station_data_mean).T\n",
    "    station_data_mean['Station_Name'] = id\n",
    "    mean_daily_trains_demand_post_covid_weekday = pd.concat([mean_daily_trains_demand_post_covid_weekday, station_data_mean], axis=0)\n",
    "\n",
    "\n",
    "mean_daily_trains_demand_post_covid_weekend = pd.DataFrame()\n",
    "\n",
    "for id, station_data in daily_trains_demand_post_covid_weekend.drop(['Business_Date', 'Weekday', 'PublicHoliday', 'Unnamed: 0'], axis=1).groupby('Station_Name'):\n",
    "    station_data = station_data.drop('Station_Name', axis=1)\n",
    "    station_data_mean = station_data.mean()\n",
    "    station_data_mean = pd.DataFrame(station_data_mean).T\n",
    "    station_data_mean['Station_Name'] = id\n",
    "    mean_daily_trains_demand_post_covid_weekend = pd.concat([mean_daily_trains_demand_post_covid_weekend, station_data_mean], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_daily_trains_demand_post_covid_weekday['log_Total_Demand'] = np.log(mean_daily_trains_demand_post_covid_weekday['Total_Demand'])\n",
    "mean_daily_trains_demand_post_covid_weekend['log_Total_Demand'] = np.log(mean_daily_trains_demand_post_covid_weekend['Total_Demand'])\n",
    "mean_daily_trains_demand_post_covid_weekday['log_Passenger_Alightings'] = np.log(mean_daily_trains_demand_post_covid_weekday['Passenger_Alightings'])\n",
    "mean_daily_trains_demand_post_covid_weekend['log_Passenger_Alightings'] = np.log(mean_daily_trains_demand_post_covid_weekend['Passenger_Alightings'])\n",
    "mean_daily_trains_demand_post_covid_weekday['log_Passenger_Boardings'] = np.log(mean_daily_trains_demand_post_covid_weekday['Passenger_Boardings'])\n",
    "mean_daily_trains_demand_post_covid_weekend['log_Passenger_Boardings'] = np.log(mean_daily_trains_demand_post_covid_weekend['Passenger_Boardings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_demand_in_rows(demand_df: pd.DataFrame, feature: str):\n",
    "\n",
    "    try:\n",
    "        df_with_feature = demand_df[['Station_Name', 'Business_Date', feature]]\n",
    "    except:\n",
    "        df_with_feature = demand_df[['Station_Name', feature]]\n",
    "\n",
    "    station_df_list = []\n",
    "\n",
    "    for id, station_df in tqdm(df_with_feature.groupby('Station_Name')):\n",
    "\n",
    "        station_df = station_df.rename({feature: f'{feature}_{id}'}, axis=1)\n",
    "        station_df = station_df.drop('Station_Name', axis=1)\n",
    "        station_df_list.append(station_df)\n",
    "\n",
    "    for i, station_df in enumerate(station_df_list):\n",
    "        if i == 0:\n",
    "            merged_df = station_df\n",
    "        else:\n",
    "            try:\n",
    "                merged_df = pd.merge(merged_df, station_df, on='Business_Date', how='outer')\n",
    "            except:\n",
    "                merged_df = pd.concat([merged_df, station_df], axis=0)\n",
    "\n",
    "    merged_df = merged_df.fillna(0)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [00:00<00:00, 1963.37it/s]\n",
      "100%|██████████| 223/223 [00:00<00:00, 977.90it/s]\n",
      "100%|██████████| 222/222 [00:00<00:00, 2566.95it/s]\n",
      "100%|██████████| 223/223 [00:00<00:00, 2202.93it/s]\n",
      "100%|██████████| 222/222 [00:00<00:00, 2487.70it/s]\n",
      "100%|██████████| 223/223 [00:00<00:00, 2153.65it/s]\n"
     ]
    }
   ],
   "source": [
    "log_demand_precovid = get_daily_demand_in_rows(daily_trains_demand_pre_covid, 'log_Total_Demand')\n",
    "log_demand_postcovid = get_daily_demand_in_rows(daily_trains_demand_post_covid, 'log_Total_Demand')\n",
    "log_alighting_precovid = get_daily_demand_in_rows(daily_trains_demand_pre_covid, 'log_Passenger_Alightings')\n",
    "log_alighting_postcovid = get_daily_demand_in_rows(daily_trains_demand_post_covid, 'log_Passenger_Alightings')\n",
    "log_boarding_precovid = get_daily_demand_in_rows(daily_trains_demand_pre_covid, 'log_Passenger_Boardings')\n",
    "log_boarding_postcovid = get_daily_demand_in_rows(daily_trains_demand_post_covid, 'log_Passenger_Boardings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_daily_trains_demand_post_covid_weekday = mean_daily_trains_demand_post_covid_weekday.sort_values('Station_Name')\n",
    "mean_daily_trains_demand_post_covid_weekday = mean_daily_trains_demand_post_covid_weekday.set_index('Station_Name')\n",
    "\n",
    "mean_daily_trains_demand_post_covid_weekend = mean_daily_trains_demand_post_covid_weekend.sort_values('Station_Name')\n",
    "mean_daily_trains_demand_post_covid_weekend = mean_daily_trains_demand_post_covid_weekend.set_index('Station_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_demand_in_rows_inference(df, feature):\n",
    "    return df[[feature]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mean_demand_postcovid_weekday = get_daily_demand_in_rows_inference(mean_daily_trains_demand_post_covid_weekday, 'log_Total_Demand')\n",
    "log_mean_alighting_postcovid_weekday = get_daily_demand_in_rows_inference(mean_daily_trains_demand_post_covid_weekday, 'log_Passenger_Alightings')\n",
    "log_mean_boarding_postcovid_weekday = get_daily_demand_in_rows_inference(mean_daily_trains_demand_post_covid_weekday, 'log_Passenger_Boardings')\n",
    "\n",
    "log_mean_demand_postcovid_weekend = get_daily_demand_in_rows_inference(mean_daily_trains_demand_post_covid_weekend, 'log_Total_Demand')\n",
    "log_mean_alighting_postcovid_weekend = get_daily_demand_in_rows_inference(mean_daily_trains_demand_post_covid_weekend, 'log_Passenger_Alightings')\n",
    "log_mean_boarding_postcovid_weekend = get_daily_demand_in_rows_inference(mean_daily_trains_demand_post_covid_weekend, 'log_Passenger_Boardings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data/curated/ML_features', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_demand_precovid.to_csv('../data/curated/ML_features/log_demand_precovid.csv', index=False)\n",
    "log_demand_postcovid.to_csv('../data/curated/ML_features/log_demand_postcovid.csv', index=False)\n",
    "log_alighting_precovid.to_csv('../data/curated/ML_features/log_alighting_precovid.csv', index=False)\n",
    "log_alighting_postcovid.to_csv('../data/curated/ML_features/log_alighting_postcovid.csv', index=False)\n",
    "log_boarding_precovid.to_csv('../data/curated/ML_features/log_boarding_precovid.csv', index=False)\n",
    "log_boarding_postcovid.to_csv('../data/curated/ML_features/log_boarding_postcovid.csv', index=False)\n",
    "\n",
    "log_mean_demand_postcovid_weekday.to_csv('../data/curated/ML_features/log_mean_demand_postcovid_weekday.csv', index=False)\n",
    "log_mean_alighting_postcovid_weekday.to_csv('../data/curated/ML_features/log_mean_alighting_postcovid_weekday.csv', index=False)\n",
    "log_mean_boarding_postcovid_weekday.to_csv('../data/curated/ML_features/log_mean_boarding_postcovid_weekday.csv', index=False)\n",
    "log_mean_alighting_postcovid_weekend.to_csv('../data/curated/ML_features/log_mean_alighting_postcovid_weekend.csv', index=False)\n",
    "log_mean_boarding_postcovid_weekend.to_csv('../data/curated/ML_features/log_mean_boarding_postcovid_weekend.csv', index=False)\n",
    "log_mean_demand_postcovid_weekend.to_csv('../data/curated/ML_features/log_mean_demand_postcovid_weekend.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight demand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_weights_withSA2 = pd.read_csv('../data/curated/ML_features/station_weights_withSA2.csv')\n",
    "station_weights = pd.read_csv('../data/curated/ML_features/station_weights.csv')\n",
    "\n",
    "station_with_sa2_list_dict = {k:i for i, k in enumerate(station_weights_withSA2['Unnamed: 0'])}\n",
    "station_list_dict = {k:i for i, k in enumerate(station_weights['Unnamed: 0'])}\n",
    "reverse_station_with_sa2_list_dict = {i:k for i, k in enumerate(station_weights_withSA2['Unnamed: 0'])}\n",
    "reverse_station_list_dict = {i:k for i, k in enumerate(station_weights['Unnamed: 0'])}\n",
    "\n",
    "station_weights_withSA2.set_index('Unnamed: 0', inplace=True)\n",
    "station_weights.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/curated/ML_features/station_weights_withSA2.json', 'w') as f:\n",
    "    json.dump(station_with_sa2_list_dict, f)\n",
    "\n",
    "with open('../data/curated/ML_features/station_weights.json', 'w') as f:\n",
    "    json.dump(station_list_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_demand_postcovid.set_index('Business_Date', inplace=True)\n",
    "log_alighting_postcovid.set_index('Business_Date', inplace=True)\n",
    "log_boarding_postcovid.set_index('Business_Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_demand(log_demand: pd.DataFrame, station_weights: pd.DataFrame, reverse_station_list_dict: dict):\n",
    "    results = []\n",
    "\n",
    "    for station, row in tqdm(station_weights.iterrows()):\n",
    "        weights = row.values\n",
    "\n",
    "        for date, row in log_demand.iterrows():\n",
    "            demand = row.values\n",
    "\n",
    "            weighted_demand = weights * demand\n",
    "\n",
    "            # Append to results list\n",
    "            results.append({\n",
    "                'Station': station,\n",
    "                'Date': date,\n",
    "                **{f'{reverse_station_list_dict[i]}': wd for i, wd in enumerate(weighted_demand)}\n",
    "            })\n",
    "\n",
    "    # Convert results list to DataFrame\n",
    "    weighted_demand_df = pd.DataFrame(results)\n",
    "\n",
    "    return weighted_demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223it [00:09, 23.14it/s]\n",
      "223it [00:09, 22.54it/s]\n",
      "223it [00:09, 23.53it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_log_demand_postcovid = get_weighted_demand(log_demand_postcovid, station_weights, reverse_station_list_dict)\n",
    "weighted_log_alighting_postcovid = get_weighted_demand(log_alighting_postcovid, station_weights, reverse_station_list_dict)\n",
    "weighted_log_boarding_postcovid = get_weighted_demand(log_boarding_postcovid, station_weights, reverse_station_list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_demand_inference(log_demand: pd.DataFrame, station_weights: pd.DataFrame, reverse_station_list_dict: dict):\n",
    "    results = []\n",
    "\n",
    "    i = 0\n",
    "    for station, row in tqdm(station_weights.iterrows()):\n",
    "        weights = row.values[:223]\n",
    "        if '(SA2)' not in station:\n",
    "            continue\n",
    "        else:\n",
    "            station = station.split('(SA2)')[1]\n",
    " \n",
    "        for date, row in log_demand.iterrows():\n",
    "            demand = row.values\n",
    "\n",
    "            weighted_demand = weights * demand\n",
    "\n",
    "            # Append to results list\n",
    "            results.append({\n",
    "                'Station': reverse_station_list_dict[i+223],\n",
    "                'Date': date,\n",
    "                **{f'{reverse_station_list_dict[i]}': wd for i, wd in enumerate(weighted_demand)}\n",
    "            })\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    # Convert results list to DataFrame\n",
    "    weighted_demand_df = pd.DataFrame(results)\n",
    "\n",
    "    return weighted_demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "442it [00:00, 15571.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "442it [00:00, 15796.41it/s]\n",
      "442it [00:00, 13916.78it/s]\n",
      "442it [00:00, 16096.08it/s]\n",
      "442it [00:00, 15464.36it/s]\n",
      "442it [00:00, 16163.16it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_log_mean_demand_postcovid_weekday = get_weighted_demand_inference(log_mean_demand_postcovid_weekday, station_weights_withSA2, reverse_station_with_sa2_list_dict)\n",
    "weighted_log_mean_alighting_postcovid_weekday = get_weighted_demand_inference(log_mean_alighting_postcovid_weekday, station_weights_withSA2, reverse_station_with_sa2_list_dict)\n",
    "weighted_log_mean_boarding_postcovid_weekday = get_weighted_demand_inference(log_mean_boarding_postcovid_weekday, station_weights_withSA2, reverse_station_with_sa2_list_dict)\n",
    "\n",
    "weighted_log_mean_demand_postcovid_weekend = get_weighted_demand_inference(log_mean_demand_postcovid_weekend, station_weights_withSA2, reverse_station_with_sa2_list_dict)\n",
    "weighted_log_mean_alighting_postcovid_weekend = get_weighted_demand_inference(log_mean_alighting_postcovid_weekend, station_weights_withSA2, reverse_station_with_sa2_list_dict)\n",
    "weighted_log_mean_boarding_postcovid_weekend = get_weighted_demand_inference(log_mean_boarding_postcovid_weekend, station_weights_withSA2, reverse_station_with_sa2_list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_log_mean_demand_postcovid_weekday.drop('Date', axis=1, inplace=True)\n",
    "weighted_log_mean_alighting_postcovid_weekday.drop('Date', axis=1, inplace=True)\n",
    "weighted_log_mean_boarding_postcovid_weekday.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "weighted_log_mean_demand_postcovid_weekend.drop('Date', axis=1, inplace=True)\n",
    "weighted_log_mean_alighting_postcovid_weekend.drop('Date', axis=1, inplace=True)\n",
    "weighted_log_mean_boarding_postcovid_weekend.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_log_demand_postcovid.to_parquet('../data/curated/ML_features/weighted_log_demand_postcovid.parquet', index=False)\n",
    "weighted_log_alighting_postcovid.to_parquet('../data/curated/ML_features/weighted_log_alighting_postcovid.parquet', index=False)\n",
    "weighted_log_boarding_postcovid.to_parquet('../data/curated/ML_features/weighted_log_boarding_postcovid.parquet', index=False)\n",
    "\n",
    "weighted_log_mean_demand_postcovid_weekday.to_parquet('../data/curated/ML_features/weighted_log_mean_demand_postcovid_weekday.parquet', index=False)\n",
    "weighted_log_mean_alighting_postcovid_weekday.to_parquet('../data/curated/ML_features/weighted_log_mean_alighting_postcovid_weekday.parquet', index=False)\n",
    "weighted_log_mean_boarding_postcovid_weekday.to_parquet('../data/curated/ML_features/weighted_log_mean_boarding_postcovid_weekday.parquet', index=False)\n",
    "\n",
    "weighted_log_mean_demand_postcovid_weekend.to_parquet('../data/curated/ML_features/weighted_log_mean_demand_postcovid_weekend.parquet', index=False)\n",
    "weighted_log_mean_alighting_postcovid_weekend.to_parquet('../data/curated/ML_features/weighted_log_mean_alighting_postcovid_weekend.parquet', index=False)\n",
    "weighted_log_mean_boarding_postcovid_weekend.to_parquet('../data/curated/ML_features/weighted_log_mean_boarding_postcovid_weekend.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_trains_demand_post_covid.drop(['Unnamed: 0', 'Passenger_Boardings', 'Passenger_Alightings', 'Total_Demand', 'log_Passenger_Boardings', 'log_Passenger_Alightings'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = pd.read_csv('../data/curated/ML_features/rainfall_Station_SA2.csv')\n",
    "rainfall_df_stations = rainfall_df[~rainfall_df['Station_Na'].isna()][['mean_rainfall_value', 'Station_Na']]\n",
    "rainfall_df_sa2 = rainfall_df[rainfall_df['Station_Na'].isna()][['mean_rainfall_value', 'SA2_NAME21']]\n",
    "rainfall_df_sa2.rename({'SA2_NAME21': 'Station'}, axis=1, inplace=True)\n",
    "\n",
    "census_and_buildings_postcovid = pd.read_csv('../data/curated/ML_features/census_and_buildings_postcovid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ML_data = daily_trains_demand_post_covid.merge(rainfall_df_stations, left_on='Station_Name', right_on='Station_Na', how='left')\n",
    "station_ML_data.drop(['Station_Na'], axis=1, inplace=True)\n",
    "station_ML_data = station_ML_data.merge(census_and_buildings_postcovid[census_and_buildings_postcovid['point_type'] == 'station'], left_on = 'Station_Name', right_on='Point Name', how = 'left')\n",
    "\n",
    "station_ML_data = station_ML_data.merge(weighted_log_demand_postcovid, left_on=['Business_Date', 'Station_Name'], right_on=['Date', 'Station'], how='left', suffixes=('', '_demand'))\n",
    "station_ML_data = station_ML_data.merge(weighted_log_alighting_postcovid, left_on=['Business_Date', 'Station_Name'], right_on=['Date', 'Station'], how='left', suffixes=('', '_alighting'))\n",
    "station_ML_data = station_ML_data.merge(weighted_log_boarding_postcovid, left_on=['Business_Date', 'Station_Name'], right_on=['Date', 'Station'], how='left', suffixes=('', '_boarding'))\n",
    "station_ML_data.drop(['Point Name', 'point_type', 'Station_alighting', 'Station_boarding', 'Date_alighting', 'Date_boarding', 'Station'], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_log_mean_demand_postcovid_weekday['Station'] = weighted_log_mean_demand_postcovid_weekday['Station'].apply(lambda x: x.split('(SA2)')[1])\n",
    "weighted_log_mean_alighting_postcovid_weekday['Station'] = weighted_log_mean_alighting_postcovid_weekday['Station'].apply(lambda x: x.split('(SA2)')[1])\n",
    "weighted_log_mean_boarding_postcovid_weekday['Station'] = weighted_log_mean_boarding_postcovid_weekday['Station'].apply(lambda x: x.split('(SA2)')[1])\n",
    "\n",
    "weighted_log_mean_demand_postcovid_weekend['Station'] = weighted_log_mean_demand_postcovid_weekend['Station'].apply(lambda x: x.split('(SA2)')[1])\n",
    "weighted_log_mean_alighting_postcovid_weekend['Station'] = weighted_log_mean_alighting_postcovid_weekend['Station'].apply(lambda x: x.split('(SA2)')[1])\n",
    "weighted_log_mean_boarding_postcovid_weekend['Station'] = weighted_log_mean_boarding_postcovid_weekend['Station'].apply(lambda x: x.split('(SA2)')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA2_ML_data_weekday = rainfall_df_sa2.copy()\n",
    "SA2_ML_data_weekday = SA2_ML_data_weekday.merge(census_and_buildings_postcovid[census_and_buildings_postcovid['point_type'] == 'suburb'], left_on = 'Station', right_on='Point Name', how = 'left')\n",
    "\n",
    "SA2_ML_data_weekday = SA2_ML_data_weekday.merge(weighted_log_mean_demand_postcovid_weekday, left_on=['Station'], right_on=['Station'], how='left', suffixes = ('', '_demand'))\n",
    "SA2_ML_data_weekday = SA2_ML_data_weekday.merge(weighted_log_mean_alighting_postcovid_weekday, left_on=['Station'], right_on=['Station'], how='left', suffixes = ('', '_alighting'))\n",
    "SA2_ML_data_weekday = SA2_ML_data_weekday.merge(weighted_log_mean_boarding_postcovid_weekday, left_on=['Station'], right_on=['Station'], how='left', suffixes = ('', '_boarding'))\n",
    "\n",
    "SA2_ML_data_weekday.drop(['Point Name', 'point_type'], axis=1, inplace=True)\n",
    "SA2_ML_data_weekday.rename({'Station': 'Station Name'}, axis=1, inplace=True)\n",
    "\n",
    "SA2_ML_data_weekend = rainfall_df_sa2.copy()\n",
    "SA2_ML_data_weekend = SA2_ML_data_weekend.merge(census_and_buildings_postcovid[census_and_buildings_postcovid['point_type'] == 'suburb'], left_on = 'Station', right_on='Point Name', how = 'left')\n",
    "\n",
    "SA2_ML_data_weekend = SA2_ML_data_weekend.merge(weighted_log_mean_demand_postcovid_weekend, left_on=['Station'], right_on=['Station'], how='left', suffixes = ('', '_demand'))\n",
    "SA2_ML_data_weekend = SA2_ML_data_weekend.merge(weighted_log_mean_alighting_postcovid_weekend, left_on=['Station'], right_on=['Station'], how='left', suffixes = ('', '_alighting'))\n",
    "SA2_ML_data_weekend = SA2_ML_data_weekend.merge(weighted_log_mean_boarding_postcovid_weekend, left_on=['Station'], right_on=['Station'], how='left', suffixes = ('', '_boarding'))\n",
    "\n",
    "SA2_ML_data_weekend.drop(['Point Name', 'point_type'], axis=1, inplace=True)\n",
    "SA2_ML_data_weekend.rename({'Station': 'Station Name'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA2_ML_data_weekday['Weekday'] = 1\n",
    "SA2_ML_data_weekend['Weekday'] = 0\n",
    "\n",
    "SA2_ML_data = pd.concat([SA2_ML_data_weekday, SA2_ML_data_weekend], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data/curated/ML_data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ML_data.to_parquet('../data/curated/ML_data/station_ML_data.parquet', index=False)\n",
    "SA2_ML_data.to_parquet('../data/curated/ML_data/SA2_ML_data.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split and Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_dates = station_ML_data['Business_Date'].unique()\n",
    "\n",
    "train_dates, val_test_dates = train_test_split(business_dates, test_size=0.3, shuffle = False)\n",
    "val_dates, test_dates = train_test_split(val_test_dates, test_size=0.5, shuffle = False)\n",
    "\n",
    "ML_train_data = station_ML_data[station_ML_data['Business_Date'].isin(train_dates)]\n",
    "ML_val_data = station_ML_data[station_ML_data['Business_Date'].isin(val_dates)]\n",
    "ML_test_data = station_ML_data[station_ML_data['Business_Date'].isin(test_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_train_data.to_parquet('../data/curated/ML_data/ML_train_data.parquet', index=False)\n",
    "ML_val_data.to_parquet('../data/curated/ML_data/ML_val_data.parquet', index=False)\n",
    "ML_test_data.to_parquet('../data/curated/ML_data/ML_test_data.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spanalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
